REPO DUMP
Generated: 2026-02-27 15:08:06.886209
Root: D:\Praca\mRNA-PLUM



================================================================================
.gitignore
================================================================================

__pycache__/
*.pyc
.venv/
OUT/
IN/
*.duckdb
*.log
dist/
build/


================================================================================
.vscode\python
================================================================================




================================================================================
.vscode\settings.json
================================================================================

{
    "python-envs.defaultEnvManager": "ms-python.python:system",
    "python-envs.pythonProjects": []
}

================================================================================
config.example.yaml
================================================================================

# Szukamy wszystkich CSV w katalogu root i podkatalogach (możesz zawęzić np. "logs/**/*.csv")
input_glob: "**/*.csv"

# Plik formularza (Excel) zawierający arkusz KEYS
keys_workbook: "RNA_PLUM_Form.xlsx"
keys_sheet: "KEYS"

# Nazwy kolumn w logach
col_time: "Czas"
col_context: "Kontekst zdarzenia"
col_desc: "Opis"
col_component: "Składnik"
col_event_name: "Nazwa zdarzenia"

# Kurs i okres z Kontekst zdarzenia
course_regex: "Kurs:\\s*([^\\s]+)"
period_regex: "(\\d{4}/\\d{2}[zl])"

chunk_rows: 200000


================================================================================
config.yaml
================================================================================

app:
  name: "RNA-PLUM"
  version: "2.0"
  timezone: "Europe/Warsaw"

paths:
  # POPRAWKA A: dodany db_path — parse_events tego wymaga (cfg["paths"]["db_path"])
  # POPRAWKA A: ujednolicona ścieżka DuckDB — wcześniej compute_stats szukał "_run/warehouse.duckdb"
  db_path: "_data/mrna_plum.duckdb"
  parquet_root: "_data/parquet"
  logs_root: "logi_plum"
  merged_logs_out: "_staging/merged"
  output_root: "_out"
  reports_excel: "_out/raport_zbiorczy.xlsx"
  individual_reports_dir: "_out/indywidualne"
  pdf_dir: "_out/pdf"
  excel_template: "wzor_raportu.xlsx"

csv:
  input_glob: "**/*.csv"
  keys_sheet: "KEYS"
  col_time: "Czas"
  col_context: "Kontekst zdarzenia"
  col_desc: "Opis"
  col_component: "Składnik"
  col_event_name: "Nazwa zdarzenia"
  chunk_rows: 200000

ingest:
  # Wzorzec dla plików: logs_WFDist22sem-NazwaPrzedmiotu-202425l_20250422-0855.csv
  filename_coursekey_regex: "^logs_(?P<coursekey>.+?)_\\d{8}-\\d{4}\\.csv$"
  recursive: true
  delimiter_detect: true
  encoding_detect: true
  normalize_to_utf8: true
  dedup:
    mode: "full_row_hash"
    hash: "sha1"

# POPRAWKA B: usunięte {root}/ z ścieżek — kod nie interpoluje tego placeholdera
mapping:
  teacher_id_email: "pliki_zrodlowe/dane_do_raportu.csv"
  email_hr: "pliki_zrodlowe/dane_do_raportu.csv"

parse_events:
  keys_xlsx: "KEYS.xlsx"
  keys_sheet: "KEYS"
  fetch_size: 5000
  insert_batch_size: 20000
  export_parquet: true

build_activities_state:
  snapshots_dir: "_data/snapshots"
  snapshots_glob: "*_zawartosc_kursow.csv"

# POPRAWKA A: ujednolicona ścieżka DuckDB (compute_stats używa tego klucza)
duckdb_path: "_data/mrna_plum.duckdb"
run_dir: "_run"

period:
  ay: "2025/26"
  term: "l"

rebuild_full: false

reports:
  excel:
    include_qc_log: true
  pdf:
    enabled: true
    engine: "excel_com"
    template_fill_mode: "anchors"


================================================================================
dump_repo.py
================================================================================

from pathlib import Path
from datetime import datetime

ROOT = Path(".").resolve()
OUT = ROOT / "FULL_REPO_DUMP.txt"

EXCLUDE = {
    ".git",
    "__pycache__",
    ".venv",
    ".idea",
    ".pytest_cache",
    "dist",
    "build"
}

def should_skip(path: Path) -> bool:
    return any(part in EXCLUDE for part in path.parts)

with OUT.open("w", encoding="utf-8") as out:
    out.write(f"REPO DUMP\n")
    out.write(f"Generated: {datetime.now()}\n")
    out.write(f"Root: {ROOT}\n\n")

    for path in sorted(ROOT.rglob("*")):
        if path.is_dir():
            continue
        if should_skip(path):
            continue
        
        out.write("\n\n" + "="*80 + "\n")
        out.write(f"{path.relative_to(ROOT)}\n")
        out.write("="*80 + "\n\n")

        try:
            content = path.read_text(encoding="utf-8")
            out.write(content)
        except Exception:
            out.write("[BINARY OR UNREADABLE FILE]\n")

print("FULL_REPO_DUMP.txt został wygenerowany.")

================================================================================
FULL_REPO_DUMP.txt
================================================================================



================================================================================
KEYS.xlsx
================================================================================

[BINARY OR UNREADABLE FILE]


================================================================================
mrna-plum.spec
================================================================================

# -*- mode: python ; coding: utf-8 -*-


a = Analysis(
    ['src\\mrna_plum\\cli.py'],
    pathex=['src'],
    binaries=[],
    datas=[],
    hiddenimports=[],
    hookspath=[],
    hooksconfig={},
    runtime_hooks=[],
    excludes=[],
    noarchive=False,
    optimize=0,
)
pyz = PYZ(a.pure)

exe = EXE(
    pyz,
    a.scripts,
    a.binaries,
    a.datas,
    [],
    name='mrna-plum',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=True,
    upx_exclude=[],
    runtime_tmpdir=None,
    console=False,
    disable_windowed_traceback=False,
    argv_emulation=False,
    target_arch=None,
    codesign_identity=None,
    entitlements_file=None,
)


================================================================================
pyproject.toml
================================================================================

[project]
name = "rna-plum"
version = "0.1.0"
description = "RNA-PLUM CLI (merge/parse/stats/export) for Moodle/PLUM logs"
requires-python = ">=3.10"
dependencies = [
  "typer>=0.12.0",
  "PyYAML>=6.0",
  "duckdb>=1.0.0",
  "pandas>=2.0.0",
  "pyarrow>=15.0.0",
  "openpyxl>=3.1.0",
]

[project.scripts]
rna_plum = "rna_plum.cli:app"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]

================================================================================
README.md
================================================================================

# mRNA-PLUM

System generowania raportów aktywności nauczycieli akademickich
(Excel VBA + Python + DuckDB)

## Architektura

merge-logs
→ parse-events
→ build-activities-state
→ compute-stats
→ export-excel
→ export-individual
→ PDF (VBA)

## Wymagania

- Python 3.13
- Excel z obsługą makr
- Windows 10/11

## Uruchomienie (CLI)

py -m mrna_plum.cli --root .

## PDF

Uruchamiane z Excel VBA (modNA_PdfEngine)


================================================================================
src\mrna_plum\__init__.py
================================================================================

__all__ = ["__version__"]
__version__ = "0.1.0"

================================================================================
src\mrna_plum\__main__.py
================================================================================

from .cli import app

if __name__ == "__main__":
    app()


================================================================================
src\mrna_plum\activities\__init__.py
================================================================================



================================================================================
src\mrna_plum\activities\activities_state.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from typing import List, Any, Dict, Optional
import json
import uuid

import duckdb


# --- Config dataclasses expected by tests ---

@dataclass(frozen=True)
class DeletionConfig:
    delete_operations: List[str]
    delete_tech_keys: List[str]
    delete_activity_labels_regex: List[str]
    disappearance_grace_period_days: int
    min_missing_snapshots_to_confirm: int
    deleted_at_policy: str  # "first_missing" | "last_seen"


@dataclass(frozen=True)
class MappingConfig:
    use_activity_id_map_table: bool
    allow_fuzzy_name_type_match: bool


@dataclass(frozen=True)
class IncrementalConfig:
    checkpoint_table: str
    checkpoint_key: str
    process_only_new_snapshots: bool
    process_only_new_events: bool


@dataclass(frozen=True)
class BuildConfig:
    deletion: DeletionConfig
    mapping: MappingConfig
    incremental: IncrementalConfig


def _ensure_tables(con: duckdb.DuckDBPyConnection) -> None:
    con.execute("create schema if not exists raw;")
    con.execute("create schema if not exists mart;")

    con.execute("""
    create table if not exists mart.activities_state (
      course_code varchar not null,
      ay varchar,
      term varchar,
      wydzial_code varchar,
      kierunek_code varchar,
      track_code varchar,
      semester_code varchar,

      activity_id varchar not null,
      type varchar,
      name_last varchar,

      first_seen_at timestamp,
      last_seen_at timestamp,

      last_snapshot_at timestamp,
      last_event_at timestamp,

      visible_last boolean,
      deleted_at timestamp,

      status_final varchar not null,
      evidence_deleted varchar not null,
      confidence_deleted double not null,

      notes varchar,
      updated_at timestamp default now(),

      primary key(course_code, activity_id)
    );
    """)

    con.execute("""
    create table if not exists mart.activities_qa (
      qa_id varchar,
      qa_type varchar not null,
      course_code varchar,
      activity_id varchar,
      object_id varchar,
      details_json varchar,
      created_at timestamp default now()
    );
    """)


def _qa(con: duckdb.DuckDBPyConnection, qa_type: str,
        course_code: Optional[str], activity_id: Optional[str],
        object_id: Optional[str], details: Dict[str, Any]) -> None:
    con.execute(
        """
        insert into mart.activities_qa(qa_id, qa_type, course_code, activity_id, object_id, details_json)
        values (?,?,?,?,?,?)
        """,
        [str(uuid.uuid4()), qa_type, course_code, activity_id, object_id, json.dumps(details, ensure_ascii=False)],
    )


def build_activities_state(con: duckdb.DuckDBPyConnection, cfg: BuildConfig) -> dict:
    """
    Public API expected by tests.
    Minimal implementation to satisfy:
    - delete from logs
    - disappearance from snapshots
    - hidden
    - conflict QA
    - missing mapping QA
    """
    _ensure_tables(con)

    # Universe: wszystkie (course_code, activity_id) z snapshotów + eventów gdzie object_id nie null
    con.execute("""
    create temp table tmp_universe as
    select distinct course_code, activity_id
    from raw.activities_snapshot
    union
    select distinct course_code, cast(object_id as varchar) as activity_id
    from events_canonical
    where object_id is not null;
    """)

    # Snapshot last
    con.execute("""
    create temp table tmp_snap_last as
    select s.*
    from raw.activities_snapshot s
    join (
      select course_code, activity_id, max(captured_at) as mx
      from raw.activities_snapshot
      group by 1,2
    ) t
    on s.course_code=t.course_code and s.activity_id=t.activity_id and s.captured_at=t.mx;
    """)

    # Snapshot bounds per activity
    con.execute("""
    create temp table tmp_snap_bounds as
    select course_code, activity_id, min(captured_at) as first_snap, max(captured_at) as last_snap
    from raw.activities_snapshot
    group by 1,2;
    """)

    # Event bounds per object_id (map 1:1 -> activity_id)
    con.execute("""
    create temp table tmp_evt_bounds as
    select course_code, cast(object_id as varchar) as activity_id,
           min(ts_utc) as first_evt,
           max(ts_utc) as last_evt
    from events_canonical
    where counted = true and object_id is not null
    group by 1,2;
    """)

    # Delete from logs (operation == DELETE)
    con.execute("""
    create temp table tmp_evt_delete as
    select course_code, cast(object_id as varchar) as activity_id, min(ts_utc) as deleted_at_log
    from events_canonical
    where counted = true
      and object_id is not null
      and upper(operation) = 'DELETE'
    group by 1,2;
    """)

    # Disappearance:
    # - last_seen_snap_at = max(captured_at) for activity
    # - count snapshots of course after last_seen_snap_at (>=min_missing)
    # - last_course_snapshot_at >= first_missing + grace
    con.execute("""
    create temp table tmp_course_snaps as
    select course_code, captured_at
    from raw.activities_snapshot
    group by 1,2;
    """)

    con.execute("""
    create temp table tmp_last_seen as
    select course_code, activity_id,
           max(captured_at) as last_seen_snap_at,
           min(captured_at) as first_seen_snap_at
    from raw.activities_snapshot
    group by 1,2;
    """)

    con.execute("""
    create temp table tmp_missing as
    select
      a.course_code,
      a.activity_id,
      a.last_seen_snap_at,
      min(cs.captured_at) as first_missing_snapshot_at,
      count(*) as missing_count,
      max(cs.captured_at) as last_course_snapshot_at
    from tmp_last_seen a
    join tmp_course_snaps cs
      on cs.course_code=a.course_code and cs.captured_at > a.last_seen_snap_at
    group by 1,2,3;
    """)

    con.execute("""
    create temp table tmp_disappearance as
    select
      course_code,
      activity_id,
      case
        when ? = 'first_missing' then first_missing_snapshot_at
        else last_seen_snap_at
      end as deleted_at_snap,
      first_missing_snapshot_at,
      last_course_snapshot_at,
      missing_count
    from tmp_missing
    where missing_count >= ?
      and last_course_snapshot_at >= (first_missing_snapshot_at + (? || ' days')::interval);
    """, [cfg.deletion.deleted_at_policy, cfg.deletion.min_missing_snapshots_to_confirm, cfg.deletion.disappearance_grace_period_days])

    # Course meta (z eventów)
    con.execute("""
    create temp table tmp_course_meta as
    select course_code,
           any_value(ay) as ay,
           any_value(term) as term,
           any_value(wydzial_code) as wydzial_code,
           any_value(kierunek_code) as kierunek_code,
           any_value(track_code) as track_code,
           any_value(semester_code) as semester_code
    from events_canonical
    group by 1;
    """)

    # Final stage
    con.execute("""
    create temp table tmp_final as
    select
      u.course_code,
      m.ay, m.term, m.wydzial_code, m.kierunek_code, m.track_code, m.semester_code,
      u.activity_id,
      sl.type,
      sl.name as name_last,
      least(sb.first_snap, eb.first_evt) as first_seen_at,
      greatest(sb.last_snap, eb.last_evt) as last_seen_at,
      sb.last_snap as last_snapshot_at,
      eb.last_evt as last_event_at,
      sl.visible_to_students as visible_last,
      dlog.deleted_at_log,
      ds.deleted_at_snap,
      case
        when dlog.deleted_at_log is not null and ds.deleted_at_snap is not null then least(dlog.deleted_at_log, ds.deleted_at_snap)
        when dlog.deleted_at_log is not null then dlog.deleted_at_log
        when ds.deleted_at_snap is not null then ds.deleted_at_snap
        else null
      end as deleted_at,
      case
        when dlog.deleted_at_log is not null and ds.deleted_at_snap is not null then 'both'
        when dlog.deleted_at_log is not null then 'log_delete_event'
        when ds.deleted_at_snap is not null then 'snapshot_disappearance'
        else 'none'
      end as evidence_deleted,
      case
        when dlog.deleted_at_log is not null and ds.deleted_at_snap is not null then 0.95
        when dlog.deleted_at_log is not null then 0.80
        when ds.deleted_at_snap is not null then 0.70
        else 0.0
      end as confidence_deleted
    from tmp_universe u
    left join tmp_course_meta m using(course_code)
    left join tmp_snap_last sl using(course_code, activity_id)
    left join tmp_snap_bounds sb using(course_code, activity_id)
    left join tmp_evt_bounds eb using(course_code, activity_id)
    left join tmp_evt_delete dlog using(course_code, activity_id)
    left join tmp_disappearance ds using(course_code, activity_id);
    """)

    # QA: conflict log delete but snapshot visible after delete
    rows = con.execute("""
    select course_code, activity_id, deleted_at_log, last_snapshot_at
    from tmp_final
    where deleted_at_log is not null
      and last_snapshot_at is not null
      and last_snapshot_at > deleted_at_log
      and visible_last = true;
    """).fetchall()
    for course_code, activity_id, deleted_at_log, last_snapshot_at in rows:
        _qa(con, "conflict_log_delete_but_visible_in_snapshot", course_code, activity_id, None, {
            "deleted_at_log": str(deleted_at_log),
            "last_snapshot_at": str(last_snapshot_at),
        })

    # QA: activity without mapping (snapshot exists but no events for it)
    rows = con.execute("""
    select s.course_code, s.activity_id
    from (select distinct course_code, activity_id from raw.activities_snapshot) s
    left join (select distinct course_code, cast(object_id as varchar) as activity_id from events_canonical where object_id is not null) e
      on e.course_code=s.course_code and e.activity_id=s.activity_id
    where e.activity_id is null;
    """).fetchall()
    for course_code, activity_id in rows:
        _qa(con, "activity_without_object_id_mapping", course_code, activity_id, None, {})

    # status_final
    con.execute("""
    create temp table tmp_final2 as
    select *,
      case
        when deleted_at is not null then 'visible_deleted'
        when visible_last = true then 'visible_active'
        when visible_last = false then 'hidden'
        else 'unknown'
      end as status_final,
      cast(null as varchar) as notes
    from tmp_final;
    """)

    # Upsert (delete+insert for simplicity in tests)
    con.execute("delete from mart.activities_state;")
    con.execute("""
    insert into mart.activities_state(
      course_code, ay, term, wydzial_code, kierunek_code, track_code, semester_code,
      activity_id, type, name_last,
      first_seen_at, last_seen_at,
      last_snapshot_at, last_event_at,
      visible_last,
      deleted_at,
      status_final, evidence_deleted, confidence_deleted,
      notes
    )
    select
      course_code, ay, term, wydzial_code, kierunek_code, track_code, semester_code,
      activity_id, type, name_last,
      first_seen_at, last_seen_at,
      last_snapshot_at, last_event_at,
      visible_last,
      deleted_at,
      status_final, evidence_deleted, confidence_deleted,
      notes
    from tmp_final2;
    """)

    return {"ok": True}

================================================================================
src\mrna_plum\activities\snapshots_load.py
================================================================================

from __future__ import annotations

import csv
import hashlib
import json
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Iterable, Optional

import duckdb


def _sha1(text: str) -> str:
    return hashlib.sha1(text.encode("utf-8", errors="replace")).hexdigest()


def _captured_at_from_filename(path: Path) -> datetime:
    # np. 20260206-0826_2526z_zawartosc_kursow.csv
    m = re.search(r"(\d{8})-(\d{4})", path.name)
    if not m:
        return datetime.fromtimestamp(path.stat().st_mtime)
    ymd = m.group(1)  # YYYYMMDD
    hm = m.group(2)   # HHMM
    return datetime(
        int(ymd[0:4]), int(ymd[4:6]), int(ymd[6:8]),
        int(hm[0:2]), int(hm[2:4]),
    )


@dataclass(frozen=True)
class SnapshotRowPL:
    course_code: str
    activity_id: str
    name: str
    type: str
    visible_to_students: bool
    captured_at: datetime
    source_file: str
    row_key: str


def iter_snapshot_csv_plum_visible(path: Path) -> Iterable[SnapshotRowPL]:
    captured_at = _captured_at_from_filename(path)

    with path.open("r", encoding="utf-8-sig", newline="") as f:
        reader = csv.DictReader(f)

        req = {"Nazwa kursu", "ID aktywności", "Nazwa aktywności", "Format aktywności"}
        missing = req - set(reader.fieldnames or [])
        if missing:
            raise ValueError(f"Snapshot(PL) missing columns {sorted(missing)} in {path}")

        for r in reader:
            course_code = (r.get("Nazwa kursu") or "").strip()
            activity_id = (r.get("ID aktywności") or "").strip()
            if not course_code or not activity_id:
                continue

            name = (r.get("Nazwa aktywności") or "").strip()
            typ = (r.get("Format aktywności") or "").strip()

            payload = json.dumps(
                {
                    "course_code": course_code,
                    "activity_id": activity_id,
                    "name": name,
                    "type": typ,
                    "visible_to_students": True,
                    "captured_at": captured_at.isoformat(),
                },
                ensure_ascii=False,
                separators=(",", ":"),
            )
            row_key = _sha1(payload)

            yield SnapshotRowPL(
                course_code=course_code,
                activity_id=activity_id,
                name=name,
                type=typ,
                visible_to_students=True,
                captured_at=captured_at,
                source_file=str(path),
                row_key=row_key,
            )


def ensure_snapshot_table(con: duckdb.DuckDBPyConnection) -> None:
    con.execute("create schema if not exists raw;")
    con.execute(
        """
        create table if not exists raw.activities_snapshot (
          course_code varchar not null,
          activity_id varchar not null,
          name varchar,
          type varchar,
          visible_to_students boolean,
          captured_at timestamp not null,
          source_file varchar,
          row_key varchar not null,
          inserted_at timestamp default now()
        );
        """
    )
    con.execute(
        "create unique index if not exists ux_activities_snapshot_rowkey on raw.activities_snapshot(row_key);"
    )


def load_plum_snapshot_file_into_duckdb(
    con: duckdb.DuckDBPyConnection,
    snapshot_file: Path,
) -> dict:
    ensure_snapshot_table(con)

    inserted = 0
    scanned = 0
    max_captured_at: Optional[datetime] = None

    for row in iter_snapshot_csv_plum_visible(snapshot_file):
        scanned += 1
        con.execute(
            """
            insert into raw.activities_snapshot
            (course_code, activity_id, name, type, visible_to_students, captured_at, source_file, row_key)
            select ?,?,?,?,?,?,?,?
            where not exists (select 1 from raw.activities_snapshot where row_key = ?)
            """,
            [
                row.course_code,
                row.activity_id,
                row.name,
                row.type,
                row.visible_to_students,
                row.captured_at,
                row.source_file,
                row.row_key,
                row.row_key,
            ],
        )
        inserted += int(con.execute("select changes()").fetchone()[0])

        if max_captured_at is None or row.captured_at > max_captured_at:
            max_captured_at = row.captured_at

    return {
        "snapshot_file": str(snapshot_file),
        "scanned_rows": scanned,
        "inserted_rows": inserted,
        "captured_at": max_captured_at.isoformat() if max_captured_at else None,
    }

================================================================================
src\mrna_plum\cfg_helpers.py
================================================================================

from __future__ import annotations
from pathlib import Path
from typing import Any

def cfg_get(cfg: dict, key: str, default: Any = None) -> Any:
    cur: Any = cfg
    for part in key.split("."):
        if not isinstance(cur, dict) or part not in cur:
            return default
        cur = cur[part]
    return cur

def cfg_str(cfg: dict, key: str, default: str | None = None) -> str | None:
    v = cfg_get(cfg, key, default)
    return None if v is None else str(v)

def cfg_int(cfg: dict, key: str, default: int | None = None) -> int | None:
    v = cfg_get(cfg, key, default)
    return None if v is None else int(v)

def cfg_bool(cfg: dict, key: str, default: bool = False) -> bool:
    v = cfg_get(cfg, key, default)
    return bool(v)

def cfg_path(root: Path, cfg: dict, key: str, default_rel: str | None = None) -> Path | None:
    v = cfg_get(cfg, key, default_rel)
    if v is None or str(v).strip() == "":
        return None
    p = Path(str(v))
    return p if p.is_absolute() else (root / p).resolve()

================================================================================
src\mrna_plum\cli.py
================================================================================

from __future__ import annotations

from pathlib import Path
from typing import Optional, Callable, Any

import typer

from mrna_plum.paths import ProjectPaths
from mrna_plum.config import load_config
from mrna_plum.logging_run import setup_file_logger
from mrna_plum.ui_bridge import ProgressWriter
from mrna_plum.errors import ConfigError, InputDataError, MixedPeriodsError, ProcessingError

# NEW: autodetekcja INPUTS_DIR
from mrna_plum.inputs.autodetect import find_inputs, InputValidationError

app = typer.Typer(add_completion=False)

# Exit codes (wg ustaleń)
EC_OK = 0
EC_CONFIG = 2
EC_INPUT = 10
EC_MIXED = 20
EC_PROC = 30
EC_INTERNAL = 40


# -------------------------
# Helpers
# -------------------------
def _resolve_root(root: str) -> Path:
    return Path(root).resolve()


def _resolve_config(root: Path, config: str | None) -> Path:
    return Path(config).resolve() if config else (root / "config.yaml").resolve()


def _ensure_dirs(paths: ProjectPaths) -> None:
    paths.run_dir.mkdir(parents=True, exist_ok=True)
    paths.data_dir.mkdir(parents=True, exist_ok=True)
    paths.parquet_dir.mkdir(parents=True, exist_ok=True)
    # opcjonalnie: out dir jeśli masz w ProjectPaths
    try:
        paths.out_dir.mkdir(parents=True, exist_ok=True)  # type: ignore[attr-defined]
    except Exception:
        (paths.root / "_out").mkdir(parents=True, exist_ok=True)


def _write_marker(paths: ProjectPaths, step: str) -> None:
    # marker: {step}.ok w _run
    paths.marker_path(step).write_text("ok", encoding="utf-8")


def _collect_input_files(root: Path, input_glob: str) -> list[Path]:
    return sorted([p for p in root.glob(input_glob) if p.is_file()])


def _main_guard(fn: Callable[..., Any]) -> Callable[..., Any]:
    def wrapper(*args, **kwargs):
        try:
            return fn(*args, **kwargs)
        except ConfigError as e:
            typer.echo(str(e), err=True)
            raise typer.Exit(code=EC_CONFIG)
        except InputDataError as e:
            typer.echo(str(e), err=True)
            raise typer.Exit(code=EC_INPUT)
        except MixedPeriodsError as e:
            typer.echo(str(e), err=True)
            raise typer.Exit(code=EC_MIXED)
        except ProcessingError as e:
            typer.echo(str(e), err=True)
            raise typer.Exit(code=EC_PROC)
        except typer.Exit:
            raise
        except Exception as e:
            typer.echo(f"Internal error: {e}", err=True)
            raise typer.Exit(code=EC_INTERNAL)

    return wrapper


# -------- NEW: INPUTS_DIR helpers --------
def _resolve_inputs_dir(root: Path, cfg: Any, inputs_dir_opt: str | None) -> Path | None:
    """
    Priorytet:
    1) CLI --inputs-dir
    2) config.yaml: inputs.inputs_dir (jeśli istnieje)
    """
    if inputs_dir_opt:
        return Path(inputs_dir_opt).expanduser().resolve()

    v = None
    try:
        if isinstance(cfg, dict):
            v = (cfg.get("inputs") or {}).get("inputs_dir")
        else:
            # jeśli kiedyś inputs będzie atrybutem
            v = getattr(getattr(cfg, "inputs", None), "inputs_dir", None)
            # Twoja konfiguracja używa często cfg._data jako słownik
            if v is None and hasattr(cfg, "_data"):
                inputs_sec = cfg._data.get("inputs") or {}  # type: ignore[attr-defined]
                if isinstance(inputs_sec, dict):
                    v = inputs_sec.get("inputs_dir")
    except Exception:
        v = None

    if not v:
        return None

    p = Path(str(v)).expanduser()
    if not p.is_absolute():
        p = (root / p).resolve()
    else:
        p = p.resolve()
    return p


def _emit_inputs_detected(progress: ProgressWriter, inputs: Any) -> None:
    progress.emit(
        "inputs",
        "detected",
        "Inputs autodetected",
        extra={
            "inputs_dir": str(inputs.inputs_dir),
            "teachers_csv": str(inputs.teachers_csv) if getattr(inputs, "teachers_csv", None) else None,
            "roster_csv": str(inputs.roster_csv) if getattr(inputs, "roster_csv", None) else None,
            "snapshot_csv": str(inputs.snapshot_csv) if getattr(inputs, "snapshot_csv", None) else None,
            # opcjonalne mapowania (jeśli find_inputs je zwraca)
            "teachers_map": getattr(inputs, "teachers_map", None),
            "roster_map": getattr(inputs, "roster_map", None),
            "snapshot_map": getattr(inputs, "snapshot_map", None),
        },
    )


def _inject_inputs_into_cfg(cfg: Any, teachers_csv: str | None, roster_csv: str | None, snapshot_csv: str | None = None) -> None:
    """
    Wstrzykuje wykryte pliki do cfg:
      cfg.inputs.teachers_csv / cfg.inputs.roster_csv / cfg.inputs.snapshot_csv
    Obsługuje cfg jako dict lub obiekt z _data.
    """
    if isinstance(cfg, dict):
        cfg.setdefault("inputs", {})
        if not isinstance(cfg["inputs"], dict):
            cfg["inputs"] = {}
        cfg["inputs"]["teachers_csv"] = teachers_csv
        cfg["inputs"]["roster_csv"] = roster_csv
        cfg["inputs"]["snapshot_csv"] = snapshot_csv
        return

    if hasattr(cfg, "_data"):
        cfg._data.setdefault("inputs", {})  # type: ignore[attr-defined]
        if not isinstance(cfg._data["inputs"], dict):  # type: ignore[attr-defined]
            cfg._data["inputs"] = {}  # type: ignore[attr-defined]
        cfg._data["inputs"]["teachers_csv"] = teachers_csv  # type: ignore[attr-defined]
        cfg._data["inputs"]["roster_csv"] = roster_csv  # type: ignore[attr-defined]
        cfg._data["inputs"]["snapshot_csv"] = snapshot_csv  # type: ignore[attr-defined]
        return

    # fallback: dynamic attrs (ostatnia deska ratunku)
    setattr(cfg, "inputs_teachers_csv", teachers_csv)
    setattr(cfg, "inputs_roster_csv", roster_csv)
    setattr(cfg, "inputs_snapshot_csv", snapshot_csv)


# -------------------------
# Commands
# -------------------------

@app.command("init")
@_main_guard
def cmd_init(
    root: str = typer.Option(..., "--root", help="Root folder projektu (np. ThisWorkbook.Path)"),
):
    """
    Tworzy podstawową strukturę folderów projektu.
    """
    root_p = _resolve_root(root)

    # lazy import - bez ryzyka cykli
    from .init_project import init_project

    created = init_project(root_p)
    typer.echo(f"Created {len(created)} folders")
    raise typer.Exit(code=EC_OK)


@app.command("merge-logs")
@_main_guard
def cmd_merge_logs(
    root: str = typer.Option(..., "--root", help="Root folder passed from VBA (ThisWorkbook.Path)"),
    config: str | None = typer.Option(None, "--config", help="Config path; default {root}/config.yaml"),
    mode: str = typer.Option(
        "duckdb",
        "--mode",
        help="duckdb (pipeline B) | parquet (pipeline A → merged_raw.parquet)",
        case_sensitive=False,
    ),
):
    """
    Merge logów CSV z Moodle/PLUM.

    mode=parquet:
        CSV → merged_raw.parquet (pipeline A)

    mode=duckdb:
        CSV → DuckDB raw (pipeline B / staging)
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    mode = mode.lower().strip()
    if mode not in ("parquet", "duckdb"):
        raise typer.BadParameter("--mode must be one of: duckdb, parquet")

    input_files = _collect_input_files(root_p, cfg.input_glob)
    if not input_files:
        raise InputDataError(f"No input files found under {root_p} with glob {cfg.input_glob}")

    progress.emit(
        "merge",
        "start",
        f"Starting merge ({mode})",
        current=0,
        total=len(input_files),
        extra={"root": str(root_p), "mode": mode},
    )
    logger.info("[merge] start mode=%s files=%s", mode, len(input_files))

    if mode == "parquet":
        # pipeline A
        from .merge import merge_logs_to_parquet

        merged_parquet = paths.parquet_dir / "merged_raw.parquet"
        total_rows = merge_logs_to_parquet(input_files, merged_parquet, dedup_per_file=True)

        progress.emit(
            "merge",
            "done",
            "Merge finished",
            current=len(input_files),
            total=len(input_files),
            extra={"rows": total_rows, "parquet": str(merged_parquet)},
        )
        _write_marker(paths, "merge")
        logger.info("[merge] done rows=%s parquet=%s", total_rows, merged_parquet)
        raise typer.Exit(code=EC_OK)

    # mode == duckdb → pipeline B
    from .store.duckdb_store import open_store
    from .merge.merge_logs import merge_logs_into_duckdb

    db_path = paths.duckdb_path
    con = open_store(db_path)
    try:
        res = merge_logs_into_duckdb(
            root=root_p,
            con=con,
            export_mode="duckdb",
            export_dir=None,
            chunk_size=int(getattr(cfg, "chunk_rows", 2000)),  # fallback
        )
    finally:
        con.close()

    progress.emit(
        "merge",
        "done",
        "Merge finished (duckdb)",
        current=len(input_files),
        total=len(input_files),
        extra={
            "db": str(db_path),
            "courses": getattr(res, "courses", None),
            "inserted_rows": getattr(res, "inserted_rows", None),
        },
    )
    _write_marker(paths, "merge")
    logger.info("[merge] done duckdb db=%s res=%s", db_path, res)
    raise typer.Exit(code=EC_OK)


@app.command("build-db")
@_main_guard
def cmd_build_db(
    root: str = typer.Option(..., "--root"),
    config: str | None = typer.Option(None, "--config"),
):
    """
    Pipeline A: merged_raw.parquet → parsed.parquet → DuckDB(raw_logs)
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    # KEYS → rules
    from .io.excel_keys import load_keys_sheet
    from .rules.engine import compile_rules

    keys_wb = (root_p / cfg.keys_workbook).resolve()
    keys_df = load_keys_sheet(keys_wb, cfg.keys_sheet)
    rules = compile_rules(keys_df)

    merged_parquet = paths.parquet_dir / "merged_raw.parquet"
    if not merged_parquet.exists():
        raise InputDataError(
            f"Missing merged parquet. Run: mrna_plum merge-logs --mode parquet --root ...  Expected: {merged_parquet}"
        )

    progress.emit("parse", "start", "Parsing merged logs & applying rules")
    logger.info("[parse] start rules=%s", len(rules))

    from .parse import parse_merged_parquet

    parsed_parquet = paths.parquet_dir / "parsed.parquet"
    n_rows, run_period = parse_merged_parquet(merged_parquet, parsed_parquet, cfg, rules)

    # DuckDB load
    from .store import DuckDbStore

    store = DuckDbStore(paths.duckdb_path)
    store.init_schema()

    progress.emit("db", "start", "Loading parsed parquet into DuckDB", extra={"db": str(paths.duckdb_path)})
    store.load_parquet_to_raw(parsed_parquet)

    progress.emit("db", "done", "DB built", extra={"rows": n_rows, "period": run_period})
    _write_marker(paths, "build_db")
    logger.info("[db] done rows=%s period=%s db=%s", n_rows, run_period, paths.duckdb_path)
    raise typer.Exit(code=EC_OK)


@app.command("parse-events")
@_main_guard
def cmd_parse_events(
    root: str = typer.Option(..., "--root", help="Root projektu"),
    config: str | None = typer.Option(None, "--config", help="config.yaml; default {root}/config.yaml"),
    keys_xlsx: str | None = typer.Option(None, "--keys-xlsx", help="Override ścieżki KEYS.xlsx/KEYS workbook"),
):
    """
    Pipeline B: raw (DuckDB) → events_canonical (DuckDB)
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    progress.emit(
        "parse_events",
        "start",
        "Parsing events into events_canonical",
        extra={"db": str(paths.duckdb_path), "keys_xlsx": keys_xlsx},
    )
    logger.info("[parse_events] start db=%s", paths.duckdb_path)

    from .parse.parse_events import run_parse_events

    exit_code = run_parse_events(cfg, root=str(root_p), keys_xlsx_override=keys_xlsx)
    if exit_code != 0:
        raise ProcessingError(f"parse-events failed with exit code {exit_code}")

    progress.emit("parse_events", "done", "Events parsed")
    _write_marker(paths, "parse_events")
    logger.info("[parse_events] done")
    raise typer.Exit(code=EC_OK)


@app.command("build-activities-state")
@_main_guard
def cmd_build_activities_state(
    root: str = typer.Option(..., "--root", help="Root projektu"),
    config: str | None = typer.Option(None, "--config", help="config.yaml; default {root}/config.yaml"),
    # NEW: INPUTS_DIR
    inputs_dir: str | None = typer.Option(
        None,
        "--inputs-dir",
        help="Folder INPUTS_DIR (autodetekcja plików HR/roster/snapshot)",
    ),
    # CHANGED: snapshot-file optional (override)
    snapshot_file: str | None = typer.Option(
        None,
        "--snapshot-file",
        help="Override: CSV '*_zawartosc_kursow.csv' (jeśli nie używasz inputs-dir)",
    ),
):
    """
    Pipeline B: snapshot CSV → raw.activities_snapshot → mart.activities_state
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    # --- resolve snapshot path (override -> autodetect) ---
    snap_path: Path | None = None

    if snapshot_file:
        snap_path = Path(snapshot_file).expanduser().resolve()
    else:
        in_dir = _resolve_inputs_dir(root_p, cfg, inputs_dir)
        if in_dir:
            try:
                inputs = find_inputs(in_dir)
            except InputValidationError as e:
                progress.emit("inputs", "error", "Inputs autodetect failed", extra={"error": str(e)})
                raise InputDataError(str(e))

            _emit_inputs_detected(progress, inputs)

            # snapshot krytyczny dla tego kroku
            snap_path = inputs.snapshot_csv

            # HR/roster opcjonalne: loguj warningi
            if not inputs.teachers_csv:
                progress.emit("inputs", "warning", "HR file missing (dane_do_raportu.csv) - HR fields will be '-'")
            if not inputs.roster_csv:
                progress.emit("inputs", "warning", "Roster missing (*_raport_uczestnikow.csv) - students_enrolled will be '-'")

            # wstrzyknij do cfg (żeby dalsze kroki mogły korzystać)
            _inject_inputs_into_cfg(
                cfg,
                teachers_csv=str(inputs.teachers_csv) if inputs.teachers_csv else None,
                roster_csv=str(inputs.roster_csv) if inputs.roster_csv else None,
                snapshot_csv=str(inputs.snapshot_csv) if inputs.snapshot_csv else None,
            )

    if not snap_path or not snap_path.exists():
        msg = "Missing snapshot CSV. Provide --snapshot-file or --inputs-dir with a file '*_zawartosc_kursow.csv'."
        progress.emit("inputs", "error", msg, extra={"snapshot_file": str(snap_path) if snap_path else None})
        raise InputDataError(msg)

    from .store import DuckDbStore
    from .activities.activities_state import (
        build_activities_state,
        BuildConfig,
        DeletionConfig,
        MappingConfig,
        IncrementalConfig,
    )

    store = DuckDbStore(paths.duckdb_path)
    store.init_schema()

    progress.emit(
        "activities_state",
        "start",
        "Loading snapshots & building activities_state",
        extra={"snapshot_file": str(snap_path), "db": str(paths.duckdb_path)},
    )
    logger.info("[activities_state] start snapshot=%s", snap_path)

    from .activities.snapshots_load import load_plum_snapshot_file_into_duckdb

    # KONFIG: minimalny default
    build_cfg = BuildConfig(
        deletion=DeletionConfig(
            delete_operations=["DELETE"],
            delete_tech_keys=[],
            delete_activity_labels_regex=[],
            disappearance_grace_period_days=14,
            min_missing_snapshots_to_confirm=2,
            deleted_at_policy="first_missing",
        ),
        mapping=MappingConfig(
            use_activity_id_map_table=True,
            allow_fuzzy_name_type_match=False,
        ),
        incremental=IncrementalConfig(
            checkpoint_table="raw.pipeline_checkpoints",
            checkpoint_key="build_activities_state",
            process_only_new_snapshots=True,
            process_only_new_events=True,
        ),
    )

    with store.connect() as con:
        load_stats = load_plum_snapshot_file_into_duckdb(con, snap_path)
        progress.emit("activities_state", "snapshots_loaded", "Snapshots loaded", extra=load_stats)

        stats = build_activities_state(con, build_cfg)

    progress.emit("activities_state", "done", "Activities state built", extra=stats)
    _write_marker(paths, "activities_state")
    logger.info("[activities_state] done %s", stats)
    raise typer.Exit(code=EC_OK)


@app.command("compute-stats")
@_main_guard
def cmd_compute_stats(
    root: str = typer.Option(..., "--root"),
    ay: str | None = typer.Option(None, "--ay"),
    term: str | None = typer.Option(None, "--term"),
    config: str | None = typer.Option(None, "--config"),
):
    """
    Ujednolicone compute-stats: wywołuje stats.compute_stats(root, ay, term).
    """
    root_p = _resolve_root(root)
    _ = _resolve_config(root_p, config)  # na przyszłość
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    progress.emit("stats", "start", "Computing stats", extra={"ay": ay, "term": term})
    logger.info("[stats] start ay=%s term=%s", ay, term)

    from .stats.compute_stats import compute_stats

    compute_stats(root=root_p, ay=ay, term=term)

    progress.emit("stats", "done", "Stats computed", extra={"ay": ay, "term": term})
    _write_marker(paths, "stats")
    logger.info("[stats] done")
    raise typer.Exit(code=EC_OK)


@app.command("export-excel")
@_main_guard
def cmd_export_excel(
    root: str = typer.Option(..., "--root"),
    db_path: str | None = typer.Option(None, "--db-path", help="Override ścieżki do DuckDB; default z ProjectPaths"),
    config: str | None = typer.Option(None, "--config"),
    # NEW: INPUTS_DIR (opcjonalne, ale przydatne do metryczki/roster w raportach)
    inputs_dir: str | None = typer.Option(None, "--inputs-dir", help="Folder INPUTS_DIR (autodetekcja HR/roster)"),
):
    """
    Eksport agregatów do Excela (docelowo: export_summary_excel).
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    # NEW: autodetekcja HR/roster (opcjonalne)
    in_dir = _resolve_inputs_dir(root_p, cfg, inputs_dir)
    if in_dir:
        try:
            inputs = find_inputs(in_dir)
        except InputValidationError as e:
            progress.emit("inputs", "error", "Inputs autodetect failed", extra={"error": str(e)})
            raise InputDataError(str(e))

        _emit_inputs_detected(progress, inputs)

        if not inputs.teachers_csv:
            progress.emit("inputs", "warning", "HR file missing (dane_do_raportu.csv) - HR fields will be '-'")
        if not inputs.roster_csv:
            progress.emit("inputs", "warning", "Roster missing (*_raport_uczestnikow.csv) - students_enrolled will be '-'")

        _inject_inputs_into_cfg(
            cfg,
            teachers_csv=str(inputs.teachers_csv) if inputs.teachers_csv else None,
            roster_csv=str(inputs.roster_csv) if inputs.roster_csv else None,
            snapshot_csv=str(inputs.snapshot_csv) if inputs.snapshot_csv else None,
        )

    db = Path(db_path).resolve() if db_path else paths.duckdb_path

    progress.emit("export_excel", "start", "Exporting Excel report", extra={"db": str(db)})
    logger.info("[export_excel] start db=%s", db)

    import duckdb
    from .reports.export_excel import export_summary_excel, ExportOverflowError, EXIT_OVERFLOW

    con = duckdb.connect(str(db))
    try:
        code, out_path = export_summary_excel(con, cfg)  # cfg w Twoim repo jest dict-like
    except ExportOverflowError:
        raise typer.Exit(code=EXIT_OVERFLOW)
    finally:
        con.close()

    progress.emit("export_excel", "done", "Excel exported", extra={"out": str(out_path)})
    _write_marker(paths, "export_excel")
    logger.info("[export_excel] done out=%s", out_path)
    raise typer.Exit(code=code)


@app.command("export-individual")
@_main_guard
def cmd_export_individual(
    root: str = typer.Option(..., "--root"),
    config: str | None = typer.Option(None, "--config"),
    out_dir: str | None = typer.Option(None, "--out-dir", help="Override folderu wyjściowego na XLSX"),
    # NEW: INPUTS_DIR
    inputs_dir: str | None = typer.Option(None, "--inputs-dir", help="Folder INPUTS_DIR (autodetekcja HR/roster/snapshot)"),
):
    """
    Eksport paczek indywidualnych.
    """
    root_p = _resolve_root(root)
    cfg_p = _resolve_config(root_p, config)
    paths = ProjectPaths(root=root_p)
    _ensure_dirs(paths)

    # Ustal out_dir_p i upewnij się że istnieje
    if out_dir:
        out_dir_p = Path(out_dir).expanduser().resolve()
    else:
        out_dir_p = paths.out_dir / "indywidualne"
    out_dir_p.mkdir(parents=True, exist_ok=True)

    logger = setup_file_logger(paths.run_dir / "run.log")
    progress = ProgressWriter(paths.run_dir / "progress.jsonl")

    cfg = load_config(cfg_p)

    # NEW: autodetekcja HR/roster (opcjonalne)
    in_dir = _resolve_inputs_dir(root_p, cfg, inputs_dir)
    if in_dir:
        try:
            inputs = find_inputs(in_dir)
        except InputValidationError as e:
            progress.emit("inputs", "error", "Inputs autodetect failed", extra={"error": str(e)})
            raise InputDataError(str(e))

        _emit_inputs_detected(progress, inputs)

        if not inputs.teachers_csv:
            progress.emit("inputs", "warning", "HR file missing (dane_do_raportu.csv) - HR fields will be '-'")
        if not inputs.roster_csv:
            progress.emit("inputs", "warning", "Roster missing (*_raport_uczestnikow.csv) - students_enrolled will be '-'")

        _inject_inputs_into_cfg(
            cfg,
            teachers_csv=str(inputs.teachers_csv) if inputs.teachers_csv else None,
            roster_csv=str(inputs.roster_csv) if inputs.roster_csv else None,
            snapshot_csv=str(inputs.snapshot_csv) if inputs.snapshot_csv else None,
        )

    # Wstrzyknij out_dir do cfg (tak jak było)
    if isinstance(cfg, dict):
        cfg.setdefault("reports", {})
        cfg["reports"]["individual_dir"] = str(out_dir_p)
    else:
        cfg._data.setdefault("reports", {})  # type: ignore[attr-defined]
        if not isinstance(cfg._data["reports"], dict):  # type: ignore[attr-defined]
            cfg._data["reports"] = {}  # type: ignore[attr-defined]
        cfg._data["reports"]["individual_dir"] = str(out_dir_p)  # type: ignore[attr-defined]

    progress.emit("export_individual", "start", "Exporting individual reports", extra={"out_dir": str(out_dir_p)})
    logger.info("[export_individual] start out_dir=%s", out_dir_p)

    import duckdb as _duckdb
    db = paths.duckdb_path
    con = _duckdb.connect(str(db))
    try:
        from .reports.export_individual import export_individual_reports
        code, result_dir = export_individual_reports(con, cfg)
    finally:
        con.close()

    progress.emit("export_individual", "done", "Individual reports exported", extra={"out_dir": str(result_dir)})
    _write_marker(paths, "export_individual")
    logger.info("[export_individual] done out_dir=%s", result_dir)
    raise typer.Exit(code=code)

================================================================================
src\mrna_plum\config.py
================================================================================

# src/mrna_plum/config.py
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

import yaml

from mrna_plum.errors import ConfigError


# ---------------------------------------------------------------------------
# AppConfig — używany przez merge/parse (pipeline A, CSV layer)
# ---------------------------------------------------------------------------

@dataclass(frozen=True)
class AppConfig:
    input_glob: str = "**/*.csv"
    keys_workbook: str = "mRNA_PLUM_Form.xlsx"
    keys_sheet: str = "KEYS"
    col_time: str = "Czas"
    col_context: str = "Kontekst zdarzenia"
    col_desc: str = "Opis"
    col_component: str = "Składnik"
    col_event_name: str = "Nazwa zdarzenia"
    course_regex: str = r"Kurs:\s*([^\s]+)"
    period_regex: str = r"(\d{4}/\d{2}[zl])"
    chunk_rows: int = 200_000


# ---------------------------------------------------------------------------
# Config — wrapper dict + dostęp atrybutowy; używany przez CLI i moduły B
# ---------------------------------------------------------------------------

class Config:
    """
    Jednolity obiekt konfiguracyjny dla całego pipeline'u B (DuckDB).

    Obsługuje dwa style dostępu:
      cfg.input_glob          — atrybuty z AppConfig (CSV layer)
      cfg.get("parse_events") — dict-style dla sekcji YAML
      cfg["hr"]               — item access (opcjonalnie)

    Używaj load_config(path) zamiast tworzyć bezpośrednio.
    """

    def __init__(self, data: Dict[str, Any]) -> None:
        self._data: Dict[str, Any] = data

        # Płaskie pola CSV-layer (kompatybilność z AppConfig)
        _csv: Dict[str, Any] = data.get("csv", data) or data
        if not isinstance(_csv, dict):
            _csv = data

        self.input_glob: str       = str(_csv.get("input_glob", "**/*.csv"))
        self.keys_workbook: str    = str(_csv.get("keys_workbook", "mRNA_PLUM_Form.xlsx"))
        self.keys_sheet: str       = str(_csv.get("keys_sheet", "KEYS"))
        self.col_time: str         = str(_csv.get("col_time", "Czas"))
        self.col_context: str      = str(_csv.get("col_context", "Kontekst zdarzenia"))
        self.col_desc: str         = str(_csv.get("col_desc", "Opis"))
        self.col_component: str    = str(_csv.get("col_component", "Składnik"))
        self.col_event_name: str   = str(_csv.get("col_event_name", "Nazwa zdarzenia"))
        self.course_regex: str     = str(_csv.get("course_regex", r"Kurs:\s*([^\s]+)"))
        self.period_regex: str     = str(_csv.get("period_regex", r"(\d{4}/\d{2}[zl])"))
        self.chunk_rows: int       = int(_csv.get("chunk_rows", 200_000))

    # ------------------------------------------------------------------
    # Dict-style API (używane przez compute_stats, export_excel itp.)
    # ------------------------------------------------------------------

    def get(self, key: str, default: Any = None) -> Any:
        return self._data.get(key, default)

    def __getitem__(self, key: str) -> Any:
        return self._data[key]

    def __contains__(self, key: str) -> bool:
        return key in self._data

    # ------------------------------------------------------------------
    # Fallback atrybutowy: cfg.parse_events -> self._data["parse_events"]
    # Nie nadpisuje jawnie zdefiniowanych atrybutów powyżej.
    # ------------------------------------------------------------------

    def __getattr__(self, name: str) -> Any:
        # Wywoływane tylko gdy normalny lookup zawiedzie.
        # Chronić przed rekursją na _data.
        if name == "_data":
            raise AttributeError(name)
        try:
            return self._data[name]
        except KeyError:
            raise AttributeError(
                f"'Config' object has no attribute '{name}' "
                f"(also not found in config dict)"
            )

    def __repr__(self) -> str:  # czytelny debug
        keys = list(self._data.keys())
        return f"<Config keys={keys}>"


# ---------------------------------------------------------------------------
# Loaders
# ---------------------------------------------------------------------------

def load_config_dict(path: Path) -> Dict[str, Any]:
    """
    Surowy YAML -> dict. Używany gdy potrzebujesz czystego słownika.
    """
    p = Path(path).resolve()
    if not p.exists():
        raise ConfigError(f"Config file not found: {p}")
    try:
        text = p.read_text(encoding="utf-8")
    except Exception as e:
        raise ConfigError(f"Cannot read config file: {p}. {e}") from e
    try:
        data = yaml.safe_load(text) or {}
    except Exception as e:
        raise ConfigError(f"Invalid YAML in config: {p}. {e}") from e
    if not isinstance(data, dict):
        raise ConfigError(f"Config root must be a mapping (dict). Got: {type(data).__name__}")
    return data


def load_config(path: Path) -> Config:
    """
    Główny loader dla CLI i pipeline'u B.
    Zwraca Config — obsługuje zarówno dostęp atrybutowy jak i dict-style.
    """
    return Config(load_config_dict(path))


def load_app_config(path: Path) -> AppConfig:
    """
    Loader dla pipeline'u A (merge/parse, CSV layer).
    Wymaga sekcji `csv:` w YAML (lub root dict dla kompatybilności wstecznej).
    """
    cfg = load_config_dict(path)
    csv_section = cfg.get("csv") or cfg
    if not isinstance(csv_section, dict):
        raise ConfigError("Config key `csv` must be a mapping (dict).")
    try:
        return AppConfig(**{
            k: v for k, v in csv_section.items()
            if k in AppConfig.__dataclass_fields__
        })
    except TypeError as e:
        raise ConfigError(f"Invalid `csv` section fields for AppConfig: {e}") from e

================================================================================
src\mrna_plum\errors.py
================================================================================

class mRnaPlumError(Exception):
    """Base app error."""


class ConfigError(mRnaPlumError):
    pass


class InputDataError(mRnaPlumError):
    pass


class MixedPeriodsError(mRnaPlumError):
    pass


class ProcessingError(mRnaPlumError):
    pass


================================================================================
src\mrna_plum\import\__init__.py
================================================================================



================================================================================
src\mrna_plum\import\import_roster.py
================================================================================

from __future__ import annotations

import csv
import json
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import duckdb

from mrna_plum.io.csv_read import detect_csv_dialect, iter_csv_rows_streaming  # masz już w projekcie


# ======================================================================================
# Helpers
# ======================================================================================

def _cfg_get(cfg: Any, path: str, default: Any = None) -> Any:
    cur = cfg
    for part in path.split("."):
        if cur is None:
            return default
        if isinstance(cur, dict):
            cur = cur.get(part, None)
        else:
            cur = getattr(cur, part, None)
    return default if cur is None else cur


def _now_ts() -> str:
    return time.strftime("%Y-%m-%d %H:%M:%S")


def _norm_int(x: Any) -> int:
    if x is None:
        return 0
    s = str(x).strip()
    if s == "":
        return 0
    # czasem CSV ma spacje albo "1 234"
    s = s.replace(" ", "").replace("\u00a0", "")
    try:
        return int(float(s))
    except Exception:
        return 0


def _pick(payload: Dict[str, str], *keys: str) -> str:
    for k in keys:
        if k in payload:
            return payload.get(k, "") or ""
    return ""


# ======================================================================================
# Schema
# ======================================================================================

def ensure_roster_tables(con: duckdb.DuckDBPyConnection) -> None:
    con.execute("CREATE SCHEMA IF NOT EXISTS stage;")
    con.execute("CREATE SCHEMA IF NOT EXISTS dim;")
    con.execute("CREATE SCHEMA IF NOT EXISTS mart;")

    con.execute(
        """
        CREATE TABLE IF NOT EXISTS stage.course_roster_raw (
            course_id                    VARCHAR,
            course_name                  VARCHAR,

            users_total                  BIGINT,
            students_total               BIGINT,
            teachers_total               BIGINT,
            teachers_no_edit             BIGINT,
            teachers_responsible         BIGINT,

            students_enrolled            BIGINT,
            students_completed           BIGINT,
            students_in_progress         BIGINT,
            students_before_start        BIGINT,

            source_file                  VARCHAR,
            loaded_at                    TIMESTAMP DEFAULT now(),
            row_key                      VARCHAR,
            payload_json                 VARCHAR
        );
        """
    )

    # 1 rekord per course_id (ostatni import wygrywa)
    con.execute(
        """
        CREATE TABLE IF NOT EXISTS dim.course_roster (
            course_id                    VARCHAR PRIMARY KEY,
            course_name                  VARCHAR,

            users_total                  BIGINT,
            students_total               BIGINT,
            teachers_total               BIGINT,
            teachers_no_edit             BIGINT,
            teachers_responsible         BIGINT,

            students_enrolled            BIGINT,
            students_completed           BIGINT,
            students_in_progress         BIGINT,
            students_before_start        BIGINT,

            source_file                  VARCHAR,
            loaded_at                    TIMESTAMP
        );
        """
    )

    con.execute(
        """
        CREATE TABLE IF NOT EXISTS mart.roster_import_qa (
            source_file      VARCHAR,
            status           VARCHAR,   -- OK / ERROR
            message          VARCHAR,
            rows_inserted    BIGINT,
            imported_at      TIMESTAMP DEFAULT now()
        );
        """
    )


def _row_key(course_id: str, course_name: str, students_enrolled: int, teachers_total: int) -> str:
    # proste i deterministyczne
    return f"{course_id}|{course_name}|{students_enrolled}|{teachers_total}"


# ======================================================================================
# Main import
# ======================================================================================

def import_course_roster_csv(
    con: duckdb.DuckDBPyConnection,
    roster_csv: Path,
) -> Tuple[int, int]:
    """
    Import CSV -> stage.course_roster_raw, then merge into dim.course_roster.
    Returns: (rows_raw_inserted, rows_dim_merged)
    """
    roster_csv = Path(roster_csv)
    if not roster_csv.exists():
        raise FileNotFoundError(roster_csv)

    ensure_roster_tables(con)

    dialect = detect_csv_dialect(roster_csv)
    rows_to_insert: List[Tuple] = []

    # oczekiwane polskie nagłówki
    for header, row in iter_csv_rows_streaming(roster_csv, dialect=dialect):
        payload = {header[i]: (row[i] if i < len(row) else "") for i in range(len(header))}

        course_id = _pick(payload, "ID kursu", "ID kursu ", "course_id").strip()
        course_name = _pick(payload, "Nazwa kursu", "course_name").strip()

        users_total = _norm_int(_pick(payload, "Użytkownicy"))
        students_total = _norm_int(_pick(payload, "Studenci"))
        teachers_total = _norm_int(_pick(payload, "Nauczyciele"))
        teachers_no_edit = _norm_int(_pick(payload, "Nauczyciele bez praw edycji"))
        teachers_responsible = _norm_int(_pick(payload, "Nauczyciele odpowiedzialny", "Nauczyciele odpowiedzialni"))

        students_enrolled = _norm_int(_pick(payload, "Studenci zapisani"))
        students_completed = _norm_int(_pick(payload, "Studenci po ukończeniu"))
        students_in_progress = _norm_int(_pick(payload, "Studenci w trakcie"))
        students_before_start = _norm_int(_pick(payload, "Studenci przed rozpocząciem", "Studenci przed rozpoczęciem"))

        # minimalny wymóg: course_id
        if course_id == "":
            continue

        rk = _row_key(course_id, course_name, students_enrolled, teachers_total)
        payload_json = json.dumps(payload, ensure_ascii=False, separators=(",", ":"))

        rows_to_insert.append(
            (
                course_id,
                course_name,
                users_total,
                students_total,
                teachers_total,
                teachers_no_edit,
                teachers_responsible,
                students_enrolled,
                students_completed,
                students_in_progress,
                students_before_start,
                str(roster_csv),
                rk,
                payload_json,
            )
        )

    # insert raw
    con.executemany(
        """
        INSERT INTO stage.course_roster_raw (
            course_id, course_name,
            users_total, students_total, teachers_total, teachers_no_edit, teachers_responsible,
            students_enrolled, students_completed, students_in_progress, students_before_start,
            source_file, row_key, payload_json
        )
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
        """,
        rows_to_insert,
    )
    rows_raw = len(rows_to_insert)

    # merge -> dim (last loaded_at wins)
    # bierzemy ostatni rekord z raw per course_id wg loaded_at (i ewentualnie rowid)
    con.execute(
        """
        INSERT OR REPLACE INTO dim.course_roster
        SELECT
            course_id,
            any_value(course_name) AS course_name,

            any_value(users_total) AS users_total,
            any_value(students_total) AS students_total,
            any_value(teachers_total) AS teachers_total,
            any_value(teachers_no_edit) AS teachers_no_edit,
            any_value(teachers_responsible) AS teachers_responsible,

            any_value(students_enrolled) AS students_enrolled,
            any_value(students_completed) AS students_completed,
            any_value(students_in_progress) AS students_in_progress,
            any_value(students_before_start) AS students_before_start,

            any_value(source_file) AS source_file,
            max(loaded_at) AS loaded_at
        FROM stage.course_roster_raw
        WHERE source_file = ?
        GROUP BY course_id;
        """,
        [str(roster_csv)],
    )

    # ile w dim “dotknięto” – przybliżenie: distinct course_id z tego pliku
    rows_dim = con.execute(
        "SELECT COUNT(DISTINCT course_id) FROM stage.course_roster_raw WHERE source_file = ?;",
        [str(roster_csv)],
    ).fetchone()[0]

    con.execute(
        "INSERT INTO mart.roster_import_qa(source_file, status, message, rows_inserted) VALUES (?, 'OK', ?, ?);",
        [str(roster_csv), f"Imported roster: {rows_raw} raw rows, {rows_dim} courses", rows_raw],
    )

    return int(rows_raw), int(rows_dim)


def build_course_facts_views(con: duckdb.DuckDBPyConnection) -> None:
    """
    Creates/updates views:
      - mart.course_roster_mapped  (course_id -> course_key + roster counts)
      - mart.course_teachers_active (teachers_active per course_key)
      - mart.course_facts (course-level facts for reporting)
    """
    con.execute("CREATE SCHEMA IF NOT EXISTS mart;")
    con.execute("CREATE SCHEMA IF NOT EXISTS dim;")

    # IMPORTANT: musisz mieć gdzieś mapę course_id -> course_key.
    # Najczęściej w pipeline to jest dim.courses(course_id, course_key, course_name) albo podobnie.
    # Tu zakładamy istnienie: dim.courses(course_id, course_key, course_name).
    con.execute(
        """
        CREATE OR REPLACE VIEW mart.course_roster_mapped AS
        SELECT
            r.course_id,
            c.course_key,
            COALESCE(c.course_name, r.course_name) AS course_name,

            COALESCE(r.students_enrolled, 0) AS students_enrolled,
            COALESCE(r.teachers_total, 0) AS teachers_enrolled,

            COALESCE(r.users_total, 0) AS users_total,
            COALESCE(r.students_total, 0) AS students_total,
            COALESCE(r.teachers_no_edit, 0) AS teachers_no_edit,
            COALESCE(r.teachers_responsible, 0) AS teachers_responsible,

            COALESCE(r.students_completed, 0) AS students_completed,
            COALESCE(r.students_in_progress, 0) AS students_in_progress,
            COALESCE(r.students_before_start, 0) AS students_before_start
        FROM dim.course_roster r
        LEFT JOIN dim.courses c
          ON c.course_id::VARCHAR = r.course_id::VARCHAR;
        """
    )

    con.execute(
        """
        CREATE OR REPLACE VIEW mart.course_teachers_active AS
        SELECT
            course_key,
            COUNT(DISTINCT teacher_id) AS teachers_active
        FROM mart.metrics_long
        WHERE visible_active = TRUE
          AND count_value > 0
          AND course_key IS NOT NULL
          AND TRIM(course_key) <> ''
        GROUP BY course_key;
        """
    )

    con.execute(
        """
        CREATE OR REPLACE VIEW mart.course_facts AS
        SELECT
            rm.course_key,
            rm.course_id,
            rm.course_name,
            rm.students_enrolled,
            rm.teachers_enrolled,
            COALESCE(ta.teachers_active, 0) AS teachers_active
        FROM mart.course_roster_mapped rm
        LEFT JOIN mart.course_teachers_active ta
          ON ta.course_key = rm.course_key;
        """
    )

================================================================================
src\mrna_plum\init_project.py
================================================================================

from __future__ import annotations
from pathlib import Path

DEFAULT_DIRS = [
    "IN/logs",
    "IN/activities",
    "OUT/logs",
    "OUT/db",
    "OUT/merged",
    "OUT/excel",
    "OUT/individual",
    "OUT/pdf",
]

def init_project(root: str | Path) -> list[Path]:
    root = Path(root).resolve()
    created: list[Path] = []
    for rel in DEFAULT_DIRS:
        p = root / rel
        if not p.exists():
            p.mkdir(parents=True, exist_ok=True)
            created.append(p)
    return created


================================================================================
src\mrna_plum\inputs\__init__.py
================================================================================



================================================================================
src\mrna_plum\inputs\autodetect.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Optional, Tuple

from mrna_plum.io.csv_read import read_csv_safely


class InputValidationError(RuntimeError):
    pass
@dataclass(frozen=True)
class DetectedInputs:
    teachers_csv: Optional[Path] = None
    roster_csv: Optional[Path] = None
    snapshot_csv: Optional[Path] = None


def _pick_latest(paths: list[Path]) -> Optional[Path]:
    if not paths:
        return None
    return max(paths, key=lambda p: p.stat().st_mtime)


def find_inputs(inputs_dir: Path) -> DetectedInputs:
    """
    Autodetekcja plików metryczki w folderze (rekurencyjnie).
    Szukamy po fragmencie nazwy (case-insensitive):
      - teachers/hr: 'nauczyciel' lub 'hr'
      - roster/uczestnicy: 'uczestnik', 'roster', 'enrol', 'zapisani'
      - snapshot/zawartosc kursow: 'zawartosc_kurs', 'snapshot', 'aktywno'
    """
    base = Path(inputs_dir).expanduser().resolve()
    if not base.exists() or not base.is_dir():
        raise InputValidationError(f"inputs_dir not found or not a folder: {base}")

    csvs = list(base.rglob("*.csv"))

    def has_any(p: Path, keys: Tuple[str, ...]) -> bool:
        n = p.name.lower()
        return any(k in n for k in keys)

    teachers = [p for p in csvs if has_any(p, ("nauczyciel", "teachers", "hr"))]
    roster = [p for p in csvs if has_any(p, ("uczestnik", "roster", "enrol", "enroll", "zapisani"))]
    snapshot = [p for p in csvs if has_any(p, ("zawartosc_kurs", "snapshot", "aktywno"))]

    return DetectedInputs(
        teachers_csv=_pick_latest(teachers),
        roster_csv=_pick_latest(roster),
        snapshot_csv=_pick_latest(snapshot),
    )

def _norm(s: str) -> str:
    # Normalizacja "odporna": małe litery, bez cudzysłowów, spacje->underscore
    return (
        str(s)
        .strip()
        .strip('"')
        .strip("'")
        .lower()
        .replace("\ufeff", "")      # BOM
        .replace("  ", " ")
        .replace(" ", "_")
        .replace("-", "_")
    )


def _build_colmap(df_cols) -> Dict[str, str]:
    # norm -> oryginalna
    m: Dict[str, str] = {}
    for c in df_cols:
        m[_norm(c)] = str(c)
    return m


def _require_cols(colmap: Dict[str, str], required_norm: Dict[str, str], file_name: str) -> Dict[str, str]:
    """
    required_norm: canonical -> normalized_expected
    returns: canonical -> original_column_name
    """
    missing = []
    out: Dict[str, str] = {}
    for canonical, expected_norm in required_norm.items():
        if expected_norm not in colmap:
            missing.append((canonical, expected_norm))
        else:
            out[canonical] = colmap[expected_norm]

    if missing:
        msg = "; ".join([f"{canon} expects '{exp}'" for canon, exp in missing])
        raise InputValidationError(f"{file_name}: missing required columns: {msg}")

    return out


def validate_and_map_teachers_hr(csv_path: Path) -> Dict[str, str]:
    """
    Twoje HR nagłówki:
    id,Pełna nazwa,E-mail,"ID bazus","Wydział jednostki zatrudnienia","Jednostka podlegajaca rozliczeniu"
    """
    df = read_csv_safely(csv_path)
    colmap = _build_colmap(df.columns)

    required = {
        "teacher_id": "id",
        "full_name": "pełna_nazwa",
        "email": "e_mail",   # bo 'E-mail' -> e_mail
    }
    mapped = _require_cols(colmap, required, csv_path.name)

    # opcjonalne:
    optional = {
        "bazus_id": "id_bazus",
        "wydzial": "wydział_jednostki_zatrudnienia",
        "jednostka": "jednostka_podlegajaca_rozliczeniu",
    }
    for canon, exp in optional.items():
        if exp in colmap:
            mapped[canon] = colmap[exp]

    return mapped


def validate_and_map_roster(csv_path: Path) -> Dict[str, str]:
    """
    Raport uczestników nagłówki:
    ID kursu,Nazwa kursu,Użytkownicy,Studenci,Nauczyciele,...,Studenci zapisani,...
    """
    df = read_csv_safely(csv_path)
    colmap = _build_colmap(df.columns)

    required = {
        "course_id": "id_kursu",
        "students_enrolled": "studenci_zapisani",
    }
    mapped = _require_cols(colmap, required, csv_path.name)

    # opcjonalne:
    optional = {
        "course_name": "nazwa_kursu",
        "students_total": "studenci",
        "teachers_total": "nauczyciele",
    }
    for canon, exp in optional.items():
        if exp in colmap:
            mapped[canon] = colmap[exp]

    return mapped


def validate_and_map_snapshot(csv_path: Path) -> Dict[str, str]:
    """
    Raport zawartości nagłówki:
    Nazwa kursu,ID kursu,Nazwa aktywności,Format aktywności,Link do aktywności,ID aktywności,...
    """
    df = read_csv_safely(csv_path)
    colmap = _build_colmap(df.columns)

    required = {
        "course_id": "id_kursu",
        "activity_id": "id_aktywności",
        "activity_name": "nazwa_aktywności",
        "activity_type": "format_aktywności",
    }
    mapped = _require_cols(colmap, required, csv_path.name)

    # opcjonalne:
    optional = {
        "course_name": "nazwa_kursu",
        "activity_link": "link_do_aktywności",
        "section_title": "tytuł_sekcji",
        "subsection_1": "tytuł_podsekcji_1",
        "subsection_2": "tytuł_podsekcji_2",
    }
    for canon, exp in optional.items():
        if exp in colmap:
            mapped[canon] = colmap[exp]

    return mapped

================================================================================
src\mrna_plum\io\__init__.py
================================================================================



================================================================================
src\mrna_plum\io\csv_read.py
================================================================================

from __future__ import annotations

import csv
import io
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Iterator, Optional, Tuple, List
import pandas as pd

def read_csv_safely(path: Path) -> pd.DataFrame:
    # logi mają polskie znaki → utf-8-sig / cp1250 bywa w praktyce
    # starter: próbujemy kilka kodowań
    encodings = ["utf-8-sig", "utf-8", "cp1250", "latin2"]
    last_err: Exception | None = None

    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc, dtype=str, low_memory=False)
        except Exception as e:
            last_err = e

    raise last_err  # type: ignore

@dataclass(frozen=True)
class CsvDialectInfo:
    delimiter: str
    encoding: str  # "utf-8-sig" lub "cp1250"


_TIME_COL_CANDIDATES = ("Czas", "Time", "Date", "TimeCreated")


def detect_encoding(path: Path) -> str:
    raw = path.read_bytes()
    sample = raw[:32768]

    if sample.startswith(b"\xef\xbb\xbf"):
        return "utf-8-sig"

    try:
        sample.decode("utf-8", errors="strict")
        return "utf-8"
    except UnicodeDecodeError:
        pass

    # najczęstsze w PL logach
    try:
        sample.decode("cp1250", errors="strict")
        return "cp1250"
    except UnicodeDecodeError:
        return "iso-8859-2"


def detect_delimiter(sample_text: str) -> str:
    """
    Wymagania: wykrywaj delimiter (TAB / ; / ,)
    Prosta i stabilna heurystyka: policz wystąpienia w pierwszych liniach.
    """
    lines = [ln for ln in sample_text.splitlines() if ln.strip()]
    head = "\n".join(lines[:20]) if lines else sample_text

    candidates = ["\t", ";", ","]
    counts = {c: head.count(c) for c in candidates}
    # Jeśli wszystko 0 -> domyślnie ';' (częste w PL)
    best = max(counts, key=lambda k: counts[k])
    return best if counts[best] > 0 else ";"


def detect_csv_dialect(path: Path) -> CsvDialectInfo:
    enc = detect_encoding(path)
    # czytaj próbkę tekstu do wykrycia delimitera
    with path.open("r", encoding=enc, errors="replace", newline="") as f:
        sample = f.read(16384)
    delim = detect_delimiter(sample)
    # jeśli enc="utf-8" bez BOM, OK; jeśli BOM był, to utf-8-sig
    if enc == "utf-8" and path.read_bytes().startswith(b"\xef\xbb\xbf"):
        enc = "utf-8-sig"
    return CsvDialectInfo(delimiter=delim, encoding=enc)


def iter_csv_rows_streaming(
    path: Path,
    *,
    dialect: Optional[CsvDialectInfo] = None,
) -> Iterator[tuple[list[str], list[str]]]:
    d = dialect or detect_csv_dialect(path)

    # Kolejność prób: najpierw to co wykryte, potem sensowne fallbacki
    enc_try = [d.encoding]
    for e in ("utf-8-sig", "utf-8", "cp1250", "latin2"):
        if e not in enc_try:
            enc_try.append(e)

    last_err: Exception | None = None

    for enc in enc_try:
        try:
            with path.open("r", encoding=enc, errors="strict", newline="") as f:
                reader = csv.reader(f, delimiter=d.delimiter)
                header: Optional[list[str]] = None

                for row in reader:
                    row = [c.strip() for c in row]
                    if not any(row):
                        continue
                    if header is None:
                        header = row
                        continue
                    yield header, row
            return  # <- cały plik przeczytany OK w tym encodingu

        except UnicodeDecodeError as e:
            last_err = e
            continue

    # jeśli nic nie zadziałało
    raise last_err  # type: ignore

def pick_time_column_index(header: list[str]) -> Optional[int]:
    """
    Rozpoznaj: "Czas" (preferowane), ale też Time/Date/TimeCreated
    """
    lowered = [h.strip().lower() for h in header]
    for cand in _TIME_COL_CANDIDATES:
        c = cand.lower()
        if c in lowered:
            return lowered.index(c)
    return None

================================================================================
src\mrna_plum\io\excel_keys.py
================================================================================

from __future__ import annotations
from dataclasses import dataclass
from pathlib import Path
from typing import List
import pandas as pd

from openpyxl import load_workbook
from ..errors import InputDataError

REQUIRED_COLS = [
    "AKTYWNOSC",
    "KLUCZ_TECHNICZNY",
    "OPERACJA",
    "LICZYC_DO_RAPORTU",
    "REGEX_DOPASOWANIA_(Opis)",
    "REGEX_USER_ID_(Opis)",
    "REGEX_OBIEKT_ID_(z dopasowania)",
    "PRIORYTET",
]

def load_keys_sheet(workbook_path: Path, sheet_name: str) -> pd.DataFrame:
    if not workbook_path.exists():
        raise InputDataError(f"KEYS workbook not found: {workbook_path}")

    wb = load_workbook(workbook_path, read_only=True, data_only=True)
    if sheet_name not in wb.sheetnames:
        raise InputDataError(f"KEYS sheet not found: {sheet_name} in {workbook_path}")

    ws = wb[sheet_name]
    rows = list(ws.values)
    if not rows:
        raise InputDataError("KEYS sheet is empty")

    header = [str(x).strip() if x is not None else "" for x in rows[0]]
    data_rows = rows[1:]
    df = pd.DataFrame(data_rows, columns=header)

    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise InputDataError(f"KEYS missing columns: {missing}")

    # normalizacja
    df = df.copy()
    df["PRIORYTET"] = pd.to_numeric(df["PRIORYTET"], errors="coerce").fillna(0).astype(int)
    df["LICZYC_DO_RAPORTU"] = df["LICZYC_DO_RAPORTU"].fillna("").astype(str).str.strip()

    # usuń puste reguły
    df = df[df["KLUCZ_TECHNICZNY"].notna() & (df["KLUCZ_TECHNICZNY"].astype(str).str.strip() != "")]
    return df.reset_index(drop=True)


================================================================================
src\mrna_plum\logging_run.py
================================================================================

from __future__ import annotations
import logging
from pathlib import Path

def setup_file_logger(log_path: Path) -> logging.Logger:
    log_path.parent.mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger("mrna_plum")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()

    fh = logging.FileHandler(log_path, encoding="utf-8")
    fmt = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    fh.setFormatter(fmt)
    logger.addHandler(fh)

    # opcjonalnie: stdout (przy CLI wygodne)
    sh = logging.StreamHandler()
    sh.setFormatter(fmt)
    logger.addHandler(sh)

    return logger


================================================================================
src\mrna_plum\merge\__init__.py
================================================================================

from mrna_plum.store.duckdb_store import open_store
from .merge_logs import merge_logs_into_duckdb

__all__ = [
    "open_store",
    "merge_logs_into_duckdb",
]

================================================================================
src\mrna_plum\merge\merge_logs.py
================================================================================

from __future__ import annotations

import json
import re
import hashlib
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterator, List, Optional

import pyarrow as pa
import pyarrow.parquet as pq

from mrna_plum.io.csv_read import detect_csv_dialect, iter_csv_rows_streaming, pick_time_column_index
from mrna_plum.store.duckdb_store import (
    ensure_schema,
    EventRawRow,
    create_stage_table,
    insert_stage_rows,
    merge_stage_into_events_raw,
    export_course_to_csv,
    export_course_to_parquet,
)

_LOG_NAME_RE = re.compile(r"^logs_(?P<course>.+?)_(?P<ts>\d{8}-\d{4})\.csv$", re.IGNORECASE)

_TIME_FORMATS = (
    # ISO / quasi-ISO
    "%Y-%m-%d %H:%M:%S",
    "%Y-%m-%d %H:%M",
    "%Y-%m-%dT%H:%M:%S",
    "%Y-%m-%dT%H:%M:%S.%f",
    "%Y-%m-%dT%H:%M",
    # PL
    "%d.%m.%Y %H:%M:%S",
    "%d.%m.%Y %H:%M",

    # Moodle/PLUM (częsty eksport): 6-11-25, 15:34:53
    "%d-%m-%y, %H:%M:%S",
    "%d-%m-%y, %H:%M",
)


def merge_logs_to_parquet(
    input_files: list[Path],
    parquet_out: Path,
    *,
    dedup_per_file: bool = True,
    row_group_size: int = 50_000,
) -> int:
    """
    Streamingowy zapis do Parquet:
    - nie używa pandas
    - nie trzyma wszystkich danych w RAM
    - dedup per plik (opcjonalnie)
    """
    parquet_out.parent.mkdir(parents=True, exist_ok=True)

    writer: Optional[pq.ParquetWriter] = None
    total_rows = 0

    try:
        for fp in input_files:
            dialect = detect_csv_dialect(fp)

            # dedup tylko w obrębie tego pliku (set resetowany per plik)
            seen: set[str] = set() if dedup_per_file else set()

            header_current: Optional[list[str]] = None
            batch_cols: dict[str, list[str]] = {}
            batch_cols["_source_file"] = []

            for header, row in iter_csv_rows_streaming(fp, dialect=dialect):
                if header_current is None:
                    header_current = header
                    for h in header_current:
                        batch_cols.setdefault(h, [])

                if dedup_per_file:
                    key = "\x1f".join(row)
                    if key in seen:
                        continue
                    seen.add(key)

                for i, h in enumerate(header):
                    batch_cols[h].append(row[i] if i < len(row) else "")
                batch_cols["_source_file"].append(str(fp))

                if len(batch_cols["_source_file"]) >= row_group_size:
                    table = pa.table(batch_cols)
                    if writer is None:
                        writer = pq.ParquetWriter(parquet_out, table.schema)
                    writer.write_table(table)
                    total_rows += table.num_rows
                    batch_cols = {k: [] for k in table.schema.names}

            if header_current is not None and len(batch_cols["_source_file"]) > 0:
                table = pa.table(batch_cols)
                if writer is None:
                    writer = pq.ParquetWriter(parquet_out, table.schema)
                writer.write_table(table)
                total_rows += table.num_rows

        if writer is None:
            empty = pa.table({})
            pq.write_table(empty, parquet_out)

        return total_rows

    finally:
        if writer is not None:
            writer.close()


def _parse_time_to_iso(value: str) -> Optional[str]:
    v = value.strip()
    if not v:
        return None

    try:
        dt = datetime.fromisoformat(v.replace("Z", "+00:00"))
        return dt.isoformat()
    except Exception:
        pass

    for fmt in _TIME_FORMATS:
        try:
            dt = datetime.strptime(v, fmt)
            return dt.isoformat(sep="T")
        except Exception:
            continue
    return None


def _normalize_fields_key(fields: List[str]) -> str:
    """
    Dedup: CAŁY wiersz identyczny po Trim (reader trimuje).
    Stabilny hash niezależny od delimitera.
    """
    joined = "\x1f".join(fields)
    return hashlib.sha256(joined.encode("utf-8")).hexdigest()


def iter_log_files(root: Path, pattern: str = "*.csv") -> Iterator[Path]:
    for p in root.rglob(pattern):
        if p.is_file():
            yield p


def group_logs_by_course(root: Path) -> Dict[str, List[Path]]:
    grouped: Dict[str, List[Path]] = {}
    for p in iter_log_files(root):
        m = _LOG_NAME_RE.match(p.name)
        if not m:
            continue
        course = m.group("course")
        grouped.setdefault(course, []).append(p)

    # stabilne sortowanie po nazwie (timestamp jest w nazwie)
    for course in list(grouped.keys()):
        grouped[course].sort(key=lambda x: x.name)
    return grouped


@dataclass(frozen=True)
class MergeLogsResult:
    courses: int
    files: int
    inserted_rows: int


def merge_logs_into_duckdb(
    *,
    root: Path,
    con,  # duckdb connection
    export_mode: str = "duckdb",  # "duckdb" | "parquet" | "csv"
    export_dir: Optional[Path] = None,
    chunk_size: int = 2000,
) -> MergeLogsResult:
    """
    Publiczny entrypoint zgodny z testami/CLI.

    - root: folder z logami logs_<KURS>_<YYYYMMDD-HHMM>.csv (rekurencyjnie)
    - export_mode: "duckdb" (domyślnie) lub "csv"/"parquet"
    - export_dir: wymagany dla "csv"/"parquet"
    - chunk_size: batch insert do stage
    """
    export_mode = (export_mode or "duckdb").lower().strip()
    if export_mode not in ("duckdb", "csv", "parquet"):
        raise ValueError(f"export_mode must be 'duckdb'|'csv'|'parquet', got: {export_mode}")

    if export_mode in ("csv", "parquet") and export_dir is None:
        raise ValueError("export_dir is required for export_mode=csv/parquet")

    return _merge_logs_into_duckdb_impl(
        root=root,
        con=con,
        export_mode=export_mode,
        export_dir=export_dir,
        chunk_size=chunk_size,
    )

_COURSE_ID_PATTERNS = [
    # najczęstsze w Moodle logs (EN)
    re.compile(r"course with id\s+'(\d+)'", re.IGNORECASE),
    re.compile(r"course with id\s+(\d+)", re.IGNORECASE),

    # czasem bez apostrofów
    re.compile(r"\bcourse id\b\s*[:=]?\s*(\d+)", re.IGNORECASE),

    # PL warianty (na wszelki wypadek)
    re.compile(r"\bid kursu\b\s*[:=]?\s*(\d+)", re.IGNORECASE),
]


def _extract_course_id_from_payload(payload: Dict[str, str]) -> Optional[int]:
    """
    Szukamy course_id głównie w polu 'Opis' (czasem 'Description'),
    ale dla bezpieczeństwa przeszukujemy też cały payload.
    """
    candidates: List[str] = []

    # preferowane pola
    for k in ("Opis", "Description", "Event description", "Nazwa zdarzenia", "Kontekst zdarzenia"):
        v = payload.get(k)
        if v:
            candidates.append(v)

    # fallback: cały payload (join wartości)
    if not candidates:
        candidates.append(" | ".join([v for v in payload.values() if v]))

    text = " \n ".join(candidates)

    for rx in _COURSE_ID_PATTERNS:
        m = rx.search(text)
        if m:
            try:
                return int(m.group(1))
            except Exception:
                return None
    return None

def _merge_logs_into_duckdb_impl(
    *,
    root: Path,
    con,
    export_mode: str,
    export_dir: Optional[Path],
    chunk_size: int,
) -> MergeLogsResult:
    """
    Rdzeń logiki scalania.
    """
    try:
        ensure_schema(con)
        grouped = group_logs_by_course(root)
        if not grouped:
            raise RuntimeError(
                f"No log files matched pattern logs_<COURSE>_<YYYYMMDD-HHMM>.csv under root={root}"
            )
        total_files = sum(len(v) for v in grouped.values())
        total_inserted = 0

        for course, files in grouped.items():
            create_stage_table(con)
            buf: List[EventRawRow] = []

            for fpath in files:
                dialect = detect_csv_dialect(fpath)

                time_idx: Optional[int] = None
                header_ref: Optional[List[str]] = None

                for header, row in iter_csv_rows_streaming(fpath, dialect=dialect):
                    if header_ref is None:
                        header_ref = header
                        time_idx = pick_time_column_index(header_ref)

                    payload = {header[i]: (row[i] if i < len(row) else "") for i in range(len(header))}
                    payload_json = json.dumps(payload, ensure_ascii=False, separators=(",", ":"))
                    course_id = _extract_course_id_from_payload(payload)

                    time_text = None
                    time_iso = None
                    if time_idx is not None and time_idx < len(row):
                        time_text = row[time_idx]
                        time_iso = _parse_time_to_iso(time_text)

                    row_key = _normalize_fields_key(row)

                    buf.append(
                        EventRawRow(
                            course=course,
                            course_id=course_id,
                            time_text=time_text,
                            time_ts_iso=time_iso,
                            row_key=row_key,
                            payload_json=payload_json,
                            source_file=str(fpath),
                        )
                    )

                    if len(buf) >= chunk_size:
                        insert_stage_rows(con, buf)
                        buf.clear()

            if buf:
                insert_stage_rows(con, buf)
                buf.clear()

            inserted = merge_stage_into_events_raw(con)
            total_inserted += inserted

            if export_mode in ("csv", "parquet"):
                assert export_dir is not None
                export_dir.mkdir(parents=True, exist_ok=True)

                if export_mode == "csv":
                    out_csv = export_dir / f"{course}_full_log.csv"
                    export_course_to_csv(con, course=course, out_csv=out_csv)
                else:
                    out_pq = export_dir / f"{course}_full_log.parquet"
                    export_course_to_parquet(con, course=course, out_parquet=out_pq)

        return MergeLogsResult(courses=len(grouped), files=total_files, inserted_rows=total_inserted)

    except UnicodeDecodeError as e:
        # Bezpieczny komunikat (bez ryzyka UnboundLocalError)
        raise RuntimeError(f"UnicodeDecodeError while reading CSV under root={root}") from e


__all__ = ["merge_logs_into_duckdb", "MergeLogsResult", "merge_logs_to_parquet"]

================================================================================
src\mrna_plum\merge\test_merge_logs.py
================================================================================

from __future__ import annotations

import csv
from pathlib import Path

import duckdb
import pytest

from mrna_plum.store.duckdb_store import open_store
from mrna_plum.merge.merge_logs import merge_logs_to_parquet
from mrna_plum.merge.merge_logs import merge_logs_into_duckdb, MergeLogsResult


def _write_csv_bytes(path: Path, data: bytes) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(data)


def _make_logs_name(course: str, ts: str) -> str:
    return f"logs_{course}_{ts}.csv"


def test_bom_utf8_and_delimiter_detection_and_insert(tmp_path: Path):
    root = tmp_path / "logs"
    db = tmp_path / "db.duckdb"

    # UTF-8 with BOM, delimiter ';'
    content = (
        "\ufeffCzas;Akcja;Opis\n"
        "2026-02-18 10:00:00;ADD;Zażółć gęślą\n"
    ).encode("utf-8")

    _write_csv_bytes(root / _make_logs_name("KURS1", "20260218-1000"), content)

    con = open_store(db)
    try:
        res = merge_logs_into_duckdb(root=root, con=con, export_mode="duckdb")
        assert res.courses == 1
        assert res.files == 1
        assert res.inserted_rows == 1

        row = con.execute(
            "SELECT course, payload_json FROM events_raw WHERE course='KURS1'"
        ).fetchone()
        assert row[0] == "KURS1"
        assert "Zażółć gęślą" in row[1]
    finally:
        con.close()


def test_windows_1250_polish_chars(tmp_path: Path):
    root = tmp_path / "logs"
    db = tmp_path / "db.duckdb"

    # cp1250, delimiter TAB
    text = "Czas\tAkcja\tOpis\n2026-02-18 10:00:00\tADD\tŚliwka w kompot\n"
    _write_csv_bytes(root / _make_logs_name("KURS2", "20260218-1000"), text.encode("cp1250"))

    con = open_store(db)
    try:
        res = merge_logs_into_duckdb(root=root, con=con, export_mode="duckdb")
        assert res.inserted_rows == 1

        payload = con.execute(
            "SELECT payload_json FROM events_raw WHERE course='KURS2'"
        ).fetchone()[0]
        assert "Śliwka w kompot" in payload
    finally:
        con.close()


def test_dedup_identical_whole_row_after_trim(tmp_path: Path):
    root = tmp_path / "logs"
    db = tmp_path / "db.duckdb"

    # dwa pliki, ten sam wiersz różniący się tylko spacingiem -> po trim ma być 1 wpis
    c1 = (
        "Czas;Akcja;Opis\n"
        "2026-02-18 10:00:00;ADD;  Duplikat  \n"
    ).encode("utf-8")
    c2 = (
        "Czas;Akcja;Opis\n"
        "2026-02-18 10:00:00;ADD;Duplikat\n"
    ).encode("utf-8")

    _write_csv_bytes(root / _make_logs_name("KURS3", "20260218-1000"), c1)
    _write_csv_bytes(root / _make_logs_name("KURS3", "20260218-1001"), c2)

    con = open_store(db)
    try:
        res = merge_logs_into_duckdb(root=root, con=con, export_mode="duckdb")
        assert res.inserted_rows == 1

        cnt = con.execute("SELECT COUNT(*) FROM events_raw WHERE course='KURS3'").fetchone()[0]
        assert cnt == 1
    finally:
        con.close()


def test_sorting_desc_by_time_on_export_csv(tmp_path: Path):
    root = tmp_path / "logs"
    db = tmp_path / "db.duckdb"
    out_dir = tmp_path / "out"

    # kolejność w pliku: starszy potem nowszy (celowo)
    content = (
        "Czas;Akcja;Opis\n"
        "2026-02-18 09:00:00;ADD;A\n"
        "2026-02-18 10:00:00;ADD;B\n"
    ).encode("utf-8")

    _write_csv_bytes(root / _make_logs_name("KURS4", "20260218-1000"), content)

    con = open_store(db)
    try:
        res = merge_logs_into_duckdb(root=root, con=con, export_mode="csv", export_dir=out_dir)
        assert res.inserted_rows == 2

        out_csv = out_dir / "KURS4_full_log.csv"
        assert out_csv.exists()

        # W eksporcie ma być B przed A (czas malejąco)
        rows = out_csv.read_text(encoding="utf-8").splitlines()
        # Header w COPY jest: course;time_text;time_ts;payload_json;source_file
        assert len(rows) >= 3
        assert '"B"' in rows[1] or "B" in rows[1]
        assert '"A"' in rows[2] or "A" in rows[2]
    finally:
        con.close()


================================================================================
src\mrna_plum\parse\__init__.py
================================================================================

from .parse_logs import parse_merged_parquet
__all__ = ["parse_merged_parquet"]


================================================================================
src\mrna_plum\parse\context.py
================================================================================

from __future__ import annotations
import re
from dataclasses import dataclass
from typing import Optional

@dataclass(frozen=True)
class ContextInfo:
    course_code: Optional[str]
    period: Optional[str]

def parse_context(context: str, course_regex: str, period_regex: str) -> ContextInfo:
    course = None
    period = None

    cm = re.search(course_regex, context or "")
    if cm:
        course = cm.group(1)

    pm = re.search(period_regex, context or "")
    if pm:
        period = pm.group(1)

    return ContextInfo(course_code=course, period=period)


================================================================================
src\mrna_plum\parse\parse_events.py
================================================================================

# src/mrna_plum/parse/parse_events.py

from __future__ import annotations

import json
import os
import re
import sys
from dataclasses import asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import pandas as pd

from mrna_plum.rules.activity_rules import ActivityRuleEngine, load_keys_rules
from mrna_plum.store.database import EventStore


COURSE_CTX_RX = re.compile(
    r"Kurs:\s*(?P<course_code>[A-Z]{1,3}/[A-Za-z]{1,6}/[A-Za-z0-9_]+/(?P<semester>\d+sem)-(?P<name>.+?)-(?P<ay>\d{4}/\d{2})(?P<term>[zl])",
    re.IGNORECASE,
)

# fallback, jeśli czas nieparsowalny
def parse_ts_to_utc(s: str) -> Optional[datetime]:
    if not s:
        return None
    s = str(s).strip()
    if not s:
        return None
    # epoch?
    if s.isdigit():
        try:
            x = int(s)
            if x > 10_000_000_000:
                x //= 1000
            return datetime.fromtimestamp(x, tz=timezone.utc)
        except Exception:
            return None
    try:
        ts = pd.to_datetime(s, utc=True, errors="coerce")
        if pd.isna(ts):
            return None
        return ts.to_pydatetime()
    except Exception:
        return None


def parse_course_context(kontekst: str) -> Optional[Dict[str, str]]:
    if not kontekst:
        return None
    m = COURSE_CTX_RX.search(kontekst)
    if not m:
        return None
    gd = m.groupdict()
    course_code = gd["course_code"]
    parts = course_code.split("/")
    # WF/An/stj/5sem-...
    wydzial = parts[0] if len(parts) > 0 else ""
    kierunek = parts[1] if len(parts) > 1 else ""
    track = parts[2] if len(parts) > 2 else ""

    return {
        "course_code": course_code,
        "wydzial_code": wydzial,
        "kierunek_code": kierunek,
        "track_code": track,
        "semester_code": gd.get("semester", ""),
        "course_name": gd.get("name", "").strip(),
        "ay": gd.get("ay", ""),
        "term": gd.get("term", "").lower(),
    }


def ensure_run_paths(root: Path) -> Dict[str, Path]:
    run_dir = root / "_run"
    run_dir.mkdir(parents=True, exist_ok=True)
    return {
        "run_dir": run_dir,
        "run_log": run_dir / "run.log",
        "progress": run_dir / "progress.jsonl",
        "ok": run_dir / "parse.ok",
    }


class RunLogger:
    def __init__(self, run_log: Path, progress: Path):
        self.run_log = run_log
        self.progress = progress

    def log(self, msg: str) -> None:
        line = f"{datetime.now().isoformat(timespec='seconds')} {msg}\n"
        self.run_log.open("a", encoding="utf-8").write(line)

    def progress_event(self, obj: Dict[str, Any]) -> None:
        self.progress.open("a", encoding="utf-8").write(json.dumps(obj, ensure_ascii=False) + "\n")


def _cfg_filters(cfg: Dict[str, Any]) -> Dict[str, Any]:
    f = cfg.get("filters", {}) or {}
    parse_cfg = cfg.get("parse_events", {}) or {}
    # dopuszczamy override w parse_events.*
    return {**f, **(parse_cfg.get("filters") or {})}


def _is_student_email(payload: Dict[str, Any], student_domain: str) -> bool:
    # payload może mieć różne kolumny; przeszukaj wszystkie wartości z '@'
    domain = student_domain.lower().strip()
    if not domain:
        return False
    blob = " ".join([str(v) for v in payload.values() if v is not None])
    return domain in blob.lower()


def _source_allowed(payload: Dict[str, Any], allowed_sources: List[str], blocked_sources: List[str]) -> bool:
    src = str(payload.get("Źródło") or payload.get("Zrodlo") or payload.get("Source") or "").strip()
    if blocked_sources and any(b.lower() in src.lower() for b in blocked_sources):
        return False
    if allowed_sources:
        return any(a.lower() in src.lower() for a in allowed_sources)
    return True


def _techkey_allowed(tech_key: str, wl: List[str], bl: List[str]) -> bool:
    if bl and tech_key in bl:
        return False
    if wl and tech_key not in wl:
        return False
    return True


def _date_allowed(ts: datetime, date_from: Optional[str], date_to: Optional[str]) -> bool:
    if date_from:
        d1 = pd.to_datetime(date_from, utc=True, errors="coerce")
        if not pd.isna(d1) and ts < d1.to_pydatetime():
            return False
    if date_to:
        d2 = pd.to_datetime(date_to, utc=True, errors="coerce")
        if not pd.isna(d2) and ts > d2.to_pydatetime():
            return False
    return True


def run_parse_events(
    cfg: Dict[str, Any],
    root: str,
    keys_xlsx_override: Optional[str] = None,
) -> int:
    """
    Exit codes:
      0 = OK
      2 = mixed periods
      1 = other error
    """
    root_p = Path(root)
    paths = ensure_run_paths(root_p)
    logger = RunLogger(paths["run_log"], paths["progress"])

    try:
        logger.log("[PARSE] start parse-events")
        store = EventStore(cfg)
        store.ensure_schema()

        # KEYS
        keys_cfg = cfg.get("parse_events", {}) or {}

        # 1️ priorytet: CLI override
        keys_xlsx = keys_xlsx_override

        # 2️ fallback: config.yaml
        if not keys_xlsx:
            keys_xlsx = keys_cfg.get("keys_xlsx")

        if not keys_xlsx:
            raise ValueError(
                "Brak KEYS: podaj --keys-xlsx lub ustaw parse_events.keys_xlsx w config.yaml"
            )

        # jeśli w config używasz {root}
        if "{root}" in keys_xlsx:
            keys_xlsx = keys_xlsx.replace("{root}", root)

        keys_sheet = keys_cfg.get("keys_sheet", "KEYS")
        rules = load_keys_rules(keys_xlsx, sheet_name=keys_sheet)
        engine = ActivityRuleEngine(rules, drop_mode_nie=True)
        logger.log(f"[PARSE] loaded KEYS rules: {len(rules)}")

        # filtry
        fil = _cfg_filters(cfg)
        student_domain = (fil.get("student_email_domain") or "@student.umw.edu.pl").lower()
        tech_wl = fil.get("tech_key_whitelist") or []
        tech_bl = fil.get("tech_key_blacklist") or []
        allowed_sources = fil.get("source_whitelist") or []
        blocked_sources = fil.get("source_blacklist") or []
        date_from = fil.get("date_from")
        date_to = fil.get("date_to")

        # DuckDB streaming z events_raw
        import duckdb
        con = duckdb.connect(str(Path(cfg["paths"]["db_path"])))
        con.execute("PRAGMA enable_progress_bar=false;")

        # incremental: bierz tylko te, których row_key nie ma w canonical_raw
        query = """
            SELECT course, time_text, time_ts_iso, row_key, payload_json, source_file
            FROM events_raw r
            WHERE NOT EXISTS (SELECT 1 FROM events_canonical_raw c WHERE c.row_key = r.row_key)
        """
        cur = con.execute(query)

        batch: List[Dict[str, Any]] = []
        conf_batch: List[Dict[str, Any]] = []

        seen_period: Optional[Tuple[str, str]] = None  # (ay, term)
        mixed_period = False

        total_read = 0
        total_matched = 0
        total_inserted = 0

        FETCH = int(keys_cfg.get("fetch_size", 5000))
        INSERT_BATCH = int(keys_cfg.get("insert_batch_size", 20000))

        while True:
            rows = cur.fetchmany(FETCH)
            if not rows:
                break

            for course, time_text, time_ts_iso, row_key, payload_json, source_file in rows:
                total_read += 1

                # payload
                try:
                    payload = json.loads(payload_json)
                except Exception:
                    continue

                # źródło filter
                if not _source_allowed(payload, allowed_sources, blocked_sources):
                    continue

                # student filter
                if student_domain and _is_student_email(payload, student_domain):
                    continue

                # czas
                ts = None
                if time_ts_iso:
                    try:
                        ts = pd.to_datetime(time_ts_iso, utc=True, errors="coerce")
                        ts = None if pd.isna(ts) else ts.to_pydatetime()
                    except Exception:
                        ts = None
                if ts is None:
                    ts = parse_ts_to_utc(str(payload.get("Czas") or payload.get("Time") or payload.get("Date") or time_text or ""))
                if ts is None:
                    continue

                if not _date_allowed(ts, date_from, date_to):
                    continue

                # kontekst kursu
                kontekst = str(payload.get("Kontekst zdarzenia") or payload.get("Event context") or "")
                ctx = parse_course_context(kontekst)
                if not ctx:
                    continue

                # okres: ay+term
                period = (ctx["ay"], ctx["term"])
                if seen_period is None:
                    seen_period = period
                elif period != seen_period:
                    mixed_period = True
                    # logujemy i kończymy po batchu
                    logger.log(f"[PARSE][ERR] mixed periods: first={seen_period} next={period} row_key={row_key}")
                    break

                # opis (KEYS dopasowanie)
                opis = str(payload.get("Opis") or payload.get("Description") or "")
                m = engine.match(opis)
                if not m:
                    continue  # aktywności spoza KEYS → pomijamy

                # whitelist/blacklist tech_key
                if not _techkey_allowed(m.tech_key, tech_wl, tech_bl):
                    continue

                total_matched += 1

                if m.conflict:
                    conf_batch.append(
                        {
                            "row_key": row_key,
                            "course_code": ctx["course_code"],
                            "teacher_id": m.teacher_id,
                            "tech_key": m.tech_key,
                            "operation": m.operation,
                            "object_id": m.object_id,
                            "note": f"KEYS conflict: multiple matches with same priority={m.priority}",
                        }
                    )

                row = {
                    "row_key": row_key,
                    "course": course,
                    "course_code": ctx["course_code"],
                    "wydzial_code": ctx["wydzial_code"],
                    "kierunek_code": ctx["kierunek_code"],
                    "track_code": ctx["track_code"],
                    "semester_code": ctx["semester_code"],
                    "course_name": ctx["course_name"],
                    "ay": ctx["ay"],
                    "term": ctx["term"],
                    "ts_utc": ts,
                    "teacher_id": m.teacher_id,
                    "operation": m.operation,
                    "tech_key": m.tech_key,
                    "activity_label": m.activity_label,
                    "object_id": m.object_id,
                    "count_mode": m.count_mode,
                    "raw_line_hash": row_key,  # row_key już jest hashem całego wiersza po trim
                    "source_file": source_file,
                    "payload_json": payload_json,
                }
                batch.append(row)

                if len(batch) >= INSERT_BATCH:
                    total_inserted += store.insert_raw_batch(batch)
                    batch.clear()
                if len(conf_batch) >= 2000:
                    store.insert_conflicts_batch(conf_batch)
                    conf_batch.clear()

            if mixed_period:
                break

            # progress co chunk
            if total_read % (FETCH * 2) == 0:
                logger.progress_event(
                    {
                        "stage": "parse-events",
                        "read": total_read,
                        "matched": total_matched,
                        "inserted_raw": total_inserted,
                        "period": {"ay": seen_period[0], "term": seen_period[1]} if seen_period else None,
                    }
                )

        if batch:
            total_inserted += store.insert_raw_batch(batch)
            batch.clear()
        if conf_batch:
            store.insert_conflicts_batch(conf_batch)
            conf_batch.clear()

        con.close()

        if mixed_period:
            logger.log("[PARSE][ERR] mixed periods -> abort")
            return 2

        # finalize counted/unieważnienia
        store.finalize_canonical()
        pq = store.export_parquet() if (cfg.get("parse_events", {}) or {}).get("export_parquet", False) else None

        paths["ok"].write_text("OK\n", encoding="utf-8")
        logger.log(f"[PARSE] OK read={total_read} matched={total_matched} inserted_raw={total_inserted} parquet={pq}")
        logger.progress_event(
            {
                "stage": "parse-events",
                "status": "ok",
                "read": total_read,
                "matched": total_matched,
                "inserted_raw": total_inserted,
                "period": {"ay": seen_period[0], "term": seen_period[1]} if seen_period else None,
            }
        )
        return 0

    except Exception as e:
        logger.log(f"[PARSE][ERR] {type(e).__name__}: {e}")
        return 1

================================================================================
src\mrna_plum\parse\parse_logs.py
================================================================================

from __future__ import annotations
from pathlib import Path
import pandas as pd

from mrna_plum.config import AppConfig
from mrna_plum.errors import MixedPeriodsError, ProcessingError
from mrna_plum.rules.engine import match_best_rule
from .context import parse_context

def parse_merged_parquet(
    parquet_in: Path,
    parquet_out: Path,
    config: AppConfig,
    rules: list,
) -> tuple[int, str | None]:
    df = pd.read_parquet(parquet_in)
    if df.empty:
        parquet_out.parent.mkdir(parents=True, exist_ok=True)
        df.to_parquet(parquet_out, index=False)
        return 0, None

    # wymagane kolumny
    need = [config.col_time, config.col_context, config.col_desc, config.col_component, config.col_event_name]
    missing = [c for c in need if c not in df.columns]
    if missing:
        raise ProcessingError(f"Missing required CSV columns: {missing}")

    # wyciągnij kontekst (kurs, okres)
    ctx = df[config.col_context].astype(str).apply(lambda x: parse_context(x, config.course_regex, config.period_regex))
    df["course_code"] = ctx.apply(lambda c: c.course_code)
    df["period"] = ctx.apply(lambda c: c.period)

    # mixed periods check (ignorujemy None)
    periods = sorted({p for p in df["period"].dropna().unique().tolist() if str(p).strip() != ""})
    if len(periods) > 1:
        raise MixedPeriodsError(f"mixed periods detected: {periods}")
    run_period = periods[0] if periods else None

    # dopasuj regułę po opisie
    tech_keys = []
    activities = []
    operations = []
    count_flags = []
    teacher_ids = []
    object_ids = []
    matched_prio = []

    for desc in df[config.col_desc].astype(str).tolist():
        m = match_best_rule(desc, rules)
        if m is None:
            tech_keys.append(None)
            activities.append(None)
            operations.append(None)
            count_flags.append(False)
            teacher_ids.append(None)
            object_ids.append(None)
            matched_prio.append(None)
        else:
            tech_keys.append(m.tech_key)
            activities.append(m.activity)
            operations.append(m.operation)
            count_flags.append(bool(m.count_to_report))
            teacher_ids.append(m.teacher_id)
            object_ids.append(m.object_id)
            matched_prio.append(m.priority)

    df["tech_key"] = tech_keys
    df["activity"] = activities
    df["operation"] = operations
    df["count_to_report"] = count_flags
    df["teacher_id"] = teacher_ids
    df["object_id"] = object_ids
    df["rule_priority"] = matched_prio

    parquet_out.parent.mkdir(parents=True, exist_ok=True)
    df.to_parquet(parquet_out, index=False)
    return len(df), run_period


================================================================================
src\mrna_plum\paths.py
================================================================================

from dataclasses import dataclass
from pathlib import Path

@dataclass(frozen=True)
class ProjectPaths:
    root: Path

    @property
    def run_dir(self) -> Path:
        return self.root / "_run"

    @property
    def data_dir(self) -> Path:
        return self.root / "_data"

    @property
    def parquet_dir(self) -> Path:
        return self.data_dir / "parquet"

    @property
    def duckdb_path(self) -> Path:
        return self.data_dir / "mrna_plum.duckdb"

    @property
    def markers_dir(self) -> Path:
        return self.run_dir

    def marker_path(self, step: str) -> Path:
        return self.markers_dir / f"{step}.ok"


================================================================================
src\mrna_plum\reports\__init__.py
================================================================================

from .export_excel import export_summary_excel, ExportOverflowError


__all__ = ["export_summary_excel", "ExportOverflowError"]

================================================================================
src\mrna_plum\reports\export_excel.py
================================================================================

from __future__ import annotations

import json
import logging
import math
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple

# xlsxwriter is used directly (fast, pyinstaller-friendly)
import xlsxwriter


# ===== Exit codes (align with project) =====
EXIT_OK = 0
EXIT_OVERFLOW = 30


@dataclass(frozen=True)
class ExportExcelConfig:
    max_rows_excel: int = 1_000_000
    overflow_strategy: str = "error"  # error | split | skip
    activity_column: str = "activity_label"  # NOW default
    course_column: str = "course_name"       # NOW default

    include_hr_cols: bool = True
    exclude_zero_counts: bool = True
    percent_excel_format: bool = True

class ExportExcelError(RuntimeError):
    pass


class ExportOverflowError(ExportExcelError):
    """Raised when row-count exceeds Excel limit and strategy=error."""
    pass


def _ensure_dirs(root: Path) -> Tuple[Path, Path]:
    run_dir = root / "_run"
    out_dir = root / "_out"
    run_dir.mkdir(parents=True, exist_ok=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    return run_dir, out_dir


def _setup_logger(run_dir: Path) -> logging.Logger:
    logger = logging.getLogger("mrna_plum.export_excel")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()

    fh = logging.FileHandler(run_dir / "run.log", encoding="utf-8")
    fmt = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    fh.setFormatter(fmt)
    logger.addHandler(fh)

    # optional console handler (kept minimal)
    sh = logging.StreamHandler()
    sh.setFormatter(fmt)
    logger.addHandler(sh)

    return logger


def _progress_append(run_dir: Path, event: Dict[str, Any]) -> None:
    p = run_dir / "progress.jsonl"
    event = dict(event)
    event["ts"] = datetime.now(timezone.utc).isoformat()
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")


def _duckdb_has_column(con, table_fqn: str, col: str) -> bool:
    # Works for DuckDB: INFORMATION_SCHEMA.COLUMNS
    sql = """
        SELECT 1
        FROM information_schema.columns
        WHERE table_schema = ? AND table_name = ? AND column_name = ?
        LIMIT 1
    """
    if "." in table_fqn:
        schema, name = table_fqn.split(".", 1)
    else:
        schema, name = "main", table_fqn
    row = con.execute(sql, [schema, name, col]).fetchone()
    return row is not None


def _select_metrics_long_sql(con, activity_col: str, course_col: str,
                            include_hr_cols: bool, exclude_zero_counts: bool,
                            percent_excel_format: bool) -> str:
    table = "mart.metrics_long"

    # activity_label fallback
    if activity_col == "activity_label" and not _duckdb_has_column(con, table, "activity_label"):
        activity_col = "tech_key"

    # course_name fallback
    if course_col == "course_name" and not _duckdb_has_column(con, table, "course_name"):
        course_col = "course_code"

    pct_course = "pct_course" if _duckdb_has_column(con, table, "pct_course") else "NULL"
    pct_program = "pct_program" if _duckdb_has_column(con, table, "pct_program") else "NULL"
    pct_faculty = "pct_faculty" if _duckdb_has_column(con, table, "pct_faculty") else "NULL"
    pct_university = "pct_university" if _duckdb_has_column(con, table, "pct_university") else "NULL"

    # Excel %: zapisujemy ułamek (12.3 -> 0.123)
    def pct_expr(expr: str) -> str:
        if expr == "NULL":
            return "NULL"
        return f"({expr} / 100.0)" if percent_excel_format else expr

    pct_course_e = pct_expr(pct_course)
    pct_program_e = pct_expr(pct_program)
    pct_faculty_e = pct_expr(pct_faculty)
    pct_university_e = pct_expr(pct_university)

    order_course = "course_code" if _duckdb_has_column(con, table, "course_code") else course_col
    order_tech = "tech_key" if _duckdb_has_column(con, table, "tech_key") else activity_col

    where_parts = []
    if _duckdb_has_column(con, table, "visible_active"):
        where_parts.append("visible_active")
    if exclude_zero_counts and _duckdb_has_column(con, table, "count_value"):
        where_parts.append("count_value <> 0")

    where_clause = f"WHERE {' AND '.join(where_parts)}" if where_parts else ""

    # HR columns (optional, only if present)
    hr_cols = []
    if include_hr_cols:
        for col in ("hr_faculty", "hr_unit", "hr_department", "hr_org"):
            if _duckdb_has_column(con, table, col):
                hr_cols.append(f"{col}::VARCHAR AS {col}")

    hr_select = (",\n            " + ",\n            ".join(hr_cols)) if hr_cols else ""

    sql = f"""
        SELECT
            full_name::VARCHAR AS full_name,
            teacher_id::VARCHAR AS teacher_id{hr_select},
            {course_col}::VARCHAR AS course_value,
            {activity_col}::VARCHAR AS activity_value,
            count_value::BIGINT AS count_value,
            {pct_course_e}::DOUBLE AS pct_course,
            {pct_program_e}::DOUBLE AS pct_program,
            {pct_faculty_e}::DOUBLE AS pct_faculty,
            {pct_university_e}::DOUBLE AS pct_university,
            {order_tech}::VARCHAR AS _order_tech
        FROM {table}
        {where_clause}
        ORDER BY
            full_name ASC,
            {order_course} ASC,
            {order_tech} ASC
    """
    return sql


def _count_rows(con, base_sql: str) -> int:
    # Wrap in subquery; DuckDB handles it well.
    sql = f"SELECT COUNT(*)::BIGINT FROM ({base_sql}) t"
    return int(con.execute(sql).fetchone()[0])


def _select_metrics_qa_sql(con) -> str:
    table = "mart.metrics_qa"
    # Minimal required columns; if missing -> NULL
    type_col = "type" if _duckdb_has_column(con, table, "type") else "NULL"
    teacher_id = "teacher_id" if _duckdb_has_column(con, table, "teacher_id") else "NULL"
    course_code = "course_code" if _duckdb_has_column(con, table, "course_code") else "NULL"
    tech_key = "tech_key" if _duckdb_has_column(con, table, "tech_key") else "NULL"
    description = "description" if _duckdb_has_column(con, table, "description") else "NULL"

    sql = f"""
        SELECT
            {type_col}::VARCHAR AS type,
            {teacher_id}::VARCHAR AS teacher_id,
            {course_code}::VARCHAR AS course_code,
            {tech_key}::VARCHAR AS tech_key,
            {description}::VARCHAR AS description
        FROM {table}
        ORDER BY type ASC, teacher_id ASC, course_code ASC, tech_key ASC
    """
    return sql


def _write_sheet_header(ws, header_fmt, headers: Sequence[str]) -> None:
    ws.write_row(0, 0, list(headers), header_fmt)
    ws.freeze_panes(1, 0)


def _iter_cursor_rows(cur, batch_size: int) -> Iterable[Tuple[Any, ...]]:
    while True:
        rows = cur.fetchmany(batch_size)
        if not rows:
            break
        for r in rows:
            yield r


def _write_metrics_long_split_streaming(
    workbook: xlsxwriter.Workbook,
    con,
    sql: str,
    max_rows: int,
    overflow_strategy: str,
    main_sheet_base: str,
    logger: logging.Logger,
) -> Tuple[int, int]:
    """
    Stream rows from DuckDB and write to one or multiple sheets.
    Returns: (written_rows, sheets_count) excluding header row.
    """
    headers = [
        "Użytkownik",
        "ID",
        "Kurs",
        "Aktywność",
        "Liczba",
        "% kurs",
        "% kierunek",
        "% wydział",
        "% uczelnia",
    ]

    header_fmt = workbook.add_format({"bold": True, "border": 1})
    # Percent format: number with 1 decimal place, NOT Excel percentage
    pct_fmt = workbook.add_format({"num_format": "0.0"})
    int_fmt = workbook.add_format({"num_format": "0"})
    text_fmt = workbook.add_format({})  # default

    # column widths (optional but helpful)
    col_widths = [28, 12, 18, 26, 10, 10, 12, 12, 12]

    def make_sheet(idx: int):
        name = main_sheet_base if idx == 1 else f"{main_sheet_base}_{idx}"
        ws = workbook.add_worksheet(name[:31])
        for i, w in enumerate(col_widths):
            ws.set_column(i, i, w)
        _write_sheet_header(ws, header_fmt, headers)
        return ws

    ws = make_sheet(1)
    sheet_idx = 1
    row_in_sheet = 1  # start after header
    total_written = 0

    cur = con.execute(sql)
    colnames = [d[0] for d in cur.description]
    hr_present = [c for c in colnames if c.startswith("hr_")]
    cur.arraysize = 10_000

    for rec in _iter_cursor_rows(cur, batch_size=10_000):
        # If current sheet is full:
        if row_in_sheet > max_rows:
            if overflow_strategy == "split":
                sheet_idx += 1
                ws = make_sheet(sheet_idx)
                row_in_sheet = 1
            else:
                # overflow_strategy 'skip' shouldn't land here (handled earlier),
                # and 'error' should be prevented by pre-count logic.
                break

        # rec order:
        # full_name, teacher_id, course_value, activity_value, count_value,
        # pct_course, pct_program, pct_faculty, pct_university, _order_tech
        full_name, teacher_id, course_value, activity_value, count_value, p1, p2, p3, p4, _ = rec

        # Write row in one call (fast), with formats for numeric columns only
        ws.write(row_in_sheet, 0, full_name, text_fmt)
        ws.write(row_in_sheet, 1, teacher_id, text_fmt)
        ws.write(row_in_sheet, 2, course_value, text_fmt)
        ws.write(row_in_sheet, 3, activity_value, text_fmt)

        # count (int)
        ws.write_number(row_in_sheet, 4, float(count_value or 0), int_fmt)

        # percents (numbers with 1 decimal place display)
        # Note: ROUND is already done upstream; we only format.
        def write_pct(col: int, val: Any):
            if val is None:
                ws.write_blank(row_in_sheet, col, None)
            else:
                ws.write_number(row_in_sheet, col, float(val), pct_fmt)

        write_pct(5, p1)
        write_pct(6, p2)
        write_pct(7, p3)
        write_pct(8, p4)

        row_in_sheet += 1
        total_written += 1

    logger.info("Wrote %s rows into %s sheet(s).", total_written, sheet_idx)
    return total_written, sheet_idx


def _write_qa_sheet(workbook: xlsxwriter.Workbook, con, logger: logging.Logger) -> int:
    ws = workbook.add_worksheet("QA")
    header_fmt = workbook.add_format({"bold": True, "border": 1})
    text_fmt = workbook.add_format({})

    headers = ["type", "teacher_id", "course_code", "tech_key", "description"]
    ws.set_column(0, 0, 22)
    ws.set_column(1, 3, 16)
    ws.set_column(4, 4, 80)

    _write_sheet_header(ws, header_fmt, headers)

    sql = _select_metrics_qa_sql(con)
    cur = con.execute(sql)
    cur.arraysize = 10_000

    r = 1
    for row in _iter_cursor_rows(cur, batch_size=10_000):
        ws.write_row(r, 0, list(row), text_fmt)
        r += 1

    logger.info("QA rows: %s", r - 1)
    return r - 1


def _write_info_sheet(
    workbook: xlsxwriter.Workbook,
    con,
    base_sql_metrics_long: str,
    ay: str,
    term: str,
    generated_at: datetime,
    logger: logging.Logger,
) -> None:
    ws = workbook.add_worksheet("INFO")
    bold = workbook.add_format({"bold": True})
    ws.set_column(0, 0, 22)
    ws.set_column(1, 1, 40)

    # counts from SQL (no pandas aggregation)
    total = int(con.execute(f"SELECT COUNT(*)::BIGINT FROM ({base_sql_metrics_long}) t").fetchone()[0])

    teachers = int(
        con.execute(f"SELECT COUNT(DISTINCT teacher_id)::BIGINT FROM ({base_sql_metrics_long}) t").fetchone()[0]
    )

    courses = int(
        con.execute(f"SELECT COUNT(DISTINCT course_value)::BIGINT FROM ({base_sql_metrics_long}) t").fetchone()[0]
    )

    rows = [
        ("ay", ay),
        ("term", term),
        ("data_wygenerowania_utc", generated_at.isoformat()),
        ("liczba_nauczycieli", teachers),
        ("liczba_kursow", courses),
        ("liczba_rekordow", total),
    ]

    ws.write(0, 0, "pole", bold)
    ws.write(0, 1, "wartosc", bold)
    for i, (k, v) in enumerate(rows, start=1):
        ws.write(i, 0, k)
        ws.write(i, 1, v)

    logger.info("INFO: teachers=%s courses=%s records=%s", teachers, courses, total)


def _export_skip_strategy_sql(con, activity_col: str) -> str:
    """
    "skip" is ambiguous in prompt. We implement safe minimal output:
    aggregate per teacher + activity only, without course. Percents set NULL.
    """
    table = "mart.metrics_long"
    if activity_col == "activity_label" and not _duckdb_has_column(con, table, "activity_label"):
        activity_col = "tech_key"

    where_clause = "WHERE visible_active" if _duckdb_has_column(con, table, "visible_active") else ""
    sql = f"""
        SELECT
            full_name::VARCHAR AS full_name,
            teacher_id::VARCHAR AS teacher_id,
            NULL::VARCHAR AS course_value,
            {activity_col}::VARCHAR AS activity_value,
            SUM(count_value)::BIGINT AS count_value,
            NULL::DOUBLE AS pct_course,
            NULL::DOUBLE AS pct_program,
            NULL::DOUBLE AS pct_faculty,
            NULL::DOUBLE AS pct_university,
            {activity_col}::VARCHAR AS _order_tech
        FROM {table}
        {where_clause}
        GROUP BY 1,2,3,4,10
        ORDER BY full_name ASC, _order_tech ASC
    """
    return sql


def export_summary_excel(con, cfg: Dict[str, Any]) -> Tuple[int, Path]:
    """
    Main entry point. Returns (exit_code, output_path).
    Requires:
      cfg["paths"]["root"] or cfg["root"] (depending on your config shape)
      cfg["report"]["ay"], cfg["report"]["term"] (or equivalents)
      cfg["export"]["max_rows_excel"], cfg["export"]["overflow_strategy"] (optional)
    """
    # --- Resolve config fields (keep tolerant to shape) ---
    root = Path(cfg.get("root") or cfg.get("paths", {}).get("root") or cfg.get("paths", {}).get("output_root", "."))
    ay = str(cfg.get("report", {}).get("ay") or cfg.get("ay") or "")
    term = str(cfg.get("report", {}).get("term") or cfg.get("term") or "")

    export_cfg = ExportExcelConfig(
        max_rows_excel=int(cfg.get("export", {}).get("max_rows_excel", 1_000_000)),
        overflow_strategy=str(cfg.get("export", {}).get("overflow_strategy", "error")),
        activity_column=str(cfg.get("export", {}).get("activity_column", "activity_label")),
        course_column=str(cfg.get("export", {}).get("course_column", "course_name")),
        include_hr_cols=bool(cfg.get("export", {}).get("include_hr_cols", True)),
        exclude_zero_counts=bool(cfg.get("export", {}).get("exclude_zero_counts", True)),
        percent_excel_format=bool(cfg.get("export", {}).get("percent_excel_format", True)),
     )

    run_dir, out_dir = _ensure_dirs(root)
    logger = _setup_logger(run_dir)

    _progress_append(run_dir, {"step": "export-excel", "status": "start", "ay": ay, "term": term})

    out_path = out_dir / f"Raport_Zbiorczy_NA_{ay}_{term}.xlsx"
    ok_flag = run_dir / "export-excel.ok"

    logger.info("Exporting XLSX to: %s", out_path)
    logger.info("Export config: %s", export_cfg)

    # Build base SQL (ordered) for main sheet
    base_sql = _select_metrics_long_sql(
    con,
    export_cfg.activity_column,
    export_cfg.course_column,
    export_cfg.include_hr_cols,
    export_cfg.exclude_zero_counts,
    export_cfg.percent_excel_format,
    )

    # Pre-count rows to enforce overflow strategy deterministically
    total_rows = _count_rows(con, base_sql)
    logger.info("metrics_long rows to export: %s", total_rows)

    # Decide strategy
    strategy = export_cfg.overflow_strategy.lower().strip()
    max_rows = export_cfg.max_rows_excel

    if total_rows > max_rows and strategy == "error":
        _progress_append(
            run_dir,
            {
                "step": "export-excel",
                "status": "error",
                "reason": "overflow",
                "rows": total_rows,
                "max_rows_excel": max_rows,
                "strategy": strategy,
            },
        )
        raise ExportOverflowError(f"Too many rows for Excel: {total_rows} > {max_rows}")

    if total_rows > max_rows and strategy == "skip":
        logger.warning("Overflow with strategy=skip; exporting aggregated per teacher (course=NULL).")
        base_sql = _export_skip_strategy_sql(con, export_cfg.activity_column)
        total_rows = _count_rows(con, base_sql)

    # Create workbook (overwrite, idempotent)
    generated_at = datetime.now(timezone.utc)

    workbook = xlsxwriter.Workbook(
        out_path.as_posix(),
        {
            "constant_memory": True,  # good for large datasets
            "strings_to_numbers": False,
            "strings_to_formulas": False,
            "strings_to_urls": False,
        },
    )

    try:
        main_sheet_base = "ZLICZENIE_AKTYWNOSCI_NA"

        # Main data
        _progress_append(run_dir, {"step": "export-excel", "status": "writing_main", "rows": total_rows})
        written_rows, sheets_count = _write_metrics_long_split_streaming(
            workbook=workbook,
            con=con,
            sql=base_sql,
            max_rows=max_rows,
            overflow_strategy=("split" if strategy == "split" else "error"),
            main_sheet_base=main_sheet_base,
            logger=logger,
        )

        # QA
        _progress_append(run_dir, {"step": "export-excel", "status": "writing_qa"})
        qa_rows = _write_qa_sheet(workbook, con, logger)

        # INFO
        _progress_append(run_dir, {"step": "export-excel", "status": "writing_info"})
        _write_info_sheet(workbook, con, base_sql, ay, term, generated_at, logger)

    finally:
        workbook.close()

    ok_flag.write_text("OK\n", encoding="utf-8")
    _progress_append(
        run_dir,
        {
            "step": "export-excel",
            "status": "done",
            "output": str(out_path),
            "main_rows": written_rows,
            "qa_rows": qa_rows,
            "main_sheets": sheets_count,
        },
    )

    logger.info("DONE: %s", out_path)
    return EXIT_OK, out_path

================================================================================
src\mrna_plum\reports\export_individual.py
================================================================================

from __future__ import annotations

import json
from logging import root
import re
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple

import duckdb
import xlsxwriter
from concurrent.futures import ThreadPoolExecutor, as_completed


# ======================================================================================
# Config helpers (tolerant: cfg can be dict-like or attr-like)
# ======================================================================================

def _cfg_get(cfg: Any, path: str, default: Any = None) -> Any:
    """
    Read cfg value using dotted path, supports both dict-like and attribute-like objects.
    Example: _cfg_get(cfg, "reports.max_workers", 4)
    """
    cur = cfg
    for part in path.split("."):
        if cur is None:
            return default
        if isinstance(cur, dict):
            cur = cur.get(part, None)
        else:
            cur = getattr(cur, part, None)
    return default if cur is None else cur


# ======================================================================================
# Logging & artifacts
# ======================================================================================

@dataclass(frozen=True)
class RunArtifacts:
    run_dir: Path
    run_log: Path
    progress_jsonl: Path
    ok_file: Path


def _ensure_artifacts(root: Path) -> RunArtifacts:
    run_dir = root / "_run"
    run_dir.mkdir(parents=True, exist_ok=True)
    run_log = run_dir / "run.log"
    progress_jsonl = run_dir / "progress.jsonl"
    ok_file = run_dir / "export-individual.ok"
    return RunArtifacts(run_dir, run_log, progress_jsonl, ok_file)


def _log(line: str, run_log: Path) -> None:
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    msg = f"{ts} [export-individual] {line}"
    print(msg)
    with run_log.open("a", encoding="utf-8") as f:
        f.write(msg + "\n")


def _progress(evt: Dict[str, Any], progress_jsonl: Path) -> None:
    evt = dict(evt)
    evt.setdefault("ts", time.strftime("%Y-%m-%d %H:%M:%S"))
    with progress_jsonl.open("a", encoding="utf-8") as f:
        f.write(json.dumps(evt, ensure_ascii=False) + "\n")


# ======================================================================================
# Filename sanitization
# ======================================================================================

_WIN_ILLEGAL = r'<>:"/\|?*'
_WIN_ILLEGAL_RE = re.compile(rf"[{re.escape(_WIN_ILLEGAL)}]")


def sanitize_filename(name: str, max_len: int = 120) -> str:
    """
    - replace illegal Windows filename chars with '_'
    - collapse whitespace
    - trim
    - limit length
    """
    if not name:
        return ""
    s = str(name).strip()
    s = _WIN_ILLEGAL_RE.sub("_", s)
    s = re.sub(r"\s+", " ", s)
    s = s.strip(" .")  # Windows hates trailing dot/space
    if len(s) > max_len:
        s = s[:max_len].rstrip(" .")
    return s


# ======================================================================================
# DuckDB SQL
# ======================================================================================

def _ensure_qa_table(con: duckdb.DuckDBPyConnection) -> None:
    con.execute("CREATE SCHEMA IF NOT EXISTS mart;")
    con.execute(
        """
        CREATE TABLE IF NOT EXISTS mart.individual_export_qa (
            teacher_id      VARCHAR,
            status          VARCHAR,  -- OK / SKIPPED_* / ERROR
            message         VARCHAR,
            output_file     VARCHAR,
            rows_exported   BIGINT,
            exported_at     TIMESTAMP DEFAULT now()
        );
        """
    )


def _qa_insert(
    con: duckdb.DuckDBPyConnection,
    teacher_id: str,
    status: str,
    message: str,
    output_file: Optional[str],
    rows_exported: int,
) -> None:
    con.execute(
        """
        INSERT INTO mart.individual_export_qa
            (teacher_id, status, message, output_file, rows_exported)
        VALUES (?, ?, ?, ?, ?)
        """,
        [teacher_id, status, message, output_file, rows_exported],
    )


def _detect_hr_columns(con: duckdb.DuckDBPyConnection) -> List[str]:
    """
    Prefer HR embedded in mart.metrics_long as dynamic columns hr_*.
    Return list of column names present in metrics_long matching hr_*.
    """
    rows = con.execute("DESCRIBE mart.metrics_long;").fetchall()
    col_names = [r[0] for r in rows]
    return [c for c in col_names if c.lower().startswith("hr_")]


def _list_teachers(con: duckdb.DuckDBPyConnection) -> List[Tuple[str, str, str, str]]:
    """
    Teachers to export (metrics_long already HR-whitelisted).
    EXPORT RULE:
      - require teacher_id AND email (non-empty); otherwise teacher is not included here.
      - require id_bazus for filename (we still include them here; missing bazus handled in worker).
    Deterministic order: teacher_id asc.
    Returns: (teacher_id, full_name, email, id_bazus)
    """
    rows = con.execute(
        """
        SELECT
            teacher_id::VARCHAR AS teacher_id,
            COALESCE(NULLIF(TRIM(full_name), ''), '') AS full_name,
            COALESCE(NULLIF(TRIM(email), ''), '') AS email,
            COALESCE(NULLIF(TRIM(id_bazus), ''), '') AS id_bazus
        FROM mart.metrics_long
        WHERE visible_active = TRUE
        GROUP BY 1, 2, 3, 4
        HAVING teacher_id IS NOT NULL
           AND TRIM(teacher_id) <> ''
           AND email IS NOT NULL
           AND TRIM(email) <> ''
        ORDER BY teacher_id ASC
        """
    ).fetchall()
    return [(str(tid), str(fn), str(em), str(bz)) for tid, fn, em, bz in rows]


def _fetch_teacher_rows(
    con: duckdb.DuckDBPyConnection,
    teacher_id: str,
) -> Iterator[Tuple[Any, ...]]:
    """
    Rows for DANE_KURSY:
      course_name, activity_label, count_value,
      pct_course/100.0, pct_kierunek/100.0, pct_wydzial/100.0, pct_uczelnia/100.0

    Deterministic sort, count_value>0 only.
    """
    cur = con.execute(
        """
        SELECT
            course_name,
            activity_label,
            count_value,
            (pct_course / 100.0)   AS pct_course_xlsx,
            (pct_kierunek / 100.0) AS pct_kierunek_xlsx,
            (pct_wydzial / 100.0)  AS pct_wydzial_xlsx,
            (pct_uczelnia / 100.0) AS pct_uczelnia_xlsx
        FROM mart.metrics_long
        WHERE visible_active = TRUE
          AND teacher_id::VARCHAR = ?
          AND count_value > 0
        ORDER BY
            course_name ASC,
            activity_label ASC
        """,
        [teacher_id],
    )
    while True:
        batch = cur.fetchmany(10_000)
        if not batch:
            break
        for row in batch:
            yield row


def _fetch_teacher_pers(
    con: duckdb.DuckDBPyConnection,
    teacher_id: str,
    hr_cols: List[str],
) -> Dict[str, Any]:
    """
    One row with "metrics_long embedded HR" preference.
    We take MAX(...) as safe collapse (same per teacher).
    Assumes email + id_bazus exist in schema (per your rules).
    """
    select_parts = [
        "teacher_id::VARCHAR AS teacher_id",
        "MAX(COALESCE(NULLIF(TRIM(full_name), ''), '')) AS full_name",
        "MAX(COALESCE(NULLIF(TRIM(email), ''), '')) AS email",
        "MAX(COALESCE(NULLIF(TRIM(id_bazus), ''), '')) AS id_bazus",
    ]

    for c in hr_cols:
        select_parts.append(f"MAX(COALESCE(NULLIF(TRIM({c}), ''), '')) AS {c}")

    sql = f"""
        SELECT {", ".join(select_parts)}
        FROM mart.metrics_long
        WHERE visible_active = TRUE
          AND teacher_id::VARCHAR = ?
        GROUP BY teacher_id
    """
    row = con.execute(sql, [teacher_id]).fetchone()
    if row is None:
        base = {"teacher_id": teacher_id, "full_name": "", "email": "", "id_bazus": ""}
        for c in hr_cols:
            base[c] = ""
        return base

    keys = ["teacher_id", "full_name", "email", "id_bazus"] + hr_cols
    return dict(zip(keys, row))


def _hr_human_label(col: str) -> str:
    """
    Map hr_* columns to human-friendly labels for DANE_PERS.
    Extend as you standardize HR fields.
    """
    m = {
        "hr_wydzial": "Wydział",
        "hr_jednostka": "Jednostka",
        "hr_katedra": "Katedra",
        "hr_zaklad": "Zakład",
        "hr_stanowisko": "Stanowisko",
        "hr_tytul": "Tytuł / Stopień",
        "hr_umowa": "Rodzaj umowy",
    }
    low = col.lower()
    return m.get(low, col)  # fallback to raw column name


# ======================================================================================
# XLSX writing
# ======================================================================================

_COURSES_HEADERS = ["Kurs", "Aktywność", "Liczba", "% kurs", "% kierunek", "% wydział", "% uczelnia"]


def _write_teacher_xlsx(
    out_file: Path,
    teacher_id: str,
    full_name: str,
    rows_iter: Iterator[Tuple[Any, ...]],
    pers: Dict[str, Any],
    hr_cols: List[str],
) -> int:
    """
    Returns rows_exported (DANE_KURSY count).
    """
    out_file.parent.mkdir(parents=True, exist_ok=True)

    wb = xlsxwriter.Workbook(out_file.as_posix(), {"constant_memory": True})
    try:
        fmt_header = wb.add_format({"bold": True})
        fmt_pct = wb.add_format({"num_format": "0.0%"})
        fmt_int = wb.add_format({"num_format": "0"})  # count_value

        # Sheet 1: DANE_KURSY
        ws1 = wb.add_worksheet("DANE_KURSY")
        for c, h in enumerate(_COURSES_HEADERS):
            ws1.write(0, c, h, fmt_header)

        r = 1
        for (
            course_name,
            activity_label,
            count_value,
            pct_course_x,
            pct_kierunek_x,
            pct_wydzial_x,
            pct_uczelnia_x,
        ) in rows_iter:
            ws1.write(r, 0, course_name if course_name is not None else "")
            ws1.write(r, 1, activity_label if activity_label is not None else "")

            try:
                ws1.write_number(r, 2, float(count_value), fmt_int)
            except Exception:
                ws1.write(r, 2, count_value)

            for j, v in enumerate([pct_course_x, pct_kierunek_x, pct_wydzial_x, pct_uczelnia_x], start=3):
                if v is None:
                    ws1.write_blank(r, j, None)
                else:
                    ws1.write_number(r, j, float(v), fmt_pct)

            r += 1

        rows_exported = r - 1

        # Sheet 2: DANE_PERS (vertical key -> value)
        ws2 = wb.add_worksheet("DANE_PERS")
        ws2.write(0, 0, "Pole", fmt_header)
        ws2.write(0, 1, "Wartość", fmt_header)

        # Required minimum fields + your "Imię i nazwisko"
        name_val = pers.get("full_name", full_name) or full_name or ""
        kv: List[Tuple[str, Any]] = [
            ("ID_PLUM", teacher_id),
            ("Imię i nazwisko", name_val),
            ("E-mail", pers.get("email", "") or ""),
            ("ID bazus", pers.get("id_bazus", "") or ""),
        ]

        # HR -> human labels (dynamic)
        for c in hr_cols:
            kv.append((_hr_human_label(c), pers.get(c, "") or ""))

        # Ensure at least Wydział/Jednostka rows exist even if hr cols absent
        if not any(_hr_human_label(c) == "Wydział" for c in hr_cols):
            kv.append(("Wydział", ""))
        if not any(_hr_human_label(c) == "Jednostka" for c in hr_cols):
            kv.append(("Jednostka", ""))

        for i, (k, v) in enumerate(kv, start=1):
            ws2.write(i, 0, k)
            ws2.write(i, 1, v)

        return rows_exported
    finally:
        wb.close()


# ======================================================================================
# Public API
# ======================================================================================

def export_individual_reports(
    con: duckdb.DuckDBPyConnection,
    cfg: Any,
) -> Tuple[int, str]:
    """
    Public entrypoint:
      export_individual_reports(con, cfg) -> (exit_code, out_dir)

    Rules applied:
      - SQL-first (DuckDB)
      - only visible_active
      - exclude count_value=0 from export
      - require teacher_id + email (non-empty) or SKIP
      - filename: <NazwiskoImie>_<BAZUS ID>.xlsx (sanitized)
      - pct columns: DB 0-100 -> XLSX pct/100.0 with format 0.0%
      - deterministic sort: course_name ASC, activity_label ASC
      - idempotent overwrite
    """
    root = Path(_cfg_get(cfg, "root", ".")).resolve()
    arts = _ensure_artifacts(root)

    out_rel = _cfg_get(cfg, "reports.individual_dir", "_out/indywidualne")
    out_rel_p = Path(out_rel)
    out_dir = (out_rel_p if out_rel_p.is_absolute() else (root / out_rel_p)).resolve()
    max_workers = int(_cfg_get(cfg, "reports.max_workers", 4))
    batch_teachers = int(_cfg_get(cfg, "reports.batch_teachers", 50))

    _log(f"root={root}", arts.run_log)
    _log(f"out_dir={out_dir}", arts.run_log)
    _log(f"max_workers={max_workers} batch_teachers={batch_teachers}", arts.run_log)

    _ensure_qa_table(con)
    hr_cols = _detect_hr_columns(con)
    _log(f"Detected HR columns in mart.metrics_long: {hr_cols}", arts.run_log)

    teachers = _list_teachers(con)  # (teacher_id, full_name, email, id_bazus) with email required
    _log(f"Teachers to export (email required): {len(teachers)}", arts.run_log)

    # For parallel: DuckDB connection is not safely shared across threads.
    # We'll open a separate connection per worker using cfg.paths.db_path.
    db_path = _cfg_get(cfg, "paths.db_path", None)

    def _worker(teacher_id: str, full_name: str, email: str, id_bazus: str) -> Tuple[str, str, str, Optional[str], int]:
        """
        Returns: (teacher_id, status, message, output_file, rows_exported)
        """
        local_con = con
        must_close = False
        try:
            # hard guards (your rule)
            if not teacher_id or not str(teacher_id).strip():
                return (str(teacher_id), "SKIPPED_NO_ID", "Missing teacher_id", None, 0)
            if not email or not str(email).strip():
                return (str(teacher_id), "SKIPPED_NO_EMAIL", "Missing email", None, 0)
            if not id_bazus or not str(id_bazus).strip():
                return (str(teacher_id), "SKIPPED_NO_BAZUS", "Missing BAZUS ID for filename", None, 0)

            if max_workers and max_workers > 1:
                if not db_path:
                    # no db_path -> do not parallelize safely
                    local_con = con
                else:
                    local_con = duckdb.connect(str(db_path))
                    must_close = True

            safe_name = sanitize_filename(full_name, max_len=120) or "UNKNOWN"
            safe_bazus = sanitize_filename(str(id_bazus), max_len=60) or "BAZUS_UNKNOWN"

            filename = f"{safe_name}_{safe_bazus}.xlsx"
            if len(filename) > 180:
                safe_name2 = sanitize_filename(safe_name, max_len=120)
                filename = f"{safe_name2}_{safe_bazus}.xlsx"

            out_file = out_dir / filename

            # fetch rows (streaming)
            rows_iter = _fetch_teacher_rows(local_con, teacher_id)

            # Need to know if any rows exist without consuming iterator -> buffer first item
            buffered: List[Tuple[Any, ...]] = []
            try:
                buffered.append(next(rows_iter))
            except StopIteration:
                buffered = []

            if not buffered:
                return (teacher_id, "SKIPPED_NO_DATA", "No rows with count_value>0", None, 0)

            def _chain() -> Iterator[Tuple[Any, ...]]:
                for x in buffered:
                    yield x
                for x in rows_iter:
                    yield x

            pers = _fetch_teacher_pers(local_con, teacher_id, hr_cols)

            # idempotent overwrite
            if out_file.exists():
                out_file.unlink()

            rows_exported = _write_teacher_xlsx(
                out_file=out_file,
                teacher_id=teacher_id,
                full_name=full_name,
                rows_iter=_chain(),
                pers=pers,
                hr_cols=hr_cols,
            )

            if rows_exported == 0:
                if out_file.exists():
                    out_file.unlink()
                return (teacher_id, "SKIPPED_NO_DATA", "No rows with count_value>0", None, 0)

            return (teacher_id, "OK", "Exported", str(out_file), int(rows_exported))

        except Exception as e:
            return (teacher_id, "ERROR", f"{type(e).__name__}: {e}", None, 0)
        finally:
            if must_close:
                try:
                    local_con.close()
                except Exception:
                    pass

    exported_ok = 0
    exported_err = 0
    exported_skip = 0

    def _batched(seq: Sequence[Tuple[str, str, str, str]], n: int) -> Iterator[List[Tuple[str, str, str, str]]]:
        for i in range(0, len(seq), n):
            yield list(seq[i : i + n])

    for batch in _batched(teachers, batch_teachers):
        if max_workers and max_workers > 1 and db_path:
            with ThreadPoolExecutor(max_workers=max_workers) as ex:
                futs = [ex.submit(_worker, tid, fn, em, bz) for (tid, fn, em, bz) in batch]
                for fut in as_completed(futs):
                    tid, status, msg, out_file, rows_exported = fut.result()
                    _qa_insert(con, tid, status, msg, out_file, rows_exported)
                    _progress(
                        {
                            "teacher_id": tid,
                            "status": status,
                            "message": msg,
                            "output_file": out_file,
                            "rows_exported": rows_exported,
                        },
                        arts.progress_jsonl,
                    )
                    if status == "OK":
                        exported_ok += 1
                    elif status.startswith("SKIPPED"):
                        exported_skip += 1
                    else:
                        exported_err += 1
        else:
            for (tid, fn, em, bz) in batch:
                tid, status, msg, out_file, rows_exported = _worker(tid, fn, em, bz)
                _qa_insert(con, tid, status, msg, out_file, rows_exported)
                _progress(
                    {
                        "teacher_id": tid,
                        "status": status,
                        "message": msg,
                        "output_file": out_file,
                        "rows_exported": rows_exported,
                    },
                    arts.progress_jsonl,
                )
                if status == "OK":
                    exported_ok += 1
                elif status.startswith("SKIPPED"):
                    exported_skip += 1
                else:
                    exported_err += 1

    _log(f"Done. OK={exported_ok} SKIPPED={exported_skip} ERROR={exported_err}", arts.run_log)

    if exported_err == 0:
        arts.ok_file.write_text("OK\n", encoding="utf-8")
        return (0, str(out_dir))
    return (2, str(out_dir))


# ======================================================================================
# Optional CLI wrapper (adapt to your cli.py / Typer)
# ======================================================================================

def cli_export_individual(root: str, config: Any) -> int:
    """
    Example CLI wrapper (adapt to your existing cli.py).
    - root: pipeline root
    - config: loaded config object/dict
    """
    if isinstance(config, dict):
        config = dict(config)
        config["root"] = root
    else:
        setattr(config, "root", root)

    db_path = _cfg_get(config, "paths.db_path", None)
    if not db_path:
        raise RuntimeError("cfg.paths.db_path is required for export-individual")

    con = duckdb.connect(str(db_path))
    try:
        code, _out = export_individual_reports(con, config)
        return int(code)
    finally:
        con.close()

================================================================================
src\mrna_plum\rules\__init__.py
================================================================================



================================================================================
src\mrna_plum\rules\activity_rules.py
================================================================================

# src/mrna_plum/rules/activity_rules.py

from __future__ import annotations

import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from openpyxl import load_workbook


@dataclass(frozen=True)
class KeyRule:
    activity_label: str
    tech_key: str
    operation: str          # CREATE/DELETE/UPDATE/VIEW/GRADE/...
    count_mode: str         # TAK / TAK_FLAG / NIE
    rx_match: re.Pattern
    rx_user: Optional[re.Pattern]
    rx_object_from_match_group: Optional[str]  # e.g. "object_id" or None
    priority: int


@dataclass(frozen=True)
class RuleMatch:
    activity_label: str
    tech_key: str
    operation: str
    count_mode: str
    teacher_id: Optional[int]
    object_id: Optional[int]
    priority: int
    conflict: bool


def _norm(s: Any) -> str:
    return ("" if s is None else str(s)).strip()


def _compile(pat: str) -> re.Pattern:
    # wszystkie regexy traktujemy case-insensitive
    return re.compile(pat, re.IGNORECASE)


def load_keys_rules(keys_xlsx: str, sheet_name: str = "KEYS") -> List[KeyRule]:
    """
    Oczekiwane kolumny w KEYS:
    AKTYWNOSC
    KLUCZ_TECHNICZNY
    OPERACJA
    LICZYC_DO_RAPORTU
    REGEX_DOPASOWANIA_(Opis)
    REGEX_USER_ID_(Opis)
    REGEX_OBIEKT_ID_(z dopasowania)   # opcjonalnie: nazwa grupy np. object_id
    PRIORYTET
    """
    wb = load_workbook(filename=keys_xlsx, read_only=True, data_only=True)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"KEYS: brak arkusza '{sheet_name}' w {keys_xlsx}")

    ws = wb[sheet_name]
    rows = ws.iter_rows(values_only=True)
    header = [(_norm(x)) for x in next(rows)]
    idx = {name: i for i, name in enumerate(header) if name}

    def col(name: str) -> int:
        if name not in idx:
            raise ValueError(f"KEYS: brak kolumny '{name}' (nagłówki: {header})")
        return idx[name]

    rules: List[KeyRule] = []

    for r in rows:
        activity_label = _norm(r[col("AKTYWNOSC")])
        tech_key = _norm(r[col("KLUCZ_TECHNICZNY")])
        operation = _norm(r[col("OPERACJA")]).upper()
        count_mode = _norm(r[col("LICZYC_DO_RAPORTU")]).upper()  # TAK/TAK_FLAG/NIE
        rx_match_txt = _norm(r[col("REGEX_DOPASOWANIA_(Opis)")])
        rx_user_txt = _norm(r[col("REGEX_USER_ID_(Opis)")])
        rx_obj_group = _norm(r[idx.get("REGEX_OBIEKT_ID_(z dopasowania)", -1)]) if "REGEX_OBIEKT_ID_(z dopasowania)" in idx else ""
        prio_txt = _norm(r[col("PRIORYTET")])
        if not rx_match_txt or not tech_key:
            continue

        try:
            prio = int(prio_txt) if prio_txt else 0
        except Exception:
            prio = 0

        rx_match = _compile(rx_match_txt)
        rx_user = _compile(rx_user_txt) if rx_user_txt else None
        rx_obj_group = rx_obj_group or None

        rules.append(
            KeyRule(
                activity_label=activity_label,
                tech_key=tech_key,
                operation=operation,
                count_mode=count_mode,
                rx_match=rx_match,
                rx_user=rx_user,
                rx_object_from_match_group=rx_obj_group,
                priority=prio,
            )
        )

    # najwyższy priorytet wcześniej – przyspiesza
    rules.sort(key=lambda x: x.priority, reverse=True)
    return rules


class ActivityRuleEngine:
    def __init__(self, rules: List[KeyRule], drop_mode_nie: bool = True):
        self.rules = rules
        self.drop_mode_nie = drop_mode_nie

    def match(self, opis: str) -> Optional[RuleMatch]:
        """
        Jeśli wiele reguł pasuje:
        - wybierz najwyższy PRIORYTET
        - jeśli kilka ma ten sam max PRIORYTET -> conflict=True
        """
        opis = opis or ""
        matches: List[Tuple[KeyRule, re.Match]] = []

        for rule in self.rules:
            m = rule.rx_match.search(opis)
            if m:
                matches.append((rule, m))

        if not matches:
            return None

        # wybór max priorytetu
        max_prio = max(rule.priority for rule, _ in matches)
        best = [(rule, m) for rule, m in matches if rule.priority == max_prio]

        # bierzemy pierwszy jako “winner”, ale zaznaczamy konflikt jeśli >1
        rule, m = best[0]
        conflict = len(best) > 1

        # object_id – z grupy nazwanej, jeśli KEYS wskazuje; inaczej spróbuj 1. grupy
        object_id: Optional[int] = None
        if rule.rx_object_from_match_group:
            gd = m.groupdict()
            val = gd.get(rule.rx_object_from_match_group)
            if val:
                try:
                    object_id = int(val)
                except Exception:
                    object_id = None
        else:
            try:
                if m.groups():
                    object_id = int(m.group(1))
            except Exception:
                object_id = None

        # teacher_id – regex osobny z KEYS (na Opis)
        teacher_id: Optional[int] = None
        if rule.rx_user:
            um = rule.rx_user.search(opis)
            if um:
                gd = um.groupdict()
                if "id" in gd and gd["id"]:
                    try:
                        teacher_id = int(gd["id"])
                    except Exception:
                        teacher_id = None
                else:
                    try:
                        teacher_id = int(um.group(1))
                    except Exception:
                        teacher_id = None

        if self.drop_mode_nie and rule.count_mode == "NIE":
            return None

        return RuleMatch(
            activity_label=rule.activity_label,
            tech_key=rule.tech_key,
            operation=rule.operation,
            count_mode=rule.count_mode,
            teacher_id=teacher_id,
            object_id=object_id,
            priority=rule.priority,
            conflict=conflict,
        )

================================================================================
src\mrna_plum\rules\engine.py
================================================================================

from __future__ import annotations
from dataclasses import dataclass
from typing import Optional
import re
import pandas as pd

from .models import Rule

@dataclass(frozen=True)
class MatchResult:
    tech_key: str
    activity: str
    operation: str
    count_to_report: bool
    teacher_id: Optional[str]
    object_id: Optional[str]
    priority: int

def compile_rules(keys_df: pd.DataFrame) -> list[Rule]:
    rules: list[Rule] = []
    for _, r in keys_df.iterrows():
        def _p(s: object) -> str:
            return "" if s is None else str(s)

        match_rx = re.compile(_p(r["REGEX_DOPASOWANIA_(Opis)"]))
        user_rx_s = _p(r["REGEX_USER_ID_(Opis)"]).strip()
        obj_rx_s  = _p(r["REGEX_OBIEKT_ID_(z dopasowania)"]).strip()

        user_rx = re.compile(user_rx_s) if user_rx_s else None
        obj_rx  = re.compile(obj_rx_s) if obj_rx_s else None

        count_flag = _p(r["LICZYC_DO_RAPORTU"]).upper() in ("TAK", "1", "TRUE", "YES")

        rules.append(
            Rule(
                activity=_p(r["AKTYWNOSC"]).strip(),
                tech_key=_p(r["KLUCZ_TECHNICZNY"]).strip(),
                operation=_p(r["OPERACJA"]).strip(),
                count_to_report=count_flag,
                regex_match_desc=match_rx,
                regex_user_id=user_rx,
                regex_object_id=obj_rx,
                priority=int(r["PRIORYTET"]),
            )
        )
    # wyższy priorytet pierwszy
    rules.sort(key=lambda x: x.priority, reverse=True)
    return rules

def match_best_rule(description: str, rules: list[Rule]) -> Optional[MatchResult]:
    for rule in rules:
        m = rule.regex_match_desc.search(description or "")
        if not m:
            continue

        teacher_id = None
        object_id = None

        if rule.regex_user_id:
            um = rule.regex_user_id.search(description or "")
            if um and um.groups():
                teacher_id = um.group(1)
            elif um:
                teacher_id = um.group(0)

        if rule.regex_object_id:
            # object_id może być z dopasowania głównego (m) albo z opisu
            om = rule.regex_object_id.search(m.group(0)) or rule.regex_object_id.search(description or "")
            if om and om.groups():
                object_id = om.group(1)
            elif om:
                object_id = om.group(0)

        return MatchResult(
            tech_key=rule.tech_key,
            activity=rule.activity,
            operation=rule.operation,
            count_to_report=rule.count_to_report,
            teacher_id=teacher_id,
            object_id=object_id,
            priority=rule.priority,
        )
    return None


================================================================================
src\mrna_plum\rules\models.py
================================================================================

from __future__ import annotations
from dataclasses import dataclass
import re
from typing import Optional

@dataclass(frozen=True)
class Rule:
    activity: str
    tech_key: str
    operation: str          # np. TAK / TAK_FLAG / NIE / etc.
    count_to_report: bool
    regex_match_desc: re.Pattern
    regex_user_id: Optional[re.Pattern]
    regex_object_id: Optional[re.Pattern]
    priority: int


================================================================================
src\mrna_plum\stats\__init__.py
================================================================================

from .compute_stats import compute_stats
__all__ = ["compute_stats"]


================================================================================
src\mrna_plum\stats\compute_stats.py
================================================================================

from __future__ import annotations

import json
from dataclasses import dataclass
from logging import root
from pathlib import Path
from datetime import datetime, timezone
from typing import Optional, Sequence

import duckdb
import pandas as pd
import yaml

from mrna_plum import paths
from mrna_plum.errors import ConfigError
from mrna_plum.paths import ProjectPaths

# ----------------------------
# Helpers / config
# ----------------------------

@dataclass(frozen=True)
class StatsConfig:
    duckdb_path: Path
    run_dir: Path
    include_deleted_in_percent: bool
    rebuild_full: bool

    # mapping sources
    map_teacher_id_email_path: Optional[Path]
    map_email_hr_path: Optional[Path]

    # rounding
    pct_round_decimals: int

    # period
    ay: Optional[str]
    term: Optional[str]


def _load_config(root: Path) -> dict:
    cfg_path = root / "config.yaml"
    if not cfg_path.exists():
        raise FileNotFoundError(f"Brak config.yaml pod: {cfg_path}")
    return yaml.safe_load(cfg_path.read_text(encoding="utf-8"))


def _resolve_path(root: Path, p: Optional[str]) -> Optional[Path]:
    if not p:
        return None
    pp = Path(p)
    return pp if pp.is_absolute() else (root / pp)


def _ensure_run_artifacts(run_dir: Path) -> None:
    run_dir.mkdir(parents=True, exist_ok=True)


def _log_progress(run_dir: Path, payload: dict) -> None:
    p = run_dir / "progress.jsonl"
    payload2 = dict(payload)
    payload2["ts"] = datetime.now(timezone.utc).isoformat()
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(payload2, ensure_ascii=False) + "\n")


def _write_ok(run_dir: Path) -> None:
    (run_dir / "compute-stats.ok").write_text(
        datetime.now(timezone.utc).isoformat(),
        encoding="utf-8",
    )


def _read_mapping_teacher_email(path: Optional[Path]) -> pd.DataFrame:
    """
    Oczekiwane kolumny: teacher_id (lub id), email (lub e-mail / mail)
    """
    if path is None:
        return pd.DataFrame(columns=["teacher_id", "email"])
    if not path.exists():
        raise FileNotFoundError(f"Brak pliku mapowania teacher_id→email: {path}")

    if path.suffix.lower() in [".xlsx", ".xls"]:
        df = pd.read_excel(path, dtype=str)
    else:
        df = pd.read_csv(path, dtype=str)

    df = df.rename(columns={c: c.strip() for c in df.columns})
    # normalizacja nazw (tolerancyjnie) — klucze lowercase bez spacji
    cols = {c.lower().strip(): c for c in df.columns}

    tid = (cols.get("teacher_id") or cols.get("id") or cols.get("userid"))

    # POPRAWKA C: dodane "e-mail" — kolumna w dane_do_raportu.csv
    eml = (cols.get("email") or cols.get("mail") or cols.get("e-mail"))

    if not tid or not eml:
        raise ValueError(
            f"Plik {path} musi mieć kolumny teacher_id/id oraz email/e-mail. "
            f"Dostępne kolumny: {list(df.columns)}"
        )

    out = df[[tid, eml]].copy()
    out.columns = ["teacher_id", "email"]
    out["teacher_id"] = out["teacher_id"].astype(str).str.strip()
    out["email"] = out["email"].astype(str).str.strip().str.lower()
    out = out.dropna().drop_duplicates()
    return out


def read_hr_table(hr_file: Path, sheet: str | None,
                  email_col: str, full_name_col: str | None,
                  wydzial_col: str | None, jednostka_col: str | None,
                  passthrough_cols: list[str] | None = None) -> pd.DataFrame:
    if not hr_file.exists():
        raise FileNotFoundError(f"Brak pliku HR: {hr_file}")

    if hr_file.suffix.lower() in [".xlsx", ".xls"]:
        df = pd.read_excel(hr_file, sheet_name=sheet or 0, dtype=str)
    else:
        df = pd.read_csv(hr_file, sep=None, engine="python", dtype=str)

    df = df.rename(columns={c: str(c).strip() for c in df.columns})

    def pick(colname: str | None) -> pd.Series:
        if not colname:
            return pd.Series([""] * len(df))
        if colname not in df.columns:
            raise ValueError(f"HR: brak kolumny '{colname}'. Dostępne: {list(df.columns)}")
        return df[colname].astype(str)

    out = pd.DataFrame()
    out["email"] = pick(email_col).str.strip().str.lower()
    out["full_name"] = pick(full_name_col).str.strip() if full_name_col else ""
    out["wydzial"] = pick(wydzial_col).str.strip() if wydzial_col else ""
    out["jednostka"] = pick(jednostka_col).str.strip() if jednostka_col else ""

    if passthrough_cols:
        for c in passthrough_cols:
            if c not in df.columns:
                raise ValueError(f"HR passthrough: brak kolumny '{c}'")
            out[c] = df[c].astype(str).str.strip()

    out = out[out["email"].notna() & (out["email"] != "")]
    out = out.drop_duplicates(subset=["email"])
    return out


def _read_mapping_email_hr(path: Optional[Path]) -> pd.DataFrame:
    """
    Oczekiwane minimum: email, full_name, wydzial, jednostka.
    
    POPRAWKA C: dodane polskie nazwy kolumn z dane_do_raportu.csv:
      - "Pełna nazwa" / "pelna nazwa"
      - "Wydział jednostki zatrudnienia"
      - "Jednostka podlegajaca rozliczeniu"
    """
    if path is None:
        return pd.DataFrame(columns=["email", "full_name", "wydzial", "jednostka"])
    if not path.exists():
        raise FileNotFoundError(f"Brak pliku mapowania email→HR: {path}")

    if path.suffix.lower() in [".xlsx", ".xls"]:
        df = pd.read_excel(path, dtype=str)
    else:
        df = pd.read_csv(path, dtype=str)

    df = df.rename(columns={c: c.strip() for c in df.columns})
    # klucze lowercase do tolerancyjnego dopasowania
    cols = {c.lower().strip(): c for c in df.columns}

    # email
    email = (cols.get("email") or cols.get("mail") or cols.get("e-mail"))

    # POPRAWKA C: dodane "pełna nazwa" i "pelna nazwa"
    full_name = (
        cols.get("full_name") or cols.get("imie_nazwisko") or
        cols.get("name") or cols.get("nazwiskoimie") or
        cols.get("pełna nazwa") or cols.get("pelna nazwa")
    )

    # POPRAWKA C: dodane "wydział jednostki zatrudnienia"
    wydzial = (
        cols.get("wydzial") or cols.get("wydział") or
        cols.get("wydzial jednostki zatrudnienia") or
        cols.get("wydział jednostki zatrudnienia")
    )

    # POPRAWKA C: dodane "jednostka podlegajaca rozliczeniu"
    jednostka = (
        cols.get("jednostka") or cols.get("unit") or cols.get("katedra") or
        cols.get("jednostka podlegajaca rozliczeniu") or
        cols.get("jednostka podlegająca rozliczeniu")
    )

    if not email:
        raise ValueError(
            f"Plik HR {path} musi mieć kolumnę email/mail/e-mail. "
            f"Dostępne kolumny: {list(df.columns)}"
        )

    out = pd.DataFrame()
    out["email"] = df[email].astype(str).str.strip().str.lower()
    out["full_name"] = df[full_name].astype(str).str.strip() if full_name else ""
    out["wydzial"] = df[wydzial].astype(str).str.strip() if wydzial else ""
    out["jednostka"] = df[jednostka].astype(str).str.strip() if jednostka else ""

    out = out.dropna().drop_duplicates(subset=["email"])
    return out


# ----------------------------
# Main compute
# ----------------------------

def compute_stats(root: Path, ay: Optional[str] = None, term: Optional[str] = None) -> None:
    cfg = _load_config(root)

    paths_obj = ProjectPaths(root=root)

    # POPRAWKA A: szukamy db_path w config, fallback do ProjectPaths
    # Hierarchia: cfg["paths"]["db_path"] → cfg["duckdb_path"] → ProjectPaths
    db_path_str = None
    paths_cfg = cfg.get("paths") or {}
    if isinstance(paths_cfg, dict):
        db_path_str = paths_cfg.get("db_path")
    if not db_path_str:
        db_path_str = cfg.get("duckdb_path")

    duckdb_path = _resolve_path(root, db_path_str) if db_path_str else paths_obj.duckdb_path

    run_dir = _resolve_path(root, cfg.get("run_dir") or "_run") or (root / "_run")

    aggregation = cfg.get("aggregation", {}) or {}
    include_deleted_in_percent = bool(aggregation.get("include_deleted_in_percent", False))
    rebuild_full = bool(cfg.get("rebuild_full", False))

    pct_round_decimals = int(cfg.get("stats", {}).get("pct_round_decimals", 4))

    map_teacher_id_email_path = _resolve_path(root, cfg.get("mapping", {}).get("teacher_id_email"))
    map_email_hr_path = _resolve_path(root, cfg.get("mapping", {}).get("email_hr"))

    # okres: CLI ma pierwszeństwo, potem config
    ay_eff = ay or cfg.get("period", {}).get("ay")
    term_eff = term or cfg.get("period", {}).get("term")
    if not rebuild_full and (not ay_eff or not term_eff):
        raise ConfigError(
            "Brak ay/term. Ustaw period.ay + period.term w config.yaml albo podaj w CLI, albo włącz rebuild_full=true."
        )

    sc = StatsConfig(
        duckdb_path=duckdb_path,
        run_dir=run_dir,
        include_deleted_in_percent=include_deleted_in_percent,
        rebuild_full=rebuild_full,
        map_teacher_id_email_path=map_teacher_id_email_path,
        map_email_hr_path=map_email_hr_path,
        pct_round_decimals=pct_round_decimals,
        ay=ay_eff,
        term=term_eff,
    )

    _ensure_run_artifacts(sc.run_dir)
    _log_progress(sc.run_dir, {"step": "start", "duckdb_path": str(sc.duckdb_path)})

    df_tid_email = _read_mapping_teacher_email(sc.map_teacher_id_email_path)
    df_email_hr = _read_mapping_email_hr(sc.map_email_hr_path)

    con = duckdb.connect(str(sc.duckdb_path))
    try:
        con.execute("CREATE SCHEMA IF NOT EXISTS mart;")

        con.register("map_tid_email_df", df_tid_email)
        con.register("map_email_hr_df", df_email_hr)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW map_tid_email AS
            SELECT DISTINCT
                teacher_id,
                lower(trim(email)) AS email
            FROM map_tid_email_df
            WHERE teacher_id IS NOT NULL AND teacher_id <> ''
              AND email IS NOT NULL AND email <> '';
        """)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW map_email_hr AS
            SELECT DISTINCT
                lower(trim(email)) AS email,
                nullif(trim(full_name), '') AS full_name,
                nullif(trim(wydzial), '') AS wydzial,
                nullif(trim(jednostka), '') AS jednostka
            FROM map_email_hr_df
            WHERE email IS NOT NULL AND email <> '';
        """)

        period_where = ""
        if not sc.rebuild_full:
            period_where = "AND ay = ? AND term = ?"

        _log_progress(sc.run_dir, {"step": "prepare_events_period", "rebuild_full": sc.rebuild_full, "ay": sc.ay, "term": sc.term})

        con.execute(f"""
            CREATE OR REPLACE TEMP VIEW events_period AS
            SELECT
                course_code,
                ay,
                term,
                wydzial_code,
                kierunek_code,
                track_code,
                semester_code,
                ts_utc,
                teacher_id,
                operation,
                tech_key,
                activity_label,
                object_id,
                count_mode
            FROM events_canonical
            WHERE counted = true
            {period_where};
        """, ([] if sc.rebuild_full else [sc.ay, sc.term]))

        _log_progress(sc.run_dir, {"step": "join_activities_state"})

        con.execute("""
            CREATE OR REPLACE TEMP VIEW joined_state AS
            SELECT
                e.*,
                s.status_final,
                s.deleted_at,
                s.visible_last,
                s.confidence_deleted,
                CASE
                    WHEN s.activity_id IS NULL THEN 1 ELSE 0
                END AS qa_missing_state
            FROM events_period e
            LEFT JOIN mart.activities_state s
              ON s.course_code = e.course_code
             AND s.activity_id = e.object_id;
        """)

        _log_progress(sc.run_dir, {"step": "qa_teacher_mapping"})

        con.execute("""
            CREATE OR REPLACE TEMP VIEW teacher_enriched AS
            SELECT
                j.*,
                m.email,
                h.full_name,
                h.wydzial AS hr_wydzial,
                h.jednostka AS hr_jednostka,
                CASE WHEN m.email ILIKE '%@student.umw.edu.pl' THEN 1 ELSE 0 END AS is_student,
                CASE WHEN m.email IS NULL THEN 1 ELSE 0 END AS qa_missing_email,
                CASE WHEN m.email IS NOT NULL AND h.email IS NULL THEN 1 ELSE 0 END AS qa_missing_hr
            FROM joined_state j
            LEFT JOIN map_tid_email m
              ON m.teacher_id = j.teacher_id
            LEFT JOIN map_email_hr h
              ON h.email = m.email;
        """)

        con.execute("""
            CREATE TABLE IF NOT EXISTS mart.metrics_qa (
                ay VARCHAR,
                term VARCHAR,
                qa_type VARCHAR,
                teacher_id VARCHAR,
                course_code VARCHAR,
                tech_key VARCHAR,
                object_id VARCHAR,
                details VARCHAR,
                created_at TIMESTAMP
            );
        """)

        if not sc.rebuild_full:
            con.execute("DELETE FROM mart.metrics_qa WHERE ay = ? AND term = ?;", [sc.ay, sc.term])

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'STUDENT_IGNORED' AS qa_type,
                teacher_id, course_code, tech_key, object_id,
                'email=' || coalesce(email,'') AS details, now() AS created_at
            FROM teacher_enriched WHERE is_student = 1;
        """)

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'MISSING_EMAIL_MAPPING' AS qa_type,
                teacher_id, course_code, tech_key, object_id,
                'teacher_id has no email mapping' AS details, now() AS created_at
            FROM teacher_enriched WHERE is_student = 0 AND qa_missing_email = 1;
        """)

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'MISSING_HR_MAPPING' AS qa_type,
                teacher_id, course_code, tech_key, object_id,
                'email=' || coalesce(email,'') AS details, now() AS created_at
            FROM teacher_enriched WHERE is_student = 0 AND qa_missing_email = 0 AND qa_missing_hr = 1;
        """)

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'EVENT_WITHOUT_ACTIVITY_STATE' AS qa_type,
                teacher_id, course_code, tech_key, object_id,
                'no activities_state row for object_id' AS details, now() AS created_at
            FROM teacher_enriched WHERE qa_missing_state = 1;
        """)

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'CONFIDENCE_LT_1' AS qa_type,
                teacher_id, course_code, tech_key, object_id,
                'confidence_deleted=' || cast(confidence_deleted AS VARCHAR) AS details, now() AS created_at
            FROM teacher_enriched
            WHERE confidence_deleted IS NOT NULL AND confidence_deleted < 1;
        """)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW teacher_ok AS
            SELECT * FROM teacher_enriched
            WHERE is_student = 0 AND qa_missing_email = 0 AND qa_missing_hr = 0;
        """)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW visible_ok AS
            SELECT * FROM teacher_ok WHERE status_final = 'visible_active';
        """)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW qa_counts AS
            SELECT ay, term, teacher_id, course_code, tech_key,
                SUM(CASE WHEN status_final = 'deleted' THEN 1 ELSE 0 END) AS deleted_count,
                SUM(CASE WHEN status_final = 'hidden' THEN 1 ELSE 0 END) AS hidden_count,
                SUM(CASE WHEN status_final IS NULL OR status_final = 'unknown' THEN 1 ELSE 0 END) AS unknown_count,
                MAX(CASE WHEN confidence_deleted IS NOT NULL AND confidence_deleted < 1 THEN 1 ELSE 0 END) AS confidence_flag
            FROM teacher_ok GROUP BY 1,2,3,4,5;
        """)

        con.execute("""
            CREATE OR REPLACE TEMP VIEW counts_visible AS
            SELECT ay, term, teacher_id, course_code, wydzial_code, kierunek_code, tech_key,
                any_value(activity_label) AS activity_label,
                CASE
                    WHEN max(count_mode) = 'object-based' THEN COUNT(DISTINCT object_id)
                    ELSE COUNT(*)
                END AS count_value,
                CASE WHEN min(count_mode) <> max(count_mode) THEN 1 ELSE 0 END AS qa_mixed_count_mode
            FROM visible_ok GROUP BY 1,2,3,4,5,6,7;
        """)

        con.execute("""
            INSERT INTO mart.metrics_qa
            SELECT ay, term, 'MIXED_COUNT_MODE' AS qa_type,
                teacher_id, course_code, tech_key, NULL AS object_id,
                'min!=max count_mode in group' AS details, now() AS created_at
            FROM counts_visible WHERE qa_mixed_count_mode = 1;
        """)

        con.execute(f"""
            CREATE OR REPLACE TEMP VIEW metrics_core AS
            SELECT
                c.ay, c.term, c.teacher_id, c.course_code, c.wydzial_code, c.kierunek_code,
                c.tech_key, c.activity_label, c.count_value,
                ROUND(c.count_value / NULLIF(SUM(c.count_value) OVER (PARTITION BY c.ay, c.term, c.course_code, c.tech_key), 0), {sc.pct_round_decimals}) AS pct_course,
                ROUND(c.count_value / NULLIF(SUM(c.count_value) OVER (PARTITION BY c.ay, c.term, c.kierunek_code, c.tech_key), 0), {sc.pct_round_decimals}) AS pct_kierunek,
                ROUND(c.count_value / NULLIF(SUM(c.count_value) OVER (PARTITION BY c.ay, c.term, c.wydzial_code, c.tech_key), 0), {sc.pct_round_decimals}) AS pct_wydzial,
                ROUND(c.count_value / NULLIF(SUM(c.count_value) OVER (PARTITION BY c.ay, c.term, c.tech_key), 0), {sc.pct_round_decimals}) AS pct_uczelnia
            FROM counts_visible c;
        """)

        con.execute("""
            CREATE TABLE IF NOT EXISTS mart.metrics_long (
                ay VARCHAR, term VARCHAR, teacher_id VARCHAR,
                full_name VARCHAR, email VARCHAR, wydzial VARCHAR, jednostka VARCHAR,
                course_code VARCHAR, tech_key VARCHAR, activity_label VARCHAR,
                count_value BIGINT, pct_course DOUBLE, pct_kierunek DOUBLE,
                pct_wydzial DOUBLE, pct_uczelnia DOUBLE,
                deleted_count BIGINT, hidden_count BIGINT, unknown_count BIGINT,
                confidence_flag BOOLEAN
            );
        """)

        if not sc.rebuild_full:
            _log_progress(sc.run_dir, {"step": "incremental_delete_long", "ay": sc.ay, "term": sc.term})
            con.execute("DELETE FROM mart.metrics_long WHERE ay = ? AND term = ?;", [sc.ay, sc.term])
        else:
            _log_progress(sc.run_dir, {"step": "rebuild_full_long"})
            con.execute("DELETE FROM mart.metrics_long;")

        _log_progress(sc.run_dir, {"step": "insert_metrics_long"})

        con.execute("""
            INSERT INTO mart.metrics_long
            SELECT
                mc.ay, mc.term, mc.teacher_id,
                coalesce(h.full_name, '') AS full_name,
                coalesce(m.email, '') AS email,
                coalesce(h.wydzial, '') AS wydzial,
                coalesce(h.jednostka, '') AS jednostka,
                mc.course_code, mc.tech_key, mc.activity_label,
                mc.count_value, mc.pct_course, mc.pct_kierunek, mc.pct_wydzial, mc.pct_uczelnia,
                coalesce(qa.deleted_count, 0) AS deleted_count,
                coalesce(qa.hidden_count, 0) AS hidden_count,
                coalesce(qa.unknown_count, 0) AS unknown_count,
                coalesce(cast(qa.confidence_flag AS BOOLEAN), false) AS confidence_flag
            FROM metrics_core mc
            LEFT JOIN map_tid_email m ON m.teacher_id = mc.teacher_id
            LEFT JOIN map_email_hr h ON h.email = m.email
            LEFT JOIN qa_counts qa
              ON qa.teacher_id = mc.teacher_id
             AND qa.course_code = mc.course_code
             AND qa.tech_key = mc.tech_key
             AND qa.ay = mc.ay AND qa.term = mc.term;
        """)

        # metrics_wide
        tech_keys_rows = con.execute("SELECT DISTINCT tech_key FROM mart.metrics_long WHERE tech_key IS NOT NULL ORDER BY tech_key;").fetchall()
        tech_keys = [r[0] for r in tech_keys_rows]

        con.execute("""
            CREATE TABLE IF NOT EXISTS mart.metrics_wide (
                ay VARCHAR, term VARCHAR, teacher_id VARCHAR, course_code VARCHAR
            );
        """)

        if not sc.rebuild_full:
            con.execute("DELETE FROM mart.metrics_wide WHERE ay = ? AND term = ?;", [sc.ay, sc.term])
        else:
            con.execute("DELETE FROM mart.metrics_wide;")

        if tech_keys:
            def safe_col(s: str) -> str:
                return "".join(ch if ch.isalnum() else "_" for ch in s)

            select_cols = ["ay", "term", "teacher_id", "course_code"]
            for tk in tech_keys:
                c = safe_col(tk)
                select_cols.append(f"MAX(CASE WHEN tech_key='{tk}' THEN count_value END) AS count_{c}")
                select_cols.append(f"MAX(CASE WHEN tech_key='{tk}' THEN pct_course END) AS pct_course_{c}")
                select_cols.append(f"MAX(CASE WHEN tech_key='{tk}' THEN pct_kierunek END) AS pct_kierunek_{c}")
                select_cols.append(f"MAX(CASE WHEN tech_key='{tk}' THEN pct_wydzial END) AS pct_wydzial_{c}")
                select_cols.append(f"MAX(CASE WHEN tech_key='{tk}' THEN pct_uczelnia END) AS pct_uczelnia_{c}")

            wide_sql = f"""
                INSERT INTO mart.metrics_wide
                SELECT {", ".join(select_cols)}
                FROM mart.metrics_long
                {"WHERE ay = ? AND term = ?" if not sc.rebuild_full else ""}
                GROUP BY ay, term, teacher_id, course_code;
            """

            if not sc.rebuild_full:
                con.execute(wide_sql, [sc.ay, sc.term])
            else:
                con.execute(wide_sql)

        _log_progress(sc.run_dir, {"step": "done"})
        _write_ok(sc.run_dir)

    finally:
        con.close()


================================================================================
src\mrna_plum\store\__init__.py
================================================================================

from .duckdb_store import DuckDbStore
__all__ = ["DuckDbStore"]


================================================================================
src\mrna_plum\store\database.py
================================================================================

# src/mrna_plum/store/database.py

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import pandas as pd


class EventStore:
    def __init__(self, cfg: Dict[str, Any]):
        self.cfg = cfg
        self.db_path = Path(cfg["paths"]["db_path"])
        self.parquet_root = Path(cfg["paths"]["parquet_root"]) if cfg.get("paths", {}).get("parquet_root") else None

    def _connect(self):
        import duckdb
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        return duckdb.connect(str(self.db_path))

    def ensure_schema(self) -> None:
        con = self._connect()
        try:
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS events_canonical_raw (
                    row_key VARCHAR,
                    course VARCHAR,
                    course_code VARCHAR,
                    wydzial_code VARCHAR,
                    kierunek_code VARCHAR,
                    track_code VARCHAR,
                    semester_code VARCHAR,
                    course_name VARCHAR,
                    ay VARCHAR,
                    term VARCHAR,
                    ts_utc TIMESTAMP,
                    teacher_id BIGINT,
                    operation VARCHAR,
                    tech_key VARCHAR,
                    activity_label VARCHAR,
                    object_id BIGINT,
                    count_mode VARCHAR,
                    raw_line_hash VARCHAR,
                    source_file VARCHAR,
                    payload_json VARCHAR
                );
                """
            )
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS events_conflicts (
                    row_key VARCHAR,
                    course_code VARCHAR,
                    teacher_id BIGINT,
                    tech_key VARCHAR,
                    operation VARCHAR,
                    object_id BIGINT,
                    note VARCHAR
                );
                """
            )
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS events_canonical (
                    -- finalna tabela do statystyk
                    row_key VARCHAR,
                    course VARCHAR,
                    course_code VARCHAR,
                    wydzial_code VARCHAR,
                    kierunek_code VARCHAR,
                    track_code VARCHAR,
                    semester_code VARCHAR,
                    course_name VARCHAR,
                    ay VARCHAR,
                    term VARCHAR,
                    ts_utc TIMESTAMP,
                    teacher_id BIGINT,
                    operation VARCHAR,
                    tech_key VARCHAR,
                    activity_label VARCHAR,
                    object_id BIGINT,
                    count_mode VARCHAR,
                    counted BOOLEAN,
                    raw_line_hash VARCHAR,
                    source_file VARCHAR
                );
                """
            )
            # indeksy logiczne / dedup incremental
            con.execute("CREATE UNIQUE INDEX IF NOT EXISTS ux_events_canonical_raw_rowkey ON events_canonical_raw(row_key);")
            con.execute("CREATE UNIQUE INDEX IF NOT EXISTS ux_events_canonical_rowkey ON events_canonical(row_key);")
        finally:
            con.close()

    def insert_raw_batch(self, rows: List[Dict[str, Any]]) -> int:
        if not rows:
            return 0
        con = self._connect()
        try:
            df = pd.DataFrame(rows)
            con.register("df_batch", df)
            # INSERT OR IGNORE po unique index (duckdb: użyj anti-join)
            con.execute(
                """
                INSERT INTO events_canonical_raw
                SELECT b.*
                FROM df_batch b
                LEFT JOIN events_canonical_raw e ON e.row_key = b.row_key
                WHERE e.row_key IS NULL;
                """
            )
            return len(rows)
        finally:
            con.close()

    def insert_conflicts_batch(self, rows: List[Dict[str, Any]]) -> int:
        if not rows:
            return 0
        con = self._connect()
        try:
            df = pd.DataFrame(rows)
            con.register("df_conf", df)
            con.execute("INSERT INTO events_conflicts SELECT * FROM df_conf;")
            return len(rows)
        finally:
            con.close()

    def finalize_canonical(self) -> int:
        """
        Zasada:
        - count_mode TAK_FLAG + TAK dla tego samego (course_code, teacher_id, tech_key, object_id)
          -> counted = false dla tych zdarzeń (unieważnienie)
        - jeśli object_id IS NULL -> liczymy event-based: counted=true jeśli count_mode='TAK'
        """
        con = self._connect()
        try:
            # przetwarzaj tylko nowe row_key
            con.execute(
                """
                INSERT INTO events_canonical
                WITH base AS (
                    SELECT r.*
                    FROM events_canonical_raw r
                    LEFT JOIN events_canonical c ON c.row_key = r.row_key
                    WHERE c.row_key IS NULL
                ),
                has_both AS (
                    SELECT
                        course_code,
                        teacher_id,
                        tech_key,
                        object_id,
                        MAX(CASE WHEN upper(count_mode)='TAK' THEN 1 ELSE 0 END) AS has_tak,
                        MAX(CASE WHEN upper(count_mode)='TAK_FLAG' THEN 1 ELSE 0 END) AS has_flag
                    FROM base
                    WHERE object_id IS NOT NULL
                    GROUP BY 1,2,3,4
                )
                SELECT
                    b.row_key,
                    b.course,
                    b.course_code,
                    b.wydzial_code,
                    b.kierunek_code,
                    b.track_code,
                    b.semester_code,
                    b.course_name,
                    b.ay,
                    b.term,
                    b.ts_utc,
                    b.teacher_id,
                    b.operation,
                    b.tech_key,
                    b.activity_label,
                    b.object_id,
                    b.count_mode,
                    CASE
                        WHEN b.object_id IS NULL THEN (upper(b.count_mode)='TAK')
                        ELSE (
                            NOT EXISTS (
                                SELECT 1 FROM has_both hb
                                WHERE hb.course_code=b.course_code
                                  AND hb.teacher_id=b.teacher_id
                                  AND hb.tech_key=b.tech_key
                                  AND hb.object_id=b.object_id
                                  AND hb.has_tak=1 AND hb.has_flag=1
                            )
                            AND (upper(b.count_mode)='TAK')
                        )
                    END AS counted,
                    b.raw_line_hash,
                    b.source_file
                FROM base b;
                """
            )

            # duckdb nie zwraca rowcount wprost stabilnie; policzmy różnicę
            res = con.execute("SELECT COUNT(*) FROM events_canonical;").fetchone()
            return int(res[0]) if res else 0
        finally:
            con.close()

    def export_parquet(self) -> Optional[Path]:
        if not self.parquet_root:
            return None
        out = self.parquet_root / "events_canonical.parquet"
        self.parquet_root.mkdir(parents=True, exist_ok=True)
        con = self._connect()
        try:
            con.execute(f"COPY (SELECT * FROM events_canonical) TO '{str(out).replace('\\\\', '/')}' (FORMAT PARQUET);")
            return out
        finally:
            con.close()

================================================================================
src\mrna_plum\store\duckdb_store.py
================================================================================

from __future__ import annotations
from pathlib import Path
import duckdb


import json
import hashlib
from dataclasses import dataclass
from typing import Iterable, Optional

class DuckDbStore:
    def __init__(self, db_path: Path):
        db_path.parent.mkdir(parents=True, exist_ok=True)
        self.db_path = db_path

    def connect(self) -> duckdb.DuckDBPyConnection:
        return duckdb.connect(str(self.db_path))

    def init_schema(self) -> None:
        with self.connect() as con:
            con.execute("""
                CREATE TABLE IF NOT EXISTS raw_logs (
                    _source_file VARCHAR,
                    "Czas" VARCHAR,
                    "Kontekst zdarzenia" VARCHAR,
                    "Opis" VARCHAR,
                    "Składnik" VARCHAR,
                    "Nazwa zdarzenia" VARCHAR,
                    course_code VARCHAR,
                    course_id BIGINT,
                    period VARCHAR,
                    tech_key VARCHAR,
                    activity VARCHAR,
                    operation VARCHAR,
                    count_to_report BOOLEAN,
                    teacher_id VARCHAR,
                    object_id VARCHAR,
                    rule_priority INTEGER
                );
            """)
            con.execute("""
                CREATE TABLE IF NOT EXISTS stats_agg (
                    period VARCHAR,
                    course_code VARCHAR,
                    teacher_id VARCHAR,
                    tech_key VARCHAR,
                    cnt_events BIGINT,
                    cnt_objects BIGINT,
                    is_invalidated BOOLEAN
                );
            """)

    def load_parquet_to_raw(self, parquet_path: Path) -> None:
        with self.connect() as con:
            # prosty append; w praktyce możesz TRUNCATE per-run
            con.execute("INSERT INTO raw_logs SELECT * FROM read_parquet(?)", [str(parquet_path)])



@dataclass(frozen=True)
class EventRawRow:
    course: str
    course_id: Optional[int]
    time_text: Optional[str]
    time_ts_iso: Optional[str]  # ISO string (UTC/naive) lub None
    row_key: str                # sha256(normalized_fields_join)
    payload_json: str           # JSON dict: header->value
    source_file: str            # pełna ścieżka lub nazwa


def _connect(db_path: Path) -> duckdb.DuckDBPyConnection:
    db_path.parent.mkdir(parents=True, exist_ok=True)
    con = duckdb.connect(str(db_path))
    # bezpieczne ustawienia, brak wymogów
    return con


def ensure_schema(con: duckdb.DuckDBPyConnection) -> None:
    con.execute(
        """
        CREATE TABLE IF NOT EXISTS events_raw (
            course       TEXT NOT NULL,
            time_text    TEXT,
            time_ts      TIMESTAMP,
            row_key      TEXT NOT NULL,
            payload_json TEXT NOT NULL,
            source_file  TEXT NOT NULL,
            inserted_at  TIMESTAMP DEFAULT now()
        );
        """
    )
    # indeksy opcjonalnie (DuckDB "CREATE INDEX" działa w nowszych wersjach)
    try:
        con.execute("CREATE INDEX IF NOT EXISTS idx_events_raw_course ON events_raw(course);")
    except Exception:
        pass
    try:
        con.execute("CREATE INDEX IF NOT EXISTS idx_events_raw_rowkey ON events_raw(row_key);")
    except Exception:
        pass


def create_stage_table(con: duckdb.DuckDBPyConnection) -> None:
    con.execute("DROP TABLE IF EXISTS _events_raw_stage;")
    con.execute(
        """
        CREATE TEMP TABLE _events_raw_stage (
            course       TEXT NOT NULL,
            time_text    TEXT,
            time_ts      TIMESTAMP,
            row_key      TEXT NOT NULL,
            payload_json TEXT NOT NULL,
            source_file  TEXT NOT NULL
        );
        """
    )


def insert_stage_rows(con: duckdb.DuckDBPyConnection, rows: list[EventRawRow]) -> None:
    if not rows:
        return
    params = [
        (
            r.course,
            r.time_text,
            r.time_ts_iso,  # DuckDB potrafi zrzucić ISO->TIMESTAMP
            r.row_key,
            r.payload_json,
            r.source_file,
        )
        for r in rows
    ]
    con.executemany(
        """
        INSERT INTO _events_raw_stage(course, time_text, time_ts, row_key, payload_json, source_file)
        VALUES (?, ?, ?, ?, ?, ?);
        """,
        params,
    )


def merge_stage_into_events_raw(con: duckdb.DuckDBPyConnection) -> int:
    """
    Dedup: tylko jeśli CAŁY wiersz identyczny (po Trim, bez BOM, bez CR).
    My realizujemy to przez:
      - payload_json z trimowanymi wartościami
      - row_key = sha256(normalized_fields_join)
    Wstawiamy tylko jeśli (course,row_key,payload_json) nie istnieje.
    """
    res = con.execute(
        """
        INSERT INTO events_raw(course, time_text, time_ts, row_key, payload_json, source_file)
        SELECT s.course, s.time_text, s.time_ts, s.row_key, s.payload_json, s.source_file
        FROM _events_raw_stage s
        LEFT JOIN events_raw e
          ON e.course = s.course
         AND e.row_key = s.row_key
         AND e.payload_json = s.payload_json
        WHERE e.course IS NULL;
        """
    )
    # DuckDB python: rowcount by cursor.rowcount is not always reliable; use changes()
    try:
        return con.execute("SELECT COUNT(*) FROM _events_raw_stage").fetchone()[0]
    except Exception:
        return 0


def open_store(db_path: Path) -> duckdb.DuckDBPyConnection:
    con = _connect(db_path)
    ensure_schema(con)
    return con


def export_course_to_csv(
    con: duckdb.DuckDBPyConnection,
    *,
    course: str,
    out_csv: Path,
) -> None:
    """
    CSV-compat: zapis *_full_log.csv posortowany po time_ts malejąco (jeśli jest),
    w przeciwnym razie stabilnie po inserted_at.
    Zapisujemy same payload_json jako jedną kolumnę? – NIE: eksportujemy jako CSV z kolumną payload_json.
    (Jeśli potrzebujesz 1:1 zgodności z VBA-headerami, da się to rozwinąć później na etapie parse.)
    """
    out_csv.parent.mkdir(parents=True, exist_ok=True)
    con.execute(
        f"""
        COPY (
            SELECT course, time_text, time_ts, payload_json, source_file
            FROM events_raw
            WHERE course = ?
            ORDER BY
              CASE WHEN time_ts IS NULL THEN 1 ELSE 0 END,
              time_ts DESC,
              inserted_at DESC
        )
        TO ?
        (HEADER, DELIMITER ';', QUOTE '"', ESCAPE '"');
        """,
        [course, str(out_csv)],
    )


def export_course_to_parquet(
    con: duckdb.DuckDBPyConnection,
    *,
    course: str,
    out_parquet: Path,
) -> None:
    out_parquet.parent.mkdir(parents=True, exist_ok=True)
    con.execute(
        """
        COPY (
            SELECT course, time_text, time_ts, payload_json, source_file, inserted_at
            FROM events_raw
            WHERE course = ?
            ORDER BY
              CASE WHEN time_ts IS NULL THEN 1 ELSE 0 END,
              time_ts DESC,
              inserted_at DESC
        )
        TO ?
        (FORMAT PARQUET);
        """,
        [course, str(out_parquet)],    )


================================================================================
src\mrna_plum\tests\__init__.py
================================================================================



================================================================================
src\mrna_plum\tests\test_build_activities_state.py
================================================================================

from __future__ import annotations

from datetime import datetime
import duckdb
import pytest

from mrna_plum.activities.activities_state import (
    BuildConfig, DeletionConfig, MappingConfig, IncrementalConfig, build_activities_state
)

def _cfg(**kw):
    return BuildConfig(
        deletion=DeletionConfig(
            delete_operations=kw.get("delete_operations", ["DELETE"]),
            delete_tech_keys=kw.get("delete_tech_keys", []),
            delete_activity_labels_regex=[],
            disappearance_grace_period_days=kw.get("grace", 14),
            min_missing_snapshots_to_confirm=kw.get("min_missing", 2),
            deleted_at_policy=kw.get("policy", "first_missing"),
        ),
        mapping=MappingConfig(
            use_activity_id_map_table=True,
            allow_fuzzy_name_type_match=False,
        ),
        incremental=IncrementalConfig(
            checkpoint_table="raw.pipeline_checkpoints",
            checkpoint_key="build_activities_state",
            process_only_new_snapshots=False,
            process_only_new_events=False,
        ),
    )

def setup_base(con):
    con.execute("create schema if not exists raw;")
    con.execute("create schema if not exists mart;")

    con.execute("""
      create table events_canonical (
        course_code varchar,
        ay varchar,
        term varchar,
        wydzial_code varchar,
        kierunek_code varchar,
        track_code varchar,
        semester_code varchar,
        ts_utc timestamp,
        teacher_id varchar,
        operation varchar,
        tech_key varchar,
        activity_label varchar,
        object_id varchar,
        count_mode varchar,
        row_key varchar,
        source_file varchar,
        counted boolean
      );
    """)
    con.execute("""
      create table raw.activities_snapshot(
        course_code varchar,
        activity_id varchar,
        name varchar,
        type varchar,
        visible_to_students boolean,
        captured_at timestamp,
        source_file varchar,
        row_key varchar
      );
    """)
    con.execute("""
      create table raw.activity_id_map(
        course_code varchar,
        activity_id varchar,
        object_id varchar,
        map_method varchar,
        confidence double,
        first_seen_at timestamp,
        last_seen_at timestamp,
        primary key(course_code, activity_id)
      );
    """)

def test_delete_from_logs():
    con = duckdb.connect(":memory:")
    setup_base(con)

    con.execute("""
      insert into raw.activities_snapshot values
      ('C1','101','Quiz 1','quiz', true, '2026-02-01 10:00:00','f.csv','rk1'),
      ('C1','101','Quiz 1','quiz', true, '2026-02-10 10:00:00','f.csv','rk2')
    """)

    con.execute("""
      insert into events_canonical values
      ('C1','2025/26','Z','W1','K1','T1','S1','2026-02-05 12:00:00','U1','DELETE','tk_del','', '101','object-based','e1','e.csv', true)
    """)

    stats = build_activities_state(con, _cfg(delete_operations=["DELETE"]))
    row = con.execute("select status_final, evidence_deleted, deleted_at from mart.activities_state where course_code='C1' and activity_id='101'").fetchone()
    assert row[0] == "visible_deleted"
    assert row[1] in ("log_delete_event", "both")
    assert row[2] is not None

def test_disappearance_from_snapshots():
    con = duckdb.connect(":memory:")
    setup_base(con)

    # snapshoty kursu: aktywność znika po 2026-02-01, potem mamy 2 snapshoty bez niej i grace spełniony
    con.execute("""
      insert into raw.activities_snapshot values
      ('C1','200','Page A','page', true, '2026-02-01 10:00:00','f.csv','a1'),
      ('C1','201','Other','page', true, '2026-02-08 10:00:00','f.csv','a2'),
      ('C1','201','Other','page', true, '2026-02-20 10:00:00','f.csv','a3')
    """)
    # brak eventów

    stats = build_activities_state(con, _cfg(grace=7, min_missing=2, policy="first_missing"))
    row = con.execute("select status_final, evidence_deleted from mart.activities_state where course_code='C1' and activity_id='200'").fetchone()
    assert row[1] == "snapshot_disappearance"
    assert row[0] == "visible_deleted"

def test_hidden():
    con = duckdb.connect(":memory:")
    setup_base(con)

    con.execute("""
      insert into raw.activities_snapshot values
      ('C1','300','Forum','forum', false, '2026-02-20 10:00:00','f.csv','h1')
    """)
    stats = build_activities_state(con, _cfg())
    row = con.execute("select status_final from mart.activities_state where course_code='C1' and activity_id='300'").fetchone()
    assert row[0] == "hidden"

def test_conflict_log_delete_but_snapshot_visible():
    con = duckdb.connect(":memory:")
    setup_base(con)

    con.execute("""
      insert into raw.activities_snapshot values
      ('C1','400','H5P','h5p', true, '2026-02-20 10:00:00','f.csv','c1')
    """)
    con.execute("""
      insert into events_canonical values
      ('C1','2025/26','Z','W1','K1','T1','S1','2026-02-10 12:00:00','U1','DELETE','tk_del','', '400','object-based','e1','e.csv', true)
    """)
    build_activities_state(con, _cfg(delete_operations=["DELETE"]))
    qa = con.execute("select count(*) from mart.activities_qa where qa_type='conflict_log_delete_but_visible_in_snapshot'").fetchone()[0]
    assert qa >= 1

def test_missing_mapping_activity_to_object():
    con = duckdb.connect(":memory:")
    setup_base(con)

    # snapshot istnieje, ale w events brak object_id/akcji
    con.execute("""
      insert into raw.activities_snapshot values
      ('C1','500','URL','url', true, '2026-02-20 10:00:00','f.csv','m1')
    """)
    build_activities_state(con, _cfg())
    qa = con.execute("select count(*) from mart.activities_qa where qa_type='activity_without_object_id_mapping'").fetchone()[0]
    assert qa >= 1

================================================================================
src\mrna_plum\tests\test_compute_stats.py
================================================================================

import duckdb
from pathlib import Path
from mrna_plum.stats.compute_stats import compute_stats

def test_pct_course_two_teachers(tmp_path: Path):
    db = tmp_path / "w.duckdb"
    con = duckdb.connect(str(db))

    con.execute("CREATE SCHEMA mart;")

    con.execute("""
        CREATE TABLE events_canonical (
            course_code VARCHAR, ay VARCHAR, term VARCHAR,
            wydzial_code VARCHAR, kierunek_code VARCHAR, track_code VARCHAR, semester_code VARCHAR,
            ts_utc TIMESTAMP, teacher_id VARCHAR, operation VARCHAR,
            tech_key VARCHAR, activity_label VARCHAR, object_id VARCHAR, count_mode VARCHAR,
            counted BOOLEAN
        );
    """)

    con.execute("""
        CREATE TABLE mart.activities_state (
            course_code VARCHAR, activity_id VARCHAR,
            status_final VARCHAR, deleted_at TIMESTAMP,
            visible_last BOOLEAN, confidence_deleted DOUBLE
        );
    """)

    # 2 nauczycieli, ta sama aktywność "PAGE"
    con.execute("""
        INSERT INTO events_canonical VALUES
        ('C1','2025/26','Z','W1','K1','T1','S1', now(), 'T_A','CREATE','PAGE','Strona','10','object-based', true),
        ('C1','2025/26','Z','W1','K1','T1','S1', now(), 'T_B','CREATE','PAGE','Strona','11','object-based', true);
    """)

    con.execute("""
        INSERT INTO mart.activities_state VALUES
        ('C1','10','visible_active', NULL, true, 1.0),
        ('C1','11','visible_active', NULL, true, 1.0);
    """)

    # mapping
    # tu najprościej: zrobisz pliki CSV/XLSX w tmp_path i wskażesz config.yaml
    # ... (pomijam dla czytelności – ale test ma sprawdzić, że oba wejdą do long)
    con.close()

    # prepare root with config + mapping files, then compute_stats(root)
    # then assert pct_course = 0.5 and 0.5

================================================================================
src\mrna_plum\tests\test_export_excel.py
================================================================================

import duckdb
import pytest
from pathlib import Path

from mrna_plum.reports.export_excel import export_summary_excel, ExportOverflowError


def _mk_con_with_tables():
    con = duckdb.connect(":memory:")
    con.execute("CREATE SCHEMA mart;")

    con.execute("""
        CREATE TABLE mart.metrics_long (
            full_name VARCHAR,
            teacher_id VARCHAR,
            course_code VARCHAR,
            tech_key VARCHAR,
            activity_label VARCHAR,
            count_value BIGINT,
            pct_course DOUBLE,
            pct_program DOUBLE,
            pct_faculty DOUBLE,
            pct_university DOUBLE,
            visible_active BOOLEAN
        );
    """)

    con.execute("""
        CREATE TABLE mart.metrics_qa (
            type VARCHAR,
            teacher_id VARCHAR,
            course_code VARCHAR,
            tech_key VARCHAR,
            description VARCHAR
        );
    """)
    return con


def _cfg(tmp_root: Path, **overrides):
    cfg = {
        "root": str(tmp_root),
        "report": {"ay": "2025_2026", "term": "Z"},
        "export": {"max_rows_excel": 1_000_000, "overflow_strategy": "error", "activity_column": "tech_key"},
    }
    # shallow merge
    for k, v in overrides.items():
        if k in cfg and isinstance(cfg[k], dict) and isinstance(v, dict):
            cfg[k].update(v)
        else:
            cfg[k] = v
    return cfg


def test_generates_file_when_data_exists(tmp_path: Path):
    con = _mk_con_with_tables()
    con.execute("""
        INSERT INTO mart.metrics_long VALUES
        ('Anna Nowak','10','BIO101','PAGE','Strona',3,12.3,4.5,1.1,0.2, TRUE),
        ('Anna Nowak','10','BIO101','URL','Adres URL',1, 1.0,0.5,0.2,0.1, TRUE);
    """)
    con.execute("INSERT INTO mart.metrics_qa VALUES ('teacher_id NOT_IN_HR','999','BIO101','PAGE','no HR');")

    cfg = _cfg(tmp_path)
    code, out_path = export_summary_excel(con, cfg)

    assert code == 0
    assert out_path.exists()
    assert (tmp_path / "_run" / "export-excel.ok").exists()
    assert (tmp_path / "_run" / "run.log").exists()
    assert (tmp_path / "_run" / "progress.jsonl").exists()


def test_generates_correct_row_count(tmp_path: Path):
    con = _mk_con_with_tables()
    con.execute("""
        INSERT INTO mart.metrics_long SELECT
            'Jan Kowalski', '1', 'C1', 'A', 'a', 1, 1.1, 2.2, 3.3, 4.4, TRUE
        FROM range(0, 123);
    """)
    cfg = _cfg(tmp_path)
    code, out_path = export_summary_excel(con, cfg)
    assert code == 0
    assert out_path.exists()
    # We don't parse XLSX here (fast test); we ensure INFO counts exist by querying SQL:
    # (INFO sheet writing uses SQL counts; if export didn't crash, it ran)


def test_qa_sheet_is_created_even_if_empty(tmp_path: Path):
    con = _mk_con_with_tables()
    con.execute("""
        INSERT INTO mart.metrics_long VALUES
        ('A A','1','C1','X','x',1,1,1,1,1, TRUE);
    """)
    # QA empty
    cfg = _cfg(tmp_path)
    code, out_path = export_summary_excel(con, cfg)
    assert code == 0
    assert out_path.exists()


def test_sorting_is_sql_ordered(tmp_path: Path):
    con = _mk_con_with_tables()
    # Insert in reverse order; SQL ORDER BY should output A then B, and tech_key sorted
    con.execute("""
        INSERT INTO mart.metrics_long VALUES
        ('B','2','C2','ZZ','zz',1,1,1,1,1, TRUE),
        ('A','1','C1','BB','bb',1,1,1,1,1, TRUE),
        ('A','1','C1','AA','aa',1,1,1,1,1, TRUE);
    """)
    cfg = _cfg(tmp_path)

    # We validate ordering by executing the same SQL builder logic indirectly:
    # minimal assert: export completes; deeper ordering validation would require reading XLSX.
    code, _ = export_summary_excel(con, cfg)
    assert code == 0


def test_overflow_error_strategy_error(tmp_path: Path):
    con = _mk_con_with_tables()
    con.execute("""
        INSERT INTO mart.metrics_long
        SELECT 'X','1','C','A','a',1,1,1,1,1, TRUE
        FROM range(0, 11);
    """)
    cfg = _cfg(tmp_path, export={"max_rows_excel": 10, "overflow_strategy": "error"})
    with pytest.raises(ExportOverflowError):
        export_summary_excel(con, cfg)


def test_overflow_split_creates_file(tmp_path: Path):
    con = _mk_con_with_tables()
    con.execute("""
        INSERT INTO mart.metrics_long
        SELECT 'X','1','C','A','a',1,1,1,1,1, TRUE
        FROM range(0, 25);
    """)
    cfg = _cfg(tmp_path, export={"max_rows_excel": 10, "overflow_strategy": "split"})
    code, out_path = export_summary_excel(con, cfg)
    assert code == 0
    assert out_path.exists()


def test_no_data_creates_xlsx_with_headers_and_info(tmp_path: Path):
    con = _mk_con_with_tables()
    # no rows
    cfg = _cfg(tmp_path)
    code, out_path = export_summary_excel(con, cfg)
    assert code == 0
    assert out_path.exists()

================================================================================
src\mrna_plum\tests\test_export_individual.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path

import duckdb
import openpyxl

from mrna_plum.reports.export_individual import export_individual_reports, sanitize_filename


@dataclass
class Cfg:
    root: str
    paths: object
    reports: object


@dataclass
class Paths:
    db_path: str


@dataclass
class Reports:
    individual_dir: str = "_out/indywidualne"
    max_workers: int = 1  # tests: deterministic, no threads
    batch_teachers: int = 50
    create_empty_individual: bool = False


def _make_db(tmp_path: Path) -> duckdb.DuckDBPyConnection:
    db_path = tmp_path / "test.duckdb"
    con = duckdb.connect(str(db_path))
    con.execute("CREATE SCHEMA mart;")
    con.execute(
        """
        CREATE TABLE mart.metrics_long (
            teacher_id      VARCHAR,
            full_name       VARCHAR,
            email           VARCHAR,
            id_bazus        VARCHAR,
            course_name     VARCHAR,
            activity_label  VARCHAR,
            count_value     BIGINT,
            pct_course      DOUBLE,
            pct_kierunek    DOUBLE,
            pct_wydzial     DOUBLE,
            pct_uczelnia    DOUBLE,
            visible_active  BOOLEAN,
            hr_wydzial      VARCHAR,
            hr_jednostka    VARCHAR
        );
        """
    )
    # Teacher A: 2 rows, one has count=0 (must be excluded)
    con.execute(
        """
        INSERT INTO mart.metrics_long VALUES
        ('10', 'Kowalski Jan', 'jan@x.pl', 'B123', 'Kurs A', 'Strona', 3,  50, 10, 5, 1, TRUE, 'WL', 'Katedra X'),
        ('10', 'Kowalski Jan', 'jan@x.pl', 'B123', 'Kurs A', 'Wiki',   0,  20, 10, 5, 1, TRUE, 'WL', 'Katedra X'),
        ('10', 'Kowalski Jan', 'jan@x.pl', 'B123', 'Kurs B', 'Adres URL', 2,  25, 10, 5, 1, TRUE, 'WL', 'Katedra X');
        """
    )
    # Teacher B: only zero rows -> should be SKIPPED and no file
    con.execute(
        """
        INSERT INTO mart.metrics_long VALUES
        ('11', 'Nowak/Anna:*?', 'a@x.pl', 'B999', 'Kurs Z', 'Strona', 0, 10, 1, 1, 1, TRUE, 'WF', 'Jedn Y');
        """
    )
    return con


def test_sanitize_filename_windows_chars():
    assert sanitize_filename('Nowak/Anna:*?') == "Nowak_Anna____"


def test_export_individual_generates_one_file(tmp_path: Path):
    con = _make_db(tmp_path)
    try:
        cfg = Cfg(
            root=str(tmp_path),
            paths=Paths(db_path=str(tmp_path / "test.duckdb")),
            reports=Reports(),
        )
        code, out_dir = export_individual_reports(con, cfg)
        assert code == 0

        out_dir = Path(out_dir)
        files = sorted(out_dir.glob("*.xlsx"))
        # only teacher_id=10 should have file
        assert len(files) == 1
        assert files[0].name.endswith("_10.xlsx")
        assert "Kowalski Jan" in files[0].name

        wb = openpyxl.load_workbook(files[0])
        assert "DANE_KURSY" in wb.sheetnames
        assert "DANE_PERS" in wb.sheetnames

        ws = wb["DANE_KURSY"]
        headers = [ws.cell(1, c).value for c in range(1, 8)]
        assert headers == ["Kurs", "Aktywność", "Liczba", "% kurs", "% kierunek", "% wydział", "% uczelnia"]

        # rows: should exclude count=0, and sorted deterministically
        rows = []
        for r in range(2, ws.max_row + 1):
            rows.append([ws.cell(r, c).value for c in range(1, 8)])
        # expect two rows
        assert len(rows) == 2
        # deterministic sort: Kurs A / Strona first, Kurs B / Adres URL second
        assert rows[0][0] == "Kurs A"
        assert rows[0][1] == "Strona"
        assert rows[1][0] == "Kurs B"
        assert rows[1][1] == "Adres URL"

        # pct in XLSX: stored as 0.xx (not 50)
        # openpyxl reads raw numeric value (formatting is separate)
        assert abs(float(rows[0][3]) - 0.50) < 1e-9

        ws2 = wb["DANE_PERS"]
        # find ID_PLUM row
        kv = {ws2.cell(r, 1).value: ws2.cell(r, 2).value for r in range(2, ws2.max_row + 1)}
        assert kv["ID_PLUM"] == "10"
        assert kv["Pełna nazwa"] == "Kowalski Jan"
        assert kv["E-mail"] == "jan@x.pl"
        assert kv["ID bazus"] == "B123"
        assert kv["Wydział"] == "WL"
        assert kv["Jednostka"] == "Katedra X"

    finally:
        con.close()


def test_export_individual_skips_teacher_with_only_zero_rows(tmp_path: Path):
    con = _make_db(tmp_path)
    try:
        cfg = Cfg(
            root=str(tmp_path),
            paths=Paths(db_path=str(tmp_path / "test.duckdb")),
            reports=Reports(),
        )
        code, out_dir = export_individual_reports(con, cfg)
        assert code == 0

        out_dir = Path(out_dir)
        # verify teacher 11 is not exported
        assert not any(p.name.endswith("_11.xlsx") for p in out_dir.glob("*.xlsx"))
    finally:
        con.close()

================================================================================
src\mrna_plum\ui_bridge\__init__.py
================================================================================

from .progress import ProgressWriter
__all__ = ["ProgressWriter"]


================================================================================
src\mrna_plum\ui_bridge\progress.py
================================================================================

from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
import json
from pathlib import Path
from typing import Any, Optional

WARSAW = ZoneInfo("Europe/Warsaw")

@dataclass
class ProgressWriter:
    path: Path

    def emit(
        self,
        step: str,
        status: str,
        message: str,
        current: Optional[int] = None,
        total: Optional[int] = None,
        extra: Optional[dict[str, Any]] = None,
    ) -> None:
        self.path.parent.mkdir(parents=True, exist_ok=True)
        payload = {
            "ts": datetime.now(WARSAW).isoformat(),
            "step": step,
            "status": status,     # start|progress|done|error
            "message": message,
            "current": current,
            "total": total,
            "extra": extra or {},
        }
        with self.path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(payload, ensure_ascii=False) + "\n")


================================================================================
src\mrna_plum.egg-info\dependency_links.txt
================================================================================




================================================================================
src\mrna_plum.egg-info\entry_points.txt
================================================================================

[console_scripts]
mrna_plum = mrna_plum.cli:app


================================================================================
src\mrna_plum.egg-info\PKG-INFO
================================================================================

Metadata-Version: 2.4
Name: mrna-plum
Version: 0.1.0
Summary: mRNA-PLUM CLI (merge/parse/stats/export) for Moodle/PLUM logs
Requires-Python: >=3.10
Requires-Dist: typer>=0.12.0
Requires-Dist: PyYAML>=6.0
Requires-Dist: duckdb>=1.0.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: pyarrow>=15.0.0
Requires-Dist: openpyxl>=3.1.0


================================================================================
src\mrna_plum.egg-info\requires.txt
================================================================================

typer>=0.12.0
PyYAML>=6.0
duckdb>=1.0.0
pandas>=2.0.0
pyarrow>=15.0.0
openpyxl>=3.1.0


================================================================================
src\mrna_plum.egg-info\SOURCES.txt
================================================================================

pyproject.toml
src/mrna_plum/__init__.py
src/mrna_plum/__main__.py
src/mrna_plum/cli.py
src/mrna_plum/config.py
src/mrna_plum/errors.py
src/mrna_plum/logging_run.py
src/mrna_plum/paths.py
src/mrna_plum.egg-info/PKG-INFO
src/mrna_plum.egg-info/SOURCES.txt
src/mrna_plum.egg-info/dependency_links.txt
src/mrna_plum.egg-info/entry_points.txt
src/mrna_plum.egg-info/requires.txt
src/mrna_plum.egg-info/top_level.txt
src/mrna_plum/io/__init__.py
src/mrna_plum/io/csv_read.py
src/mrna_plum/io/excel_keys.py
src/mrna_plum/merge/__init__.py
src/mrna_plum/merge/merge_logs.py
src/mrna_plum/parse/__init__.py
src/mrna_plum/parse/context.py
src/mrna_plum/parse/parse_logs.py
src/mrna_plum/reports/__init__.py
src/mrna_plum/reports/export_excel.py
src/mrna_plum/reports/export_individual.py
src/mrna_plum/rules/__init__.py
src/mrna_plum/rules/engine.py
src/mrna_plum/rules/models.py
src/mrna_plum/stats/__init__.py
src/mrna_plum/stats/compute_stats.py
src/mrna_plum/store/__init__.py
src/mrna_plum/store/duckdb_store.py
src/mrna_plum/ui_bridge/__init__.py
src/mrna_plum/ui_bridge/progress.py

================================================================================
src\mrna_plum.egg-info\top_level.txt
================================================================================

mrna_plum


================================================================================
src\rna_plum.egg-info\dependency_links.txt
================================================================================




================================================================================
src\rna_plum.egg-info\entry_points.txt
================================================================================

[console_scripts]
rna_plum = rna_plum.cli:app


================================================================================
src\rna_plum.egg-info\PKG-INFO
================================================================================

Metadata-Version: 2.4
Name: rna-plum
Version: 0.1.0
Summary: RNA-PLUM CLI (merge/parse/stats/export) for Moodle/PLUM logs
Requires-Python: >=3.10
Requires-Dist: typer>=0.12.0
Requires-Dist: PyYAML>=6.0
Requires-Dist: duckdb>=1.0.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: pyarrow>=15.0.0
Requires-Dist: openpyxl>=3.1.0


================================================================================
src\rna_plum.egg-info\requires.txt
================================================================================

typer>=0.12.0
PyYAML>=6.0
duckdb>=1.0.0
pandas>=2.0.0
pyarrow>=15.0.0
openpyxl>=3.1.0


================================================================================
src\rna_plum.egg-info\SOURCES.txt
================================================================================

README.md
pyproject.toml
src/mrna_plum/__init__.py
src/mrna_plum/__main__.py
src/mrna_plum/cfg_helpers.py
src/mrna_plum/cli.py
src/mrna_plum/config.py
src/mrna_plum/errors.py
src/mrna_plum/init_project.py
src/mrna_plum/logging_run.py
src/mrna_plum/paths.py
src/mrna_plum/activities/__init__.py
src/mrna_plum/activities/activities_state.py
src/mrna_plum/activities/snapshots_load.py
src/mrna_plum/import/__init__.py
src/mrna_plum/import/import_roster.py
src/mrna_plum/inputs/__init__.py
src/mrna_plum/inputs/autodetect.py
src/mrna_plum/io/__init__.py
src/mrna_plum/io/csv_read.py
src/mrna_plum/io/excel_keys.py
src/mrna_plum/merge/__init__.py
src/mrna_plum/merge/merge_logs.py
src/mrna_plum/merge/test_merge_logs.py
src/mrna_plum/parse/__init__.py
src/mrna_plum/parse/context.py
src/mrna_plum/parse/parse_events.py
src/mrna_plum/parse/parse_logs.py
src/mrna_plum/reports/__init__.py
src/mrna_plum/reports/export_excel.py
src/mrna_plum/reports/export_individual.py
src/mrna_plum/rules/__init__.py
src/mrna_plum/rules/activity_rules.py
src/mrna_plum/rules/engine.py
src/mrna_plum/rules/models.py
src/mrna_plum/stats/__init__.py
src/mrna_plum/stats/compute_stats.py
src/mrna_plum/store/__init__.py
src/mrna_plum/store/database.py
src/mrna_plum/store/duckdb_store.py
src/mrna_plum/tests/__init__.py
src/mrna_plum/tests/test_build_activities_state.py
src/mrna_plum/tests/test_compute_stats.py
src/mrna_plum/tests/test_export_excel.py
src/mrna_plum/tests/test_export_individual.py
src/mrna_plum/ui_bridge/__init__.py
src/mrna_plum/ui_bridge/progress.py
src/rna_plum.egg-info/PKG-INFO
src/rna_plum.egg-info/SOURCES.txt
src/rna_plum.egg-info/dependency_links.txt
src/rna_plum.egg-info/entry_points.txt
src/rna_plum.egg-info/requires.txt
src/rna_plum.egg-info/top_level.txt

================================================================================
src\rna_plum.egg-info\top_level.txt
================================================================================

mrna_plum


================================================================================
vba\export_txt\mRNA-PLUM_VBA_20260226_142220.txt
================================================================================

﻿# VBA EXPORT
# Host: Microsoft Excel
# Project: VBAProject
# Date: 2026-02-26 14:22:20
# Components: 15
--------------------------------------------------------------------------------
================================================================================
=== Component: Ten_skoroszyt  [Document/Sheet Module]
================================================================================
Private Sub Workbook_Open()
    raporty_plum.Show vbModeless
End Sub


--------------------------------------------------------------------------------

================================================================================
=== Component: Arkusz1  [Document/Sheet Module]
================================================================================

--------------------------------------------------------------------------------

================================================================================
=== Component: raporty_plum  [UserForm]
================================================================================
Option Explicit

Private Sub Label3_Click()

End Sub

Private Sub UserForm_Initialize()

    Me.caption = "mRNA-PLUM — Raporty Nauczycieli Akademickich"

    ' wczytaj ostatnie ścieżki
    Me.txtLogsFolder.text = GetSetting("mRNA-PLUM", "Paths", "LogsFolder", "")
    Me.txtTemplateXlsx.text = ""

    ' KEYS: pamiętaj wybór, a jak brak to domyślnie root\_data\KEYS.xlsx
    Dim defKeys As String
    defKeys = ThisWorkbook.path & "\_data\KEYS.xlsx"

    Me.txtKeysXlsx.text = GetSetting("mRNA-PLUM", "Paths", "KeysXlsx", defKeys)
    Me.txtInputsDir.text = GetSetting("mRNA-PLUM", "Paths", "InputsDir", ThisWorkbook.path & "\_data\inputs")

    ResetProgress
    Me.LabelStatus.caption = "Gotowy."

End Sub


' =========================================================
' WYBÓR FOLDERU LOGÓW
' =========================================================
Private Sub btnPickLogsFolder_Click()

    Dim p As String
    p = modNA_UIInputs.PickFolderDialog( _
            "Wskaż folder nadrzędny z logami (z podfolderami)", _
            Me.txtLogsFolder.text)

    If Len(p) > 0 Then
        Me.txtLogsFolder.text = p
    End If

End Sub


' =========================================================
' WYBÓR TEMPLATE
' =========================================================
Private Sub btnPickTemplate_Click()

    Dim p As String
    p = modNA_UIInputs.PickFileDialog( _
            "Wskaż wzór raportu (Excel)", _
            "Excel", "*.xlsx", "")

    If Len(p) > 0 Then
        Me.txtTemplateXlsx.text = p
    End If

End Sub


' =========================================================
' START PIPELINE
' =========================================================
Private Sub btnStart_Click()

    Dim errMsg As String

    If Not modNA_UIInputs.UI_ValidateInputs(errMsg) Then
        MsgBox errMsg, vbExclamation
        Exit Sub
    End If

    ' Zapamiętaj folder logów
    SaveSetting "mRNA-PLUM", "Paths", "LogsFolder", Me.txtLogsFolder.text
    SaveSetting "mRNA-PLUM", "Paths", "KeysXlsx", Me.txtKeysXlsx.text
    SaveSetting "mRNA-PLUM", "Paths", "InputsDir", Me.txtInputsDir.text

    Me.btnStart.enabled = False
    Me.LabelStatus.caption = "Inicjalizacja..."

    modNA_Launcher.StartPipeline

End Sub


' =========================================================
' ZAMKNIJ
' =========================================================
Private Sub btnClose_Click()
    Unload Me
End Sub


' =========================================================
' PUBLIC — wywoływane z Launchera
' =========================================================

Public Sub SetStatus(ByVal txt As String)
    Me.LabelStatus.caption = txt
End Sub

Public Sub SetProgress(ByVal pct As Double, ByVal txt As String)

    If pct < 0 Then pct = 0
    If pct > 1 Then pct = 1

    Me.LabelBar.Width = Me.FrameBar.Width * pct
    Me.LabelPct.caption = Format(pct, "0%")
    Me.LabelStatus.caption = txt

End Sub

Public Sub ResetProgress()
    Me.LabelBar.Width = 0
    Me.LabelPct.caption = "0%"
End Sub

Public Sub SetRunning(ByVal running As Boolean)
    Me.btnStart.enabled = Not running
End Sub

Private Sub btnPickKeys_Click()

    Dim p As String
    p = modNA_UIInputs.PickFileDialog( _
            "Wskaż plik KEYS.xlsx (reguły parsowania)", _
            "Excel", "*.xlsx", _
            Me.txtKeysXlsx.text)

    If Len(p) > 0 Then
        Me.txtKeysXlsx.text = p
    End If

End Sub
Private Sub btnConvertXlsx_Click()
    On Error GoTo EH

    Dim src As String
    src = Trim$(Me.txtInputsDir.text) ' albo osobny textbox np. txtXlsxSourceFolder

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    ' normalizacja (często ratuje przy kopiuj/wklej)
    src = Replace$(src, """", "")
    src = Trim$(src)
    If Right$(src, 1) = "\" Then src = Left$(src, Len(src) - 1)

    If Len(src) = 0 Or Not fso.FolderExists(src) Then
        src = modNA_UIInputs.PickFolderDialog( _
                "Wskaż folder z XLSX do konwersji (z podfolderami)", _
                ThisWorkbook.path)
        If Len(src) = 0 Then Exit Sub
        Me.txtInputsDir.text = src
    End If

    Me.LabelStatus.caption = "Konwersja XLSX › CSV..."
    DoEvents

    modNA_Convert.ConvertXlsxFolderToCsv src, ThisWorkbook.path

    Me.LabelStatus.caption = "Konwersja zakończona."
    Exit Sub

EH:
    Me.LabelStatus.caption = "Błąd konwersji XLSX › CSV."
    MsgBox "Błąd: " & Err.Description, vbExclamation
End Sub
Private Sub btnMergeTeacherIdCsv_Click()
    On Error GoTo EH

    Me.LabelStatus.caption = "Scalanie CSV... wybierz 2 pliki."
    DoEvents

    Call MergeCsv_ByEmail

    Exit Sub
EH:
    Me.LabelStatus.caption = "Błąd scalania CSV."
    MsgBox "Błąd scalania CSV: " & Err.Description, vbExclamation
End Sub


Private Sub btnPickInputsDir_Click()
    Dim p As String
    p = modNA_UIInputs.PickFolderDialog( _
            "Wskaż folder z plikami źródłowymi", _
            Me.txtInputsDir.text)

    If Len(p) > 0 Then
        Me.txtInputsDir.text = p
    End If
End Sub

--------------------------------------------------------------------------------

================================================================================
=== Component: Autostart  [Standard Module]
================================================================================
Sub StartRaportowanie()
    frmMainMenu.Show vbModeless
End Sub
--------------------------------------------------------------------------------

================================================================================
=== Component: Autozamykanie  [Standard Module]
================================================================================
Sub ZamknijSkoroszyt()
    ThisWorkbook.Close SaveChanges:=False
End Sub
--------------------------------------------------------------------------------

================================================================================
=== Component: Arkusz2  [Document/Sheet Module]
================================================================================

--------------------------------------------------------------------------------

================================================================================
=== Component: Class1  [Class Module]
================================================================================

--------------------------------------------------------------------------------

================================================================================
=== Component: Arkusz3  [Document/Sheet Module]
================================================================================

--------------------------------------------------------------------------------

================================================================================
=== Component: modExportVBA  [Standard Module]
================================================================================
' === modExportVBA.bas (rozszerzenie: TXT + osobne .vb do folderu) ===
Option Explicit

Private Const vbext_ct_StdModule As Long = 1
Private Const vbext_ct_ClassModule As Long = 2
Private Const vbext_ct_MSForm As Long = 3
Private Const vbext_ct_Document As Long = 100

' --- WIDOCZNE W ALT+F8 (bez parametrów) ---
Public Sub ExportAllVBAtoSingleTxt_UI()
    ExportAllVBAtoSingleTxt_Worker ""
End Sub

Public Sub ExportAllVBAtoSingleTxt_ToFolderDesktop()
    Dim desk As String
    desk = CreateObject("WScript.Shell").SpecialFolders("Desktop")

    Dim outPath As String
    outPath = desk & "\" & SafeStr(ThisWorkbookOrDoc.VBProject.Name) & "_VBA_" & Format(Now, "yyyymmdd_HHNNSS") & ".txt"
    ExportAllVBAtoSingleTxt_Worker outPath
End Sub

' NOWE: folder + osobne .vb (i dodatkowo 1 zbiorczy .txt w tym samym folderze)
Public Sub ExportAllVBA_ToFolder_WithSeparateVB_UI()
    ExportAllVBA_ToFolder_WithSeparateVB_Worker ""
End Sub
' --- /WIDOCZNE ---


' =========================
' 1) Eksport do jednego TXT
' =========================
Private Sub ExportAllVBAtoSingleTxt_Worker(Optional ByVal outPath As String = "")
    On Error GoTo blad

    Dim proj As Object, comps As Object, c As Object
    Dim hostName As String, projName As String, whenStr As String
    hostName = Application.Name
    Set proj = ThisWorkbookOrDoc.VBProject
    Set comps = proj.VBComponents
    projName = SafeStr(proj.Name)
    whenStr = Format(Now, "yyyy-mm-dd HH:nn:ss")

    If Len(outPath) = 0 Then
        outPath = PickSaveTxt(projName & "_VBA_" & Format(Now, "yyyymmdd_HHNNSS") & ".txt")
        If Len(outPath) = 0 Then Exit Sub
    End If

    Dim sb As String
    sb = "# VBA EXPORT" & vbCrLf & _
         "# Host: " & hostName & vbCrLf & _
         "# Project: " & projName & vbCrLf & _
         "# Date: " & whenStr & vbCrLf & _
         "# Components: " & comps.Count & vbCrLf & _
         String(80, "-") & vbCrLf

    For Each c In comps
        sb = sb & ComponentBlock(c) & vbCrLf
    Next c

    SaveTextUTF8 outPath, sb
    MsgBox "Zapisano eksport VBA do:" & vbCrLf & outPath, vbInformation
    Exit Sub

blad:
    HandleVBAccessError "Błąd eksportu (TXT)", Err
End Sub


' ==========================================
' 2) NOWE: Eksport do folderu + osobne .vb
' ==========================================
Private Sub ExportAllVBA_ToFolder_WithSeparateVB_Worker(Optional ByVal rootOutDir As String = "")
    On Error GoTo blad

    Dim proj As Object, comps As Object, c As Object
    Set proj = ThisWorkbookOrDoc.VBProject
    Set comps = proj.VBComponents

    Dim hostBase As String
    hostBase = GetHostFileBaseName() ' nazwa "głównego pliku" (bez rozszerzenia)
    If Len(hostBase) = 0 Then hostBase = SafeStr(proj.Name)

    If Len(rootOutDir) = 0 Then
        rootOutDir = PickFolder("Wybierz lokalizację docelową (katalog nadrzędny):")
        If Len(rootOutDir) = 0 Then Exit Sub
    End If

    Dim stamp As String: stamp = Format(Now, "yyyymmdd_HHNNSS")
    Dim outFolder As String
    outFolder = rootOutDir & "\" & CleanFileName(hostBase) & "_VBA_" & stamp

    EnsureFolderExists outFolder
    EnsureFolderExists outFolder & "\Modules"

    ' (A) Zapis zbiorczego TXT do tego samego folderu
    Dim txtPath As String
    txtPath = outFolder & "\" & CleanFileName(hostBase) & "_VBA_" & stamp & ".txt"
    ExportAllVBAtoSingleTxt_Worker txtPath

    ' (B) Zapis każdego komponentu do osobnego .vb
    Dim savedCount As Long: savedCount = 0
    For Each c In comps
        Dim codeLines As Long: codeLines = c.CodeModule.CountOfLines

        Dim code As String
        If codeLines > 0 Then
            code = c.CodeModule.lines(1, codeLines)
        Else
            code = "" ' puste moduły też zapisujemy, żeby było widać że istnieją
        End If

        Dim header As String
        header = "' === Component: " & c.Name & " [" & ComponentTypeName(c.Type) & "]" & vbCrLf & _
                 "' === Exported: " & Format(Now, "yyyy-mm-dd HH:nn:ss") & vbCrLf & vbCrLf

        Dim vbPath As String
        vbPath = outFolder & "\Modules\" & CleanFileName(c.Name) & ".vb"

        SaveTextUTF8 vbPath, header & code
        savedCount = savedCount + 1
    Next c

    MsgBox "Zapisano folder eksportu:" & vbCrLf & outFolder & vbCrLf & vbCrLf & _
           "• TXT: " & txtPath & vbCrLf & _
           "• Pliki .vb: " & savedCount & " szt. w \Modules\", vbInformation
    Exit Sub

blad:
    HandleVBAccessError "Błąd eksportu (folder + .vb)", Err
End Sub


' === Helper: zwraca obiekt-kontener projektu (Excel: ThisWorkbook, Word: ActiveDocument)
Private Function ThisWorkbookOrDoc() As Object
    Dim o As Object

    On Error Resume Next
    Set o = CallByName(Application, "ThisWorkbook", VbGet)
    On Error GoTo 0
    If Not o Is Nothing Then
        Set ThisWorkbookOrDoc = o
        Exit Function
    End If

    On Error Resume Next
    Set o = CallByName(Application, "ActiveDocument", VbGet)
    On Error GoTo 0
    If Not o Is Nothing Then
        Set ThisWorkbookOrDoc = o
        Exit Function
    End If

    Err.Raise 5, , "Nie rozpoznano hosta (Excel/Word) – nie można uzyskać kontenera VBProject."
End Function


Private Function ComponentBlock(ByVal comp As Object) As String
    Dim kind As String: kind = ComponentTypeName(comp.Type)
    Dim codeLines As Long: codeLines = comp.CodeModule.CountOfLines
    Dim code As String: If codeLines > 0 Then code = comp.CodeModule.lines(1, codeLines)

    ComponentBlock = _
        String(80, "=") & vbCrLf & _
        "=== Component: " & comp.Name & "  [" & kind & "]" & vbCrLf & _
        String(80, "=") & vbCrLf & _
        code & vbCrLf & _
        String(80, "-") & vbCrLf
End Function

Private Function ComponentTypeName(ByVal t As Long) As String
    Select Case t
        Case vbext_ct_StdModule:   ComponentTypeName = "Standard Module"
        Case vbext_ct_ClassModule: ComponentTypeName = "Class Module"
        Case vbext_ct_MSForm:      ComponentTypeName = "UserForm"
        Case vbext_ct_Document:    ComponentTypeName = "Document/Sheet Module"
        Case Else:                 ComponentTypeName = "Unknown(" & t & ")"
    End Select
End Function


' ===== UI pickery =====
Private Function PickSaveTxt(ByVal suggestName As String) As String
    On Error GoTo blad
    With Application.FileDialog(msoFileDialogSaveAs)
        .title = "Gdzie zapisać eksport VBA jako TXT?"
        .InitialFileName = suggestName
        .Filters.Clear
        .Filters.Add "Pliki tekstowe (*.txt)", "*.txt"
        If .Show Then PickSaveTxt = .SelectedItems(1)
    End With
    Exit Function
blad:
    PickSaveTxt = ""
End Function

Private Function PickFolder(ByVal title As String) As String
    On Error GoTo blad
    With Application.FileDialog(msoFileDialogFolderPicker)
        .title = title
        If .Show Then PickFolder = .SelectedItems(1)
    End With
    Exit Function
blad:
    PickFolder = ""
End Function


' ===== Zapis UTF-8 =====
Private Sub SaveTextUTF8(ByVal path As String, ByVal textData As String)
    Dim stm As Object: Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2           ' adTypeText
        .Charset = "utf-8"
        .Open
        .WriteText textData
        .SaveToFile path, 2 ' adSaveCreateOverWrite
        .Close
    End With
End Sub


' ===== Foldery/ścieżki =====
Private Sub EnsureFolderExists(ByVal folderPath As String)
    If Len(dir$(folderPath, vbDirectory)) = 0 Then
        MkDirRecursive folderPath
    End If
End Sub

Private Sub MkDirRecursive(ByVal folderPath As String)
    Dim fso As Object: Set fso = CreateObject("Scripting.FileSystemObject")
    If fso.FolderExists(folderPath) Then Exit Sub
    fso.CreateFolder folderPath
End Sub

Private Function GetHostFileBaseName() As String
    ' Excel: ThisWorkbook.Name, Word: ActiveDocument.Name
    On Error Resume Next

    Dim nm As String
    nm = ""
    nm = CallByName(ThisWorkbookOrDoc, "Name", VbGet)

    On Error GoTo 0
    If Len(nm) = 0 Then Exit Function

    Dim p As Long: p = InStrRev(nm, ".")
    If p > 1 Then
        GetHostFileBaseName = Left$(nm, p - 1)
    Else
        GetHostFileBaseName = nm
    End If
End Function

Private Function CleanFileName(ByVal s As String) As String
    ' usuwa znaki niedozwolone w nazwach plików Windows
    Dim bad As Variant, i As Long
    bad = Array("\", "/", ":", "*", "?", """", "<", ">", "|")
    CleanFileName = s
    For i = LBound(bad) To UBound(bad)
        CleanFileName = Replace(CleanFileName, bad(i), "_")
    Next i
    CleanFileName = Trim$(CleanFileName)
    If Len(CleanFileName) = 0 Then CleanFileName = "NONAME"
End Function

Private Function SafeStr(ByVal s As String) As String
    SafeStr = Replace(Replace(s, vbCr, " "), vbLf, " ")
End Function


' ===== Obsługa błędów dostępu do VBProject =====
Private Sub HandleVBAccessError(ByVal caption As String, ByVal e As ErrObject)
    If e.Number = 1004 Or e.Number = 70 Then
        MsgBox "Brak dostępu do projektu VBA." & vbCrLf & _
               "Włącz: Plik › Opcje › Centrum zaufania › Ustawienia… › Ustawienia makr ›" & vbCrLf & _
               "„Ufaj dostępowi do modelu obiektowego projektu VBA”.", vbExclamation, caption
    Else
        MsgBox caption & ":" & vbCrLf & e.Number & " - " & e.Description, vbCritical
    End If
End Sub




--------------------------------------------------------------------------------

================================================================================
=== Component: modPdfEngine  [Standard Module]
================================================================================
Option Explicit

' ============================================================
' modPdfEngine — stable PDF engine for mRNA-PLUM (late binding)
' ============================================================

' ---------- Logging ----------
Private mLogFile As Integer
Private mLogPath As String

' ============================================================
' PUBLIC API
' ============================================================
Public Sub PdfEngine_RunBatch(ByVal cfg As Object)
    On Error GoTo EH

    Dim t0 As Double: t0 = Timer

    ' Validate cfg
    Dim root As String: root = NzStr(cfg("root"))
    Dim inFolder As String: inFolder = NzStr(cfg("in_indywidualne"))
    Dim outPdf As String: outPdf = NzStr(cfg("out_pdf"))
    Dim runDir As String: runDir = NzStr(cfg("run_dir"))
    Dim templatePath As String: templatePath = NzStr(cfg("template_path"))

    Dim sheetPers As String: sheetPers = NzStr(cfg("sheet_dane_pers"))
    Dim sheetKursy As String: sheetKursy = NzStr(cfg("sheet_dane_kursy"))
    Dim sheetReport As String: sheetReport = NzStr(cfg("sheet_report"))

    Dim maxBlocks As Long: maxBlocks = CLng(cfg("max_blocks"))
    Dim truncateOverflow As Boolean: truncateOverflow = CBool(cfg("truncate_overflow"))

    If Right$(inFolder, 1) <> "\" Then inFolder = inFolder & "\"
    If Right$(outPdf, 1) <> "\" Then outPdf = outPdf & "\"
    If Right$(runDir, 1) <> "\" Then runDir = runDir & "\"

    EnsureFolder runDir
    EnsureFolder outPdf

    OpenLog runDir, "pdf_batch"

    LogLine "START PdfEngine_RunBatch"
    LogLine "root=" & root
    LogLine "in_indywidualne=" & inFolder
    LogLine "out_pdf=" & outPdf
    LogLine "template_path=" & templatePath

    If dir(templatePath) = vbNullString Then
        Err.Raise vbObjectError + 100, "PdfEngine_RunBatch", "Nie znaleziono template: " & templatePath
    End If

    ' Stability settings
    Dim prevCalc As XlCalculation
    Dim prevSU As Boolean, prevEE As Boolean, prevDA As Boolean
    prevCalc = Application.Calculation
    prevSU = Application.ScreenUpdating
    prevEE = Application.EnableEvents
    prevDA = Application.DisplayAlerts

    Application.ScreenUpdating = False
    Application.EnableEvents = False
    Application.DisplayAlerts = False
    Application.Calculation = xlCalculationManual

    Dim f As String
    f = dir(inFolder & "*.xlsx")
    If Len(f) = 0 Then
        LogLine "Brak plików XLSX w: " & inFolder
        GoTo CleanUp
    End If

    Dim countOk As Long, countFail As Long, countAll As Long

    Do While Len(f) > 0
        countAll = countAll + 1
        Dim srcPath As String: srcPath = inFolder & f

        On Error GoTo OneFail
        ProcessOneTeacherFile srcPath, templatePath, outPdf, sheetPers, sheetKursy, sheetReport, maxBlocks, truncateOverflow
        countOk = countOk + 1
        LogLine "OK: " & srcPath
        On Error GoTo EH

NextFile:
    f = dir()
    DoEvents
    GoTo ContinueLoop

OneFail:
    countFail = countFail + 1
    LogLine "FAIL: " & srcPath & " | Err=" & Err.Number & " | " & Err.Description
    Err.Clear
    On Error GoTo EH
    Resume NextFile

ContinueLoop:
Loop

CleanUp:
    Application.Calculation = prevCalc
    Application.DisplayAlerts = prevDA
    Application.EnableEvents = prevEE
    Application.ScreenUpdating = prevSU

    LogLine "DONE: all=" & countAll & ", ok=" & countOk & ", fail=" & countFail & ", sec=" & Format$(Timer - t0, "0.0")
    CloseLog
    Exit Sub

EH:
    LogLine "FATAL: Err=" & Err.Number & " | " & Err.Description
    CloseLog
    Err.Raise Err.Number, "PdfEngine_RunBatch", Err.Description
End Sub

' ============================================================
' CORE — one teacher file
' ============================================================
Private Sub ProcessOneTeacherFile( _
    ByVal srcPath As String, _
    ByVal templatePath As String, _
    ByVal outPdfFolder As String, _
    ByVal sheetPers As String, _
    ByVal sheetKursy As String, _
    ByVal sheetReport As String, _
    ByVal maxBlocks As Long, _
    ByVal truncateOverflow As Boolean _
)
    On Error GoTo EH

    Dim wbData As Workbook, wbTpl As Workbook
    Dim wsPers As Worksheet, wsKursy As Worksheet, wsReport As Worksheet

    LogLine "----"
    LogLine "Process: " & srcPath

    Set wbData = Workbooks.Open(fileName:=srcPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Set wsPers = GetSheetSafe(wbData, sheetPers)
    Set wsKursy = GetSheetSafe(wbData, sheetKursy)
    If wsKursy Is Nothing Then Err.Raise vbObjectError + 200, "ProcessOneTeacherFile", "Brak arkusza DANE_KURSY w: " & srcPath

    Set wbTpl = Workbooks.Open(fileName:=templatePath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Set wsReport = ResolveReportSheet(wbTpl, sheetReport)
    If wsReport Is Nothing Then Err.Raise vbObjectError + 201, "ProcessOneTeacherFile", "Nie znaleziono arkusza raportu w template."

    ' 1) Fill named ranges (metryczka + KPI)
    If Not wsPers Is Nothing Then
        FillNamedRangesFromDanePers wbTpl, wsPers
    Else
        LogLine "WARN: Brak DANE_PERS w źródle: " & srcPath
    End If

    ' 2) Load courses
    Dim courses As Collection
    Set courses = LoadCourses(wsKursy)

    Dim nCourses As Long
    nCourses = courses.Count

    If nCourses > maxBlocks Then
        Dim msg As String
        msg = "Nadmiar kursów: " & nCourses & " > " & maxBlocks & " w " & srcPath
        If truncateOverflow Then
            LogLine "WARN: " & msg & " | TRUNCATE -> " & maxBlocks
            nCourses = maxBlocks
        Else
            Err.Raise vbObjectError + 202, "ProcessOneTeacherFile", msg
        End If
    End If

    ' 3) Fill course blocks 1..N
    Dim i As Long
    For i = 1 To nCourses
        FillCourseBlock wsReport, i, courses(i)
    Next i

    ' 4) Clear unused blocks
    TrimUnusedBlocks wsReport, nCourses, maxBlocks

    ' 5) Setup page breaks (manual)
    SetupPageBreaks wsReport, nCourses, maxBlocks

    ' 6) Print area to last block
    SetPrintAreaToLastBlock wsReport, nCourses, maxBlocks

    ' 7) Export PDF
    Dim outPdfPath As String
    outPdfPath = outPdfFolder & BuildPdfFileName(wbTpl, wbData, wsPers, srcPath) & ".pdf"

    ExportReportToPdf wbTpl, wsReport, outPdfPath

    ' Close without saving (template always)
    SafeClose wbTpl
    SafeClose wbData
    Exit Sub

EH:
    LogLine "ERROR ProcessOneTeacherFile: Err=" & Err.Number & " | " & Err.Description
    SafeClose wbTpl
    SafeClose wbData
    Err.Raise Err.Number, "ProcessOneTeacherFile", Err.Description
End Sub

' ============================================================
' REQUIRED FUNCTIONS (per spec)
' ============================================================

Public Sub FillNamedRangesFromDanePers(ByVal templateWb As Workbook, ByVal danePersWs As Worksheet)
    On Error GoTo EH

    Dim LastRow As Long
    LastRow = LastUsedRow(danePersWs, 1)
    If LastRow < 1 Then Exit Sub

    Dim r As Long
    Dim startRow As Long: startRow = 1

    ' jeśli A1 wygląda jak nagłówek "Name" -> start od 2
    If LCase$(Trim$(CStr(danePersWs.Cells(1, 1).value))) = "name" Then startRow = 2

    For r = startRow To LastRow
        Dim nm As String, v As Variant
        nm = Trim$(CStr(danePersWs.Cells(r, 1).value))
        v = danePersWs.Cells(r, 2).value

        If Len(nm) > 0 Then
            If NameExistsInWorkbook(templateWb, nm) Then
                On Error Resume Next
                templateWb.names(nm).RefersToRange.value = v
                If Err.Number <> 0 Then
                    LogLine "WARN: nie dało się ustawić NamedRange '" & nm & "' (" & Err.Number & "): " & Err.Description
                    Err.Clear
                End If
                On Error GoTo EH
            Else
                LogLine "WARN: brak NamedRange w template: " & nm
            End If
        End If
    Next r

    Exit Sub
EH:
    Err.Raise Err.Number, "FillNamedRangesFromDanePers", Err.Description
End Sub

Public Function LoadCourses(ByVal daneKursyWs As Worksheet) As Collection
    On Error GoTo EH

    Dim col As New Collection

    Dim LastRow As Long, lastCol As Long
    LastRow = LastUsedRow(daneKursyWs, 1)
    lastCol = LastUsedCol(daneKursyWs, 1)
    If LastRow < 2 Or lastCol < 1 Then
        Set LoadCourses = col
        Exit Function
    End If

    Dim headers() As Variant
    headers = daneKursyWs.Range(daneKursyWs.Cells(1, 1), daneKursyWs.Cells(1, lastCol)).Value2

    Dim data() As Variant
    data = daneKursyWs.Range(daneKursyWs.Cells(2, 1), daneKursyWs.Cells(LastRow, lastCol)).Value2

    Dim r As Long, c As Long
    For r = 1 To UBound(data, 1)
        Dim d As Object ' Scripting.Dictionary
        Set d = CreateObject("Scripting.Dictionary")
        d.CompareMode = 1 ' TextCompare

        For c = 1 To lastCol
            Dim h As String
            h = Trim$(CStr(headers(1, c)))
            If Len(h) = 0 Then h = "col_" & c
            d(h) = data(r, c)
        Next c

        col.Add d
    Next r

    Set LoadCourses = col
    Exit Function

EH:
    Err.Raise Err.Number, "LoadCourses", Err.Description
End Function

Public Sub FillCourseBlock(ByVal wsReport As Worksheet, ByVal blockNo As Long, ByVal courseRow As Object)
    ' courseRow: Scripting.Dictionary header->value
    On Error GoTo EH

    Dim topNm As String
    topNm = "nr_blk_" & Format$(blockNo, "00") & "_top"

    Dim topCell As Range
    Set topCell = GetNamedRangeCell(wsReport.Parent, topNm)
    If topCell Is Nothing Then
        LogLine "WARN: brak NamedRange top dla bloku: " & topNm
        Exit Sub
    End If

    ' --- MAPOWANIE BLOKU ---
    ' Najstabilniejsze podejście: tabela map w template (opcjonalna):
    ' Sheet: "MAPA_BLOKU"
    ' kol A: FieldName (nagłówek z DANE_KURSY)
    ' kol B: RowOffset (0=ten sam wiersz co top)
    ' kol C: ColOffset (0=ta sama kolumna co top)
    ' Jeśli nie ma MAPA_BLOKU -> stosujemy "default minimal" (tytuł kursu itp.) + log ostrzegawczy.

    Dim map As Object
    Set map = TryLoadBlockMap(wsReport.Parent)

    If map Is Nothing Then
        ' Default minimal: wpisz tytuł kursu w 2 wierszach od top,
        ' a ID kursu obok (bardzo bezpieczne, bo nie rozwala layoutu).
        ' Dostosujesz po potwierdzeniu offsetów albo dodaniu MAPA_BLOKU.
        LogLine "WARN: brak MAPA_BLOKU w template — używam default minimal dla bloku " & blockNo

        Dim vTitle As Variant, vId As Variant
        vTitle = PickCourseValue(courseRow, Array("pełna nazwa e-kursu", "pelna nazwa e-kursu", "full_name", "fullname", "nazwa", "course_name", "nazwa kursu"))
        vId = PickCourseValue(courseRow, Array("id kursu", "course_id", "id", "courseid"))

        ' Wstaw: topCell.Offset(0,0) -> tytuł
        topCell.Offset(0, 0).value = vTitle
        ' ID np. w komórce obok (kolumna +10) — bezpieczne, ale może wymagać korekty
        topCell.Offset(0, 10).value = vId

        Exit Sub
    End If

    ' Map exists: iterate entries field->(rOff,cOff)
    Dim k As Variant
    For Each k In map.keys
        Dim rc As Variant
        rc = map(k) ' array(0)=rOff, array(1)=cOff

        Dim val As Variant
        val = GetCourseValueByHeader(courseRow, CStr(k))

        With topCell.Offset(CLng(rc(0)), CLng(rc(1)))
            .value = val
        End With
    Next k

    Exit Sub

EH:
    Err.Raise Err.Number, "FillCourseBlock", Err.Description
End Sub

Public Sub SetupPageBreaks(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    ' Reset existing manual breaks
    On Error Resume Next
    wsReport.ResetAllPageBreaks
    On Error GoTo EH

    ' Wg ustaleń: HPageBreak przed blokami #2,#5,#8,#11,#14 (ale tylko jeśli istnieją w zakresie 1..maxBlocks)
    Dim breaks As Variant
    breaks = Array(2, 5, 8, 11, 14)

    Dim i As Long
    For i = LBound(breaks) To UBound(breaks)
        Dim b As Long: b = CLng(breaks(i))
        If b >= 1 And b <= maxBlocks Then
            ' Jeśli realnie mamy mniej kursów niż b, to i tak break jest OK (template ma stałe strony),
            ' ale możesz też warunkować: If nCourses >= b Then ...
            Dim nm As String
            nm = "nr_blk_" & Format$(b, "00") & "_top"
            Dim topCell As Range
            Set topCell = GetNamedRangeCell(wsReport.Parent, nm)
            If Not topCell Is Nothing Then
                wsReport.HPageBreaks.Add Before:=topCell
            Else
                LogLine "WARN: SetupPageBreaks brak named range: " & nm
            End If
        End If
    Next i

    Exit Sub
EH:
    Err.Raise Err.Number, "SetupPageBreaks", Err.Description
End Sub

Public Sub TrimUnusedBlocks(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    If nCourses < 0 Then nCourses = 0
    If nCourses >= maxBlocks Then Exit Sub

    Dim blockHeight As Long
    blockHeight = DetectBlockHeight(wsReport, maxBlocks)
    If blockHeight <= 0 Then
        LogLine "WARN: Nie wykryto wysokości bloku — TrimUnusedBlocks pominięte"
        Exit Sub
    End If

    Dim b As Long
    For b = nCourses + 1 To maxBlocks
        Dim topNm As String: topNm = "nr_blk_" & Format$(b, "00") & "_top"
        Dim topCell As Range: Set topCell = GetNamedRangeCell(wsReport.Parent, topNm)
        If Not topCell Is Nothing Then
            Dim rng As Range
            ' Czyścimy "obszar bloku": od top w dół blockHeight-1 wierszy.
            ' Szerokość: używamy UsedRange.Columns, ale ograniczamy do sensownego obszaru strony.
            Set rng = BlockRangeByHeuristics(wsReport, topCell, blockHeight)
            rng.ClearContents
        End If
    Next b

    Exit Sub
EH:
    Err.Raise Err.Number, "TrimUnusedBlocks", Err.Description
End Sub

Public Sub SetPrintAreaToLastBlock(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    If nCourses <= 0 Then
        ' jeżeli brak kursów — drukuj stronę 1 (metryczka + KPI) -> ustawimy UsedRange
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    If nCourses > maxBlocks Then nCourses = maxBlocks

    Dim blockHeight As Long
    blockHeight = DetectBlockHeight(wsReport, maxBlocks)
    If blockHeight <= 0 Then
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    Dim lastTopNm As String: lastTopNm = "nr_blk_" & Format$(nCourses, "00") & "_top"
    Dim lastTop As Range: Set lastTop = GetNamedRangeCell(wsReport.Parent, lastTopNm)

    If lastTop Is Nothing Then
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    Dim LastRow As Long
    LastRow = lastTop.row + blockHeight - 1

    ' Kolumny do wydruku: od 1 do ostatniej użytej w nagłówku / usedrange
    Dim lastCol As Long
    lastCol = wsReport.UsedRange.Column + wsReport.UsedRange.Columns.Count - 1
    If lastCol < 1 Then lastCol = 1

    Dim rng As Range
    Set rng = wsReport.Range(wsReport.Cells(1, 1), wsReport.Cells(LastRow, lastCol))
    wsReport.PageSetup.PrintArea = rng.Address

    Exit Sub
EH:
    Err.Raise Err.Number, "SetPrintAreaToLastBlock", Err.Description
End Sub

Public Sub ExportReportToPdf(ByVal templateWb As Workbook, ByVal wsReport As Worksheet, ByVal outPdfPath As String)
    On Error GoTo EH

    EnsureFolder ParentFolder(outPdfPath)

    ' Stabilne ustawienia PageSetup wg ustaleń
    With wsReport.PageSetup
        .Zoom = False
        .FitToPagesWide = 1
        .FitToPagesTall = False
    End With

    ' Export
    wsReport.ExportAsFixedFormat _
        Type:=xlTypePDF, _
        fileName:=outPdfPath, _
        Quality:=xlQualityStandard, _
        IncludeDocProperties:=True, _
        IgnorePrintAreas:=False, _
        OpenAfterPublish:=False

    LogLine "PDF: " & outPdfPath
    Exit Sub

EH:
    Err.Raise Err.Number, "ExportReportToPdf", Err.Description
End Sub

' ============================================================
' Helpers — report/template/data
' ============================================================

Private Function ResolveReportSheet(ByVal wb As Workbook, ByVal sheetName As String) As Worksheet
    On Error Resume Next
    If Len(sheetName) > 0 Then
        Set ResolveReportSheet = wb.Worksheets(sheetName)
    Else
        Set ResolveReportSheet = wb.Worksheets(1)
    End If
    On Error GoTo 0
End Function

Private Function GetSheetSafe(ByVal wb As Workbook, ByVal sheetName As String) As Worksheet
    On Error Resume Next
    Set GetSheetSafe = wb.Worksheets(sheetName)
    On Error GoTo 0
End Function

Private Sub SafeClose(ByVal wb As Workbook)
    On Error Resume Next
    If Not wb Is Nothing Then wb.Close SaveChanges:=False
    On Error GoTo 0
End Sub

Private Function BuildPdfFileName(ByVal wbTpl As Workbook, ByVal wbData As Workbook, ByVal wsPers As Worksheet, ByVal srcPath As String) As String
    ' Prefer: NazwiskoImie + BAZUS ID (z DANE_PERS jeśli są NamedRanges na te dane)
    On Error GoTo EH

    Dim base As String
    base = FileBaseName(srcPath)

    Dim nazw As String, bazus As String
    nazw = ""
    bazus = ""

    ' Jeżeli w DANE_PERS są klucze, np. nr_meta_NazwiskoImie / nr_meta_BazusID
    ' to to już trafia do NamedRanges w template. Ale do nazwy PDF możemy też czytać prosto z DANE_PERS:
    If Not wsPers Is Nothing Then
        nazw = FindPersValue(wsPers, Array("NazwiskoImie", "Nazwisko Imię", "NAZWISKOIMIE", "nr_meta_NazwiskoImie"))
        bazus = FindPersValue(wsPers, Array("BAZUS ID", "Bazus ID", "BAZUSID", "nr_meta_BazusID"))
    End If

    If Len(Trim$(nazw)) > 0 Then base = Trim$(nazw)
    If Len(Trim$(bazus)) > 0 Then base = base & "_" & Trim$(bazus)

    base = SanitizeFileName(base)
    If Len(base) > 180 Then base = Left$(base, 180)

    BuildPdfFileName = base
    Exit Function

EH:
    BuildPdfFileName = SanitizeFileName(FileBaseName(srcPath))
End Function

Private Function FindPersValue(ByVal ws As Worksheet, ByVal keys As Variant) As String
    On Error GoTo EH
    Dim LastRow As Long: LastRow = LastUsedRow(ws, 1)
    If LastRow < 1 Then Exit Function

    Dim startRow As Long: startRow = 1
    If LCase$(Trim$(CStr(ws.Cells(1, 1).value))) = "name" Then startRow = 2

    Dim r As Long, i As Long
    For r = startRow To LastRow
        Dim nm As String: nm = Trim$(CStr(ws.Cells(r, 1).value))
        If Len(nm) > 0 Then
            For i = LBound(keys) To UBound(keys)
                If LCase$(nm) = LCase$(CStr(keys(i))) Then
                    FindPersValue = Trim$(CStr(ws.Cells(r, 2).value))
                    Exit Function
                End If
            Next i
        End If
    Next r
    Exit Function
EH:
    FindPersValue = ""
End Function

' ============================================================
' Block mapping via MAPA_BLOKU (recommended)
' ============================================================

Private Function TryLoadBlockMap(ByVal wb As Workbook) As Object
    ' Returns Scripting.Dictionary: key=FieldName (DANE_KURSY header), value=array(rOff,cOff)
    ' Expected sheet: MAPA_BLOKU
    ' A: FieldName, B: RowOffset, C: ColOffset
    On Error GoTo EH

    Dim ws As Worksheet
    On Error Resume Next
    Set ws = wb.Worksheets("MAPA_BLOKU")
    On Error GoTo 0
    If ws Is Nothing Then Exit Function

    Dim LastRow As Long: LastRow = LastUsedRow(ws, 1)
    If LastRow < 2 Then Exit Function

    Dim d As Object: Set d = CreateObject("Scripting.Dictionary")
    d.CompareMode = 1 ' TextCompare

    Dim r As Long
    For r = 2 To LastRow
        Dim fieldName As String
        fieldName = Trim$(CStr(ws.Cells(r, 1).value))
        If Len(fieldName) > 0 Then
            Dim ro As Long, co As Long
            ro = CLng(val(ws.Cells(r, 2).value))
            co = CLng(val(ws.Cells(r, 3).value))
            d(fieldName) = Array(ro, co)
        End If
    Next r

    If d.Count = 0 Then Exit Function
    Set TryLoadBlockMap = d
    Exit Function

EH:
    LogLine "WARN: MAPA_BLOKU read error: " & Err.Number & " | " & Err.Description
End Function

Private Function GetCourseValueByHeader(ByVal courseRow As Object, ByVal headerName As String) As Variant
    ' direct header match
    If courseRow.Exists(headerName) Then
        GetCourseValueByHeader = courseRow(headerName)
    Else
        ' fuzzy (normalized)
        GetCourseValueByHeader = GetCourseValueFuzzy(courseRow, headerName)
    End If
End Function

Private Function GetCourseValueFuzzy(ByVal courseRow As Object, ByVal headerName As String) As Variant
    On Error GoTo EH

    Dim target As String
    target = NormalizeKey(headerName)

    Dim k As Variant
    For Each k In courseRow.keys
        If NormalizeKey(CStr(k)) = target Then
            GetCourseValueFuzzy = courseRow(k)
            Exit Function
        End If
    Next k

    GetCourseValueFuzzy = vbNullString
    Exit Function

EH:
    GetCourseValueFuzzy = vbNullString
End Function

Private Function PickCourseValue(ByVal courseRow As Object, ByVal candidates As Variant) As Variant
    Dim i As Long
    For i = LBound(candidates) To UBound(candidates)
        Dim v As Variant
        v = GetCourseValueByHeader(courseRow, CStr(candidates(i)))
        If Len(Trim$(CStr(v))) > 0 Then
            PickCourseValue = v
            Exit Function
        End If
    Next i
    PickCourseValue = vbNullString
End Function

' ============================================================
' Block geometry heuristics
' ============================================================

Private Function DetectBlockHeight(ByVal wsReport As Worksheet, ByVal maxBlocks As Long) As Long
    ' detect from successive tops: min positive delta between blk_i and blk_{i+1}
    On Error GoTo EH

    Dim minDelta As Long: minDelta = 0
    Dim i As Long
    For i = 1 To maxBlocks - 1
        Dim a As Range, b As Range
        Set a = GetNamedRangeCell(wsReport.Parent, "nr_blk_" & Format$(i, "00") & "_top")
        Set b = GetNamedRangeCell(wsReport.Parent, "nr_blk_" & Format$(i + 1, "00") & "_top")
        If Not a Is Nothing And Not b Is Nothing Then
            Dim d As Long: d = b.row - a.row
            If d > 0 Then
                If minDelta = 0 Or d < minDelta Then minDelta = d
            End If
        End If
    Next i

    DetectBlockHeight = minDelta
    Exit Function

EH:
    DetectBlockHeight = 0
End Function

Private Function BlockRangeByHeuristics(ByVal ws As Worksheet, ByVal topCell As Range, ByVal blockHeight As Long) As Range
    ' width: we take usedrange last col, but at least up to topCell.Column
    Dim lastCol As Long
    lastCol = ws.UsedRange.Column + ws.UsedRange.Columns.Count - 1
    If lastCol < topCell.Column Then lastCol = topCell.Column

    Set BlockRangeByHeuristics = ws.Range(ws.Cells(topCell.row, 1), ws.Cells(topCell.row + blockHeight - 1, lastCol))
End Function

' ============================================================
' Named range utilities
' ============================================================

Private Function NameExistsInWorkbook(ByVal wb As Workbook, ByVal nameText As String) As Boolean
    On Error GoTo EH
    Dim nm As Name
    Set nm = wb.names(nameText)
    NameExistsInWorkbook = True
    Exit Function
EH:
    NameExistsInWorkbook = False
End Function

Private Function GetNamedRangeCell(ByVal wb As Workbook, ByVal nameText As String) As Range
    On Error GoTo EH
    Dim nm As Name
    Set nm = wb.names(nameText)
    Set GetNamedRangeCell = nm.RefersToRange.Cells(1, 1)
    Exit Function
EH:
    Set GetNamedRangeCell = Nothing
End Function

' ============================================================
' File / folder / log
' ============================================================

Private Sub EnsureFolder(ByVal path As String)
    On Error Resume Next
    If Len(path) = 0 Then Exit Sub
    If Right$(path, 1) = "\" Then path = Left$(path, Len(path) - 1)
    If Len(dir(path, vbDirectory)) = 0 Then MkDir path
    On Error GoTo 0
End Sub

Private Function ParentFolder(ByVal fullPath As String) As String
    Dim p As Long: p = InStrRev(fullPath, "\")
    If p > 0 Then ParentFolder = Left$(fullPath, p) Else ParentFolder = ""
End Function

Private Function FileBaseName(ByVal fullPath As String) As String
    Dim s As String: s = fullPath
    Dim p As Long: p = InStrRev(s, "\")
    If p > 0 Then s = Mid$(s, p + 1)
    Dim d As Long: d = InStrRev(s, ".")
    If d > 0 Then s = Left$(s, d - 1)
    FileBaseName = s
End Function

Private Function SanitizeFileName(ByVal s As String) As String
    Dim bad As Variant, i As Long
    bad = Array("\", "/", ":", "*", "?", """", "<", ">", "|")
    For i = LBound(bad) To UBound(bad)
        s = Replace$(s, CStr(bad(i)), "_")
    Next i
    s = Replace$(s, vbCr, " ")
    s = Replace$(s, vbLf, " ")
    s = Trim$(s)
    SanitizeFileName = s
End Function

Private Sub OpenLog(ByVal runDir As String, ByVal prefix As String)
    Dim ts As String
    ts = Format$(Now, "yyyy-mm-dd_hh-nn-ss")
    mLogPath = runDir & prefix & "_" & ts & ".log"

    mLogFile = FreeFile
    Open mLogPath For Output As #mLogFile
    Print #mLogFile, "LOG " & Now
End Sub

Private Sub CloseLog()
    On Error Resume Next
    If mLogFile <> 0 Then Close #mLogFile
    mLogFile = 0
    On Error GoTo 0
End Sub

Private Sub LogLine(ByVal s As String)
    On Error Resume Next
    If mLogFile <> 0 Then Print #mLogFile, Format$(Now, "hh:nn:ss") & " | " & s
    On Error GoTo 0
End Sub

' ============================================================
' Worksheet scanning
' ============================================================

Private Function LastUsedRow(ByVal ws As Worksheet, ByVal col As Long) As Long
    On Error GoTo EH
    LastUsedRow = ws.Cells(ws.Rows.Count, col).End(xlUp).row
    Exit Function
EH:
    LastUsedRow = 0
End Function

Private Function LastUsedCol(ByVal ws As Worksheet, ByVal row As Long) As Long
    On Error GoTo EH
    LastUsedCol = ws.Cells(row, ws.Columns.Count).End(xlToLeft).Column
    Exit Function
EH:
    LastUsedCol = 0
End Function

' ============================================================
' Text normalization (simple, stable)
' ============================================================

Private Function NormalizeKey(ByVal s As String) As String
    s = LCase$(Trim$(s))
    s = ReplacePolish(s)
    s = Replace$(s, " ", "")
    s = Replace$(s, "_", "")
    s = Replace$(s, "-", "")
    s = Replace$(s, "/", "")
    s = Replace$(s, ":", "")
    s = Replace$(s, ".", "")
    s = Replace$(s, ",", "")
    NormalizeKey = s
End Function

Private Function ReplacePolish(ByVal s As String) As String
    s = Replace$(s, "ą", "a")
    s = Replace$(s, "ć", "c")
    s = Replace$(s, "ę", "e")
    s = Replace$(s, "ł", "l")
    s = Replace$(s, "ń", "n")
    s = Replace$(s, "ó", "o")
    s = Replace$(s, "ś", "s")
    s = Replace$(s, "ż", "z")
    s = Replace$(s, "ź", "z")
    ReplacePolish = s
End Function

Private Function NzStr(ByVal v As Variant) As String
    If IsError(v) Then NzStr = "" Else NzStr = CStr(v)
End Function

--------------------------------------------------------------------------------

================================================================================
=== Component: modNA_PdfEngine  [Standard Module]
================================================================================
Option Explicit

' =========================
' KONFIG
' =========================
Private Const SHEET_KURSY As String = "DANE_KURSY"
Private Const SHEET_PERS  As String = "DANE_PERS"

Private Const REPORT_SHEET As String = "Raport_NA" ' <-- potwierdziłeś

Private Const MAX_BLOCKS As Long = 16

' PDF / wydruk
Private Const MARGIN_CM As Double = 1.5
Private Const PERCENT_FORMAT As String = "0,0%"

Private mLogFile As Integer
Private mLogPath As String

' =========================
' START
' =========================
Public Sub RaportyNAPDF()
    On Error GoTo EH
    Application.ScreenUpdating = False
    Application.EnableEvents = False
    Application.Calculation = xlCalculationManual

    Dim wzorPath As String, srcFolder As String, outFolder As String

    wzorPath = PickReportTemplate()
    If Len(wzorPath) = 0 Then GoTo CleanUp

    srcFolder = PickSourceFolder()
    If Len(srcFolder) = 0 Then GoTo CleanUp
    If Right$(srcFolder, 1) <> "\" Then srcFolder = srcFolder & "\"

    outFolder = srcFolder & "raporty_NA_pdf\"
    EnsureFolder outFolder

    Dim f As String
    f = dir$(srcFolder & "*.xlsx")

    If Len(f) = 0 Then
        MsgBox "Brak plików .xlsx w folderze.", vbExclamation
        GoTo CleanUp
    End If

    Do While Len(f) > 0
        ProcessOneSourceFile srcFolder & f, wzorPath, outFolder
        f = dir$
    Loop

    MsgBox "Zakończone. PDF-y zapisane w: " & outFolder, vbInformation

CleanUp:
    Application.ScreenUpdating = True
    Application.EnableEvents = True
    Application.Calculation = xlCalculationAutomatic
    Exit Sub

EH:
    MsgBox "Błąd: " & Err.Number & " - " & Err.Description, vbCritical
    Resume CleanUp
End Sub

' =========================
' 1 PLIK -> 1 PDF
' =========================
Private Sub ProcessOneSourceFile(ByVal srcPath As String, ByVal wzorPath As String, ByVal outFolder As String)
    On Error GoTo EH

    Dim wbSrc As Workbook, wbTpl As Workbook, wbOut As Workbook
    Dim wsK As Worksheet, wsP As Worksheet, wsOut As Worksheet

    Dim runFolder As String, logPath As String
    runFolder = ParentFolderWithBackslash(outFolder) & "_run\"
    EnsureFolder runFolder

    logPath = runFolder & "pdf_" & Format$(Now, "yyyymmdd_hhnnss") & "_" & SanitizeFileName(Replace$(dir$(srcPath), ".xlsx", "")) & ".log"
    LogOpen logPath
    LogLine "START src=" & srcPath

    ' --- open source (read-only) ---
    Set wbSrc = Workbooks.Open(srcPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)
    Set wsK = GetWsOrNothing(wbSrc, SHEET_KURSY)
    Set wsP = GetWsOrNothing(wbSrc, SHEET_PERS)

    If wsK Is Nothing Then
        LogLine "ERROR: missing sheet: " & SHEET_KURSY
        GoTo CloseAndExit
    End If

    ' --- open template (read-only) and SaveCopyAs ---
    Set wbTpl = Workbooks.Open(wzorPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Dim tmpPath As String
    tmpPath = outFolder & "~tmp_" & Format$(Now, "yyyymmdd_hhnnss") & "_" & SanitizeFileName(Replace$(wbSrc.Name, ".xlsx", "")) & ".xlsx"

    Application.DisplayAlerts = False
    wbTpl.SaveCopyAs tmpPath
    Application.DisplayAlerts = True

    wbTpl.Close SaveChanges:=False
    Set wbTpl = Nothing

    ' --- open working copy (writable) ---
    Set wbOut = Workbooks.Open(tmpPath, ReadOnly:=False, UpdateLinks:=0, AddToMru:=False)
    Set wsOut = GetWsOrNothing(wbOut, REPORT_SHEET)
    If wsOut Is Nothing Then
        LogLine "ERROR: missing report sheet: " & REPORT_SHEET
        GoTo CloseAndExit
    End If

    ' 1) DANE_PERS -> NamedRanges
    If Not wsP Is Nothing Then
        FillNamedRangesFromDanePers wbOut, wsP
    Else
        LogLine "WARN: missing sheet: " & SHEET_PERS
    End If

    ' 2) Kursy -> 16 bloków
    FillAllCourseBlocks wbOut, wsOut, wsK, MAX_BLOCKS

    ' 3) Layout + Print settings
    ApplyLayout wsOut

    ' 4) PDF name (prefer NamedRanges, fallback to source filename)
    Dim nauczyciel As String, bazusID As String, base As String
    nauczyciel = CStr(GetNameValueOrEmpty(wbOut, "nr_meta_Nauczyciel"))
    bazusID = CStr(GetNameValueOrEmpty(wbOut, "nr_meta_BazusID"))

    base = Replace$(wbSrc.Name, ".xlsx", "")
    If Len(Trim$(nauczyciel)) > 0 Then base = Trim$(nauczyciel)
    If Len(Trim$(bazusID)) > 0 Then base = base & "_" & Trim$(bazusID)

    base = SanitizeFileName(base)
    If Len(base) > 180 Then base = Left$(base, 180)

    Dim outPdfPath As String
    outPdfPath = outFolder & base & ".pdf"
    LogLine "Export PDF -> " & outPdfPath

    wsOut.ExportAsFixedFormat Type:=xlTypePDF, _
                              fileName:=outPdfPath, _
                              Quality:=xlQualityStandard, _
                              IncludeDocProperties:=True, _
                              IgnorePrintAreas:=False, _
                              OpenAfterPublish:=False

    LogLine "OK"

CloseAndExit:
    On Error Resume Next
    If Not wbOut Is Nothing Then wbOut.Close SaveChanges:=False
    If Len(tmpPath) > 0 Then Kill tmpPath
    If Not wbTpl Is Nothing Then wbTpl.Close SaveChanges:=False
    If Not wbSrc Is Nothing Then wbSrc.Close SaveChanges:=False
    LogClose
    On Error GoTo 0
    Exit Sub

EH:
    LogLine "FAIL Err=" & Err.Number & " | " & Err.Description
    Resume CloseAndExit
End Sub

' =========================
' BLOKI KURSÓW
' =========================
Private Sub FillAllCourseBlocks(ByVal wbOut As Workbook, ByVal wsOut As Worksheet, ByVal wsK As Worksheet, ByVal maxBlocks As Long)
    On Error GoTo EH

    Dim courses As Collection
    Set courses = LoadDistinctCourses(wsK) ' kolekcja stringów (display name)

    Dim nAll As Long: nAll = courses.Count
    Dim nUse As Long: nUse = nAll
    If nUse > maxBlocks Then
        LogLine "WARN: overflow courses " & nUse & " -> truncate to " & maxBlocks
        nUse = maxBlocks
    End If

    ' słownik metryk: key = courseKey|activityKey -> Array(count, pct)
    Dim metrics As Object
    Set metrics = LoadCourseMetrics(wsK)

    Dim b As Long
    For b = 1 To maxBlocks
        If b <= nUse Then
            Dim courseName As String
            courseName = CStr(courses(b))

            FillOneCourseBlock wbOut, wsOut, b, courseName, metrics
        Else
            ClearOneCourseBlock wbOut, wsOut, b
        End If
    Next b

    ' pagebreaks: #2,#5,#8,#11,#14 (wg PROMPT 9)
    SetupPageBreaks_ByTopAnchors wbOut, wsOut, maxBlocks

    ' print area: do końca bloku nUse
    SetPrintAreaToLastUsedBlock_ByTopAnchors wbOut, wsOut, nUse, maxBlocks

    Exit Sub

EH:
    Err.Raise Err.Number, "FillAllCourseBlocks", Err.Description
End Sub

Private Sub FillOneCourseBlock(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long, ByVal courseName As String, ByVal metrics As Object)
    On Error GoTo EH

    Dim sNo As String: sNo = Format$(blockNo, "00")

    ' --- nagłówek bloku przez NamedRanges ---
    SafeSetNameValue wb, "nr_blk_" & sNo & "_top", blockNo
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseName", courseName

    ' ID / liczby: jeśli masz je w DANE_KURSY (np. specjalne wiersze),
    ' to najprościej dostarczyć je jako NamedRanges w DANE_PERS.
    ' Ale jeżeli masz w DANE_KURSY kolumny dla ID/studentów/nauczycieli,
    ' dopisz tu mapowanie. Na razie zostawiamy puste (albo "-").
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseID", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Studenci", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Nauczyciele", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Aktywni", ""

    ' --- zakres bloku: bierzemy od nr_blk_XX_top do tuż przed kolejnym top (albo wysokość jak blok 1) ---
    Dim rngBlock As Range
    Set rngBlock = GetBlockRangeByTopAnchors(wb, ws, blockNo, MAX_BLOCKS)

    ' --- aktywności: wypełnij po etykietach w obrębie bloku (działa dla układu lewa/prawa tabela) ---
    FillActivitiesInsideBlock rngBlock, courseName, metrics

    Exit Sub

EH:
    Err.Raise Err.Number, "FillOneCourseBlock", Err.Description
End Sub

Private Sub ClearOneCourseBlock(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long)
    Dim sNo As String: sNo = Format$(blockNo, "00")

    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseName", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseID", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Studenci", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Nauczyciele", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Aktywni", ""

    ' wyczyść wartości liczbowe/procenty w tabelach aktywności w obrębie bloku
    On Error Resume Next
    Dim rngBlock As Range
    Set rngBlock = GetBlockRangeByTopAnchors(wb, ws, blockNo, MAX_BLOCKS)
    On Error GoTo 0
    If rngBlock Is Nothing Then Exit Sub

    ClearActivityValuesInsideBlock rngBlock
End Sub

' -------------------------
' Aktywności w bloku: znajdź etykiety i wpisz wartości do komórek obok
' -------------------------
Private Sub FillActivitiesInsideBlock(ByVal rngBlock As Range, ByVal courseName As String, ByVal metrics As Object)
    ' Założenie: w wierszu aktywności jest komórka z etykietą (np. "Rozdziały w książce"),
    ' a po prawej w tym samym wierszu są kolumny: Ilość, % w skali kursu.
    ' Działa także gdy blok ma DWIE tabele (lewa i prawa), bo etykiety są w obu miejscach.

    Dim activities As Variant
    activities = Array( _
        "Rozdziały w książce", "Strony lekcji", "Strona", "Tekst i media", _
        "Wpisy do bazy danych", "Pojęcia w słowniku", "Adres URL", _
        "Pliki i foldery", "H5P", "Wpisy w Wiki", _
        "Utworzone pytania", "Ocenione zadań", "Ocenione zadan", "Ocenione zadania", _
        "Spotkania MS Teams", "Opinia zwrotna", "Głosowanie", _
        "Wiadomości na czacie", "Wpisy na forum" _
    )

    Dim i As Long
    For i = LBound(activities) To UBound(activities)
        Dim actLabel As String: actLabel = CStr(activities(i))

        Dim c As Range
        For Each c In rngBlock.Cells
            If NormalizeFuzzy(CStr(c.value)) = NormalizeFuzzy(actLabel) Then
                ' komórka etykiety może być scalona
                Dim labArea As Range: Set labArea = MergeAreaOrSelf(c)
                Dim rowNum As Long: rowNum = labArea.row

                ' znajdź w tym wierszu “Ilość” i “% w skali kursu” w ramach tej tabeli
                ' heurystyka: bierzemy pierwsze dwie NIEPuste komórki na prawo od etykiety,
                ' które nie są tekstem-nagłówkiem.
                Dim tgtCount As Range, tgtPct As Range
                Set tgtCount = FindNextValueCellRight(labArea)
                If Not tgtCount Is Nothing Then Set tgtPct = FindNextValueCellRight(tgtCount.MergeArea)

                Dim key As String
                key = NormalizeFuzzy(courseName) & "|" & NormalizeFuzzy(actLabel)

                If metrics.Exists(key) Then
                    Dim arr As Variant: arr = metrics(key)
                    PutValueOrDash tgtCount, arr(0), False
                    PutValueOrDash tgtPct, arr(1), True
                Else
                    PutValueOrDash tgtCount, Empty, False
                    PutValueOrDash tgtPct, Empty, True
                End If
            End If
        Next c
    Next i
End Sub

Private Sub ClearActivityValuesInsideBlock(ByVal rngBlock As Range)
    ' Czyścimy tylko komórki, które wyglądają jak pola Ilość/% (czyli nie teksty).
    Dim c As Range
    For Each c In rngBlock.Cells
        If c.MergeCells Then
            If c.Address <> c.MergeArea.Cells(1, 1).Address Then GoTo NextC
        End If

        Dim t As String: t = Trim$(CStr(c.value))
        If Len(t) = 0 Then GoTo NextC

        ' jeśli to tekst etykiety lub nagłówek - pomijamy
        If Not IsNumericLike(t) And InStr(1, t, "%", vbTextCompare) = 0 Then GoTo NextC

        c.MergeArea.ClearContents
NextC:
    Next c
End Sub

' =========================
' DANE: kursy i metryki
' =========================
Private Function LoadDistinctCourses(ByVal wsK As Worksheet) As Collection
    Dim col As New Collection
    Dim dict As Object: Set dict = CreateObject("Scripting.Dictionary")
    dict.CompareMode = vbTextCompare

    Dim lastR As Long: lastR = LastRow(wsK)
    Dim r As Long
    For r = 2 To lastR
        Dim courseName As String
        courseName = Trim$(CStr(wsK.Cells(r, 1).value))
        If Len(courseName) > 0 Then
            Dim key As String: key = NormalizeFuzzy(courseName)
            If Not dict.Exists(key) Then
                dict.Add key, True
                col.Add courseName
            End If
        End If
    Next r

    Set LoadDistinctCourses = col
End Function

Private Function LoadCourseMetrics(ByVal wsK As Worksheet) As Object
    Dim dict As Object: Set dict = CreateObject("Scripting.Dictionary")
    dict.CompareMode = vbTextCompare

    Dim lastR As Long: lastR = LastRow(wsK)
    Dim r As Long
    For r = 2 To lastR
        Dim courseName As String, actLabel As String
        courseName = Trim$(CStr(wsK.Cells(r, 1).value))
        actLabel = Trim$(CStr(wsK.Cells(r, 2).value))
        If Len(courseName) = 0 Or Len(actLabel) = 0 Then GoTo NextR

        Dim cnt As Variant, pct As Variant
        cnt = wsK.Cells(r, 3).value
        pct = wsK.Cells(r, 4).value

        Dim key As String
        key = NormalizeFuzzy(courseName) & "|" & NormalizeFuzzy(actLabel)

        dict(key) = Array(cnt, pct)
NextR:
    Next r

    Set LoadCourseMetrics = dict
End Function

' =========================
' PageBreaks + PrintArea oparte o nr_blk_XX_top
' =========================
Private Sub SetupPageBreaks_ByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal maxBlocks As Long)
    On Error Resume Next
    ws.ResetAllPageBreaks
    On Error GoTo 0

    Dim breaks As Variant
    breaks = Array(2, 5, 8, 11, 14)

    Dim i As Long, b As Long
    For i = LBound(breaks) To UBound(breaks)
        b = CLng(breaks(i))
        If b >= 1 And b <= maxBlocks Then
            Dim topCell As Range
            Set topCell = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(b, "00") & "_top")
            If Not topCell Is Nothing Then
                ws.HPageBreaks.Add Before:=ws.Rows(topCell.row)
            End If
        End If
    Next i
End Sub

Private Sub SetPrintAreaToLastUsedBlock_ByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    If nCourses < 1 Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If
    If nCourses > maxBlocks Then nCourses = maxBlocks

    Dim topLast As Range
    Set topLast = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(nCourses, "00") & "_top")
    If topLast Is Nothing Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If

    ' wysokość bloku: różnica top(2) - top(1) (stały układ)
    Dim h As Long: h = GetBlockHeightFromAnchors(wb)
    If h <= 0 Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If

    Dim LastRow As Long
    LastRow = topLast.row + h - 1

    Dim lastCol As Long
    lastCol = ws.UsedRange.Column + ws.UsedRange.Columns.Count - 1

    ws.PageSetup.PrintArea = ws.Range(ws.Cells(1, 1), ws.Cells(LastRow, lastCol)).Address
End Sub

Private Function GetBlockRangeByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long, ByVal maxBlocks As Long) As Range
    Dim topCell As Range
    Set topCell = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(blockNo, "00") & "_top")
    If topCell Is Nothing Then Exit Function

    Dim h As Long: h = GetBlockHeightFromAnchors(wb)
    If h <= 0 Then Exit Function

    ' szerokość bierzemy z UsedRange kolumn (praktycznie cały blok jest w tym zakresie)
    Dim w As Long
    w = ws.UsedRange.Columns.Count
    If w < 1 Then w = 30

    Set GetBlockRangeByTopAnchors = ws.Range(topCell, topCell.Offset(h - 1, w - 1))
End Function

Private Function GetBlockHeightFromAnchors(ByVal wb As Workbook) As Long
    Dim t1 As Range, t2 As Range
    Set t1 = GetNameRangeOrNothing(wb, "nr_blk_01_top")
    Set t2 = GetNameRangeOrNothing(wb, "nr_blk_02_top")
    If t1 Is Nothing Or t2 Is Nothing Then Exit Function
    GetBlockHeightFromAnchors = t2.row - t1.row
End Function

' =========================
' NamedRanges: DANE_PERS -> workbook.Names
' =========================
Private Sub FillNamedRangesFromDanePers(ByVal templateWb As Workbook, ByVal danePersWs As Worksheet)
    On Error GoTo EH

    Dim lastR As Long: lastR = LastRow(danePersWs)
    If lastR < 1 Then Exit Sub

    Dim startRow As Long: startRow = 1
    If LCase$(Trim$(CStr(danePersWs.Cells(1, 1).value))) = "name" Then startRow = 2

    Dim r As Long
    For r = startRow To lastR
        Dim nm As String: nm = Trim$(CStr(danePersWs.Cells(r, 1).value))
        If Len(nm) = 0 Then GoTo NextR

        Dim v As Variant: v = danePersWs.Cells(r, 2).value
        If NameExists(templateWb, nm) Then
            On Error Resume Next
            templateWb.names(nm).RefersToRange.value = v
            If Err.Number <> 0 Then
                LogLine "WARN: NamedRange set failed '" & nm & "' Err=" & Err.Number
                Err.Clear
            End If
            On Error GoTo EH
        End If
NextR:
    Next r
    Exit Sub

EH:
    Err.Raise Err.Number, "FillNamedRangesFromDanePers", Err.Description
End Sub

Private Sub SafeSetNameValue(ByVal wb As Workbook, ByVal nm As String, ByVal v As Variant)
    If Not NameExists(wb, nm) Then Exit Sub
    On Error Resume Next
    wb.names(nm).RefersToRange.value = v
    On Error GoTo 0
End Sub

Private Function GetNameValueOrEmpty(ByVal wb As Workbook, ByVal nm As String) As Variant
    On Error GoTo EH
    If Not NameExists(wb, nm) Then Exit Function
    GetNameValueOrEmpty = wb.names(nm).RefersToRange.value
    Exit Function
EH:
    GetNameValueOrEmpty = Empty
End Function

Private Function NameExists(ByVal wb As Workbook, ByVal nameText As String) As Boolean
    On Error GoTo EH
    Dim n As Name
    Set n = wb.names(nameText)
    NameExists = True
    Exit Function
EH:
    NameExists = False
End Function

Private Function GetNameRangeOrNothing(ByVal wb As Workbook, ByVal nm As String) As Range
    On Error GoTo EH
    If Not NameExists(wb, nm) Then Exit Function
    Set GetNameRangeOrNothing = wb.names(nm).RefersToRange
    Exit Function
EH:
End Function

' =========================
' Layout
' =========================
Private Sub ApplyLayout(ByVal ws As Worksheet)
    With ws.PageSetup
        .PaperSize = xlPaperA4
        .Orientation = xlPortrait
        .LeftMargin = Application.CentimetersToPoints(MARGIN_CM)
        .RightMargin = Application.CentimetersToPoints(MARGIN_CM)
        .TopMargin = Application.CentimetersToPoints(MARGIN_CM)
        .BottomMargin = Application.CentimetersToPoints(MARGIN_CM)
        .Zoom = False
        .FitToPagesWide = 1
        .FitToPagesTall = False
    End With
    ws.UsedRange.WrapText = True
End Sub

' =========================
' PutValue / helpers
' =========================
Private Sub PutValueOrDash(ByVal tgt As Range, ByVal v As Variant, ByVal isPercent As Boolean)
    If tgt Is Nothing Then Exit Sub

    Dim area As Range
    Set area = tgt.MergeArea

    If IsEmpty(v) Or v = "" Then
        area.NumberFormat = "General"
        area.Cells(1, 1).value = "-"
        Exit Sub
    End If

    If isPercent Then
        Dim x As Double, s As String

        If IsNumeric(v) Then
            x = CDbl(v)
        Else
            s = Trim$(CStr(v))
            s = Replace$(s, "%", "")
            s = Replace$(s, Chr$(160), " ")
            s = Replace$(s, " ", "")

            If Application.DecimalSeparator = "," Then
                s = Replace$(s, ".", ",")
            Else
                s = Replace$(s, ",", ".")
            End If

            If Not IsNumeric(s) Then
                area.NumberFormat = "General"
                area.Cells(1, 1).value = "-"
                Exit Sub
            End If
            x = CDbl(s)
        End If

        If x > 1# Then x = x / 100#
        area.Cells(1, 1).value = x
        area.NumberFormat = PERCENT_FORMAT
    Else
        If IsNumeric(v) Then
            area.Cells(1, 1).value = CDbl(v)
            area.NumberFormat = "General"
        Else
            area.NumberFormat = "General"
            area.Cells(1, 1).value = "-"
        End If
    End If
End Sub

Private Function FindNextValueCellRight(ByVal fromArea As Range) As Range
    ' Szuka pierwszej "sensownej" komórki na prawo od etykiety, w tym samym wierszu.
    ' Obsługa scaleń: przechodzimy po kolumnach od końca mergeArea.
    Dim ws As Worksheet: Set ws = fromArea.Worksheet
    Dim r As Long: r = fromArea.row
    Dim startCol As Long: startCol = fromArea.Column + fromArea.Columns.Count

    Dim c As Long
    For c = startCol To ws.Columns.Count
        Dim cc As Range: Set cc = ws.Cells(r, c)
        Dim ma As Range: Set ma = MergeAreaOrSelf(cc)

        ' pomijamy jeśli to ewidentny tekst-nagłówek
        Dim t As String: t = Trim$(CStr(ma.Cells(1, 1).value))
        If NormalizeFuzzy(t) Like "*rodzaj udostepnionej*" Then GoTo NextC
        If NormalizeFuzzy(t) Like "*ilosc*" Then GoTo NextC
        If InStr(1, t, "%", vbTextCompare) > 0 And InStr(1, NormalizeFuzzy(t), "skali", vbTextCompare) > 0 Then GoTo NextC

        Set FindNextValueCellRight = ma
        Exit Function
NextC:
    Next c
End Function

Private Function MergeAreaOrSelf(ByVal c As Range) As Range
    If c.MergeCells Then
        Set MergeAreaOrSelf = c.MergeArea
    Else
        Set MergeAreaOrSelf = c
    End If
End Function

Private Function IsNumericLike(ByVal s As String) As Boolean
    Dim t As String
    t = Replace$(s, "%", "")
    t = Replace$(t, " ", "")
    t = Replace$(t, Chr$(160), "")
    If Len(t) = 0 Then Exit Function
    If Application.DecimalSeparator = "," Then
        t = Replace$(t, ".", ",")
    Else
        t = Replace$(t, ",", ".")
    End If
    IsNumericLike = IsNumeric(t)
End Function

Private Function NormalizeFuzzy(ByVal s As String) As String
    s = Replace$(s, vbCr, " ")
    s = Replace$(s, vbLf, " ")
    s = Replace$(s, Chr$(160), " ")
    s = Trim$(Application.WorksheetFunction.Trim(s))
    s = LCase$(s)
    s = ReplacePolish(s)
    NormalizeFuzzy = s
End Function

Private Function ReplacePolish(ByVal s As String) As String
    s = Replace$(s, "ą", "a")
    s = Replace$(s, "ć", "c")
    s = Replace$(s, "ę", "e")
    s = Replace$(s, "ł", "l")
    s = Replace$(s, "ń", "n")
    s = Replace$(s, "ó", "o")
    s = Replace$(s, "ś", "s")
    s = Replace$(s, "ż", "z")
    s = Replace$(s, "ź", "z")
    ReplacePolish = s
End Function

' =========================
' Tools: sheets, picker, folder, lastrow, sanitize
' =========================
Private Function GetWsOrNothing(ByVal wb As Workbook, ByVal wsName As String) As Worksheet
    On Error Resume Next
    Set GetWsOrNothing = wb.Worksheets(wsName)
    On Error GoTo 0
End Function

Private Function PickReportTemplate() As String
    Dim fd As FileDialog
    Set fd = Application.FileDialog(msoFileDialogFilePicker)
    With fd
        .title = "Wskaż plik wzoru raportu (.xlsx)"
        .Filters.Clear
        .Filters.Add "Excel", "*.xlsx"
        .AllowMultiSelect = False
        If .Show = -1 Then PickReportTemplate = .SelectedItems(1)
    End With
End Function

Private Function PickSourceFolder() As String
    Dim fd As FileDialog
    Set fd = Application.FileDialog(msoFileDialogFolderPicker)
    With fd
        .title = "Wybierz folder z plikami źródłowymi (.xlsx)"
        If .Show = -1 Then PickSourceFolder = .SelectedItems(1)
    End With
End Function

Private Sub EnsureFolder(ByVal path As String)
    Dim fso As Object
    If Len(path) = 0 Then Exit Sub
    If Right$(path, 1) = "\" Then path = Left$(path, Len(path) - 1)
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(path) Then fso.CreateFolder path
End Sub

Private Function SanitizeFileName(ByVal s As String) As String
    Dim bad: bad = Array("/", "\", ":", "*", "?", """", "<", ">", "|")
    Dim i As Long
    For i = LBound(bad) To UBound(bad)
        s = Replace$(s, bad(i), "-")
    Next i
    SanitizeFileName = s
End Function

Private Function LastRow(ByVal ws As Worksheet) As Long
    LastRow = ws.Cells(ws.Rows.Count, 1).End(xlUp).row
End Function

Private Function ParentFolderWithBackslash(ByVal folderPath As String) As String
    Dim p As String: p = folderPath
    If Right$(p, 1) = "\" Then p = Left$(p, Len(p) - 1)
    Dim i As Long: i = InStrRev(p, "\")
    If i > 0 Then ParentFolderWithBackslash = Left$(p, i)
End Function

' =========================
' Logging
' =========================


Private Sub LogOpen(ByVal path As String)
    mLogPath = path
    mLogFile = FreeFile
    Open mLogPath For Output As #mLogFile
    Print #mLogFile, "LOG " & Now
End Sub

Private Sub LogLine(ByVal s As String)
    On Error Resume Next
    If mLogFile <> 0 Then Print #mLogFile, Format$(Now, "hh:nn:ss") & " | " & s
    On Error GoTo 0
End Sub

Private Sub LogClose()
    On Error Resume Next
    If mLogFile <> 0 Then Close #mLogFile
    mLogFile = 0
    On Error GoTo 0
End Sub

--------------------------------------------------------------------------------

================================================================================
=== Component: modNA_Launcher  [Standard Module]
================================================================================
' === modNA_Launcher ===
Option Explicit

' ---------------------------
' Konfiguracja / stałe
' ---------------------------
Private Const PROGRESS_INTERVAL_SEC As Double = 1# / 86400#   ' 1 sek (Date = dni)
Private Const PROGRESS_FILE As String = "_run\progress.jsonl"
Private Const RUN_LOG As String = "_run\run.log"

Private Const OUT_INDY As String = "_out\indywidualne\"
Private Const OUT_PDF As String = "_out\pdf\"
Private Const RUN_DIR As String = "_run\"

' Uwaga: ustaw to na nazwę pliku exe jeśli dystrybuujesz PyInstaller
Private Const PIPE_EXE As String = "mrna-plum.exe"  ' albo np. "mrna_plum_cli.exe"

' ---------------------------
' Stan pipeline (globalny)
' ---------------------------
Private Type TStep
    Name As String
    Cmd As String
End Type

Private gSteps() As TStep
Private gStepIndex As Long
Private gStepStart As Date

Private gWsh As Object          ' WScript.Shell
Private gExec As Object         ' WshScriptExec
Private gNextOnTime As Date
Private gMonitoring As Boolean
Private gRoot As String

' ---------------------------
' PUBLIC: wymagane przez Ciebie
' ---------------------------
Public Function RunPython(ByVal cmdLine As String) As Long
    ' Blokujące oczekiwanie (UWAGA: zamrozi UI na czas działania procesu).
    ' Dobre do krótkich komend / testów, ale nie do długiego pipeline.
    Dim sh As Object
    Set sh = CreateObject("WScript.Shell")

    ' 0 = hidden window, True = wait
    ' cmdLine MUSI zawierać pełne cudzysłowy dla ścieżek ze spacjami.
    RunPython = sh.Run(cmdLine, 0, True)
End Function

' ---------------------------
' PUBLIC: uruchomienie całości z UserForm
' ---------------------------
Public Sub StartPipeline()
    On Error GoTo EH

    gRoot = ThisWorkbook.path
    EnsureFolders
    If dir$(gRoot & "\" & PIPE_EXE) = vbNullString Then
        Err.Raise vbObjectError + 701, "StartPipeline", "Nie znaleziono pliku EXE: " & gRoot & "\" & PIPE_EXE
    End If

    If dir$(gRoot & "\config.yaml") = vbNullString Then
        Err.Raise vbObjectError + 702, "StartPipeline", "Nie znaleziono pliku config.yaml: " & gRoot & "\config.yaml"
    End If
    InitSteps

    ' wyczyść artefakty run
    SafeKillFile gRoot & "\" & RUN_LOG
    SafeKillFile gRoot & "\" & gRootRel(PROGRESS_FILE)
    ClearOkFlags

    AppendLog "=== START PIPELINE: " & Format(Now, "yyyy-mm-dd hh:nn:ss") & " ==="

    Set gWsh = CreateObject("WScript.Shell")
    gWsh.CurrentDirectory = gRoot
    gStepIndex = 0

    ' UI: zablokuj przyciski / ustaw status startowy
    UI_SetRunning True
    UI_SetStatus "Start pipeline..."

    StartNextStep
    Exit Sub

EH:
    PipelineFail "StartPipeline error: " & Err.Number & " - " & Err.Description
End Sub

' ---------------------------
' Pipeline core (asynchroniczny, bez freeze UI)
' ---------------------------
Private Sub InitSteps()
    ReDim gSteps(0 To 5) As TStep

    gSteps(0).Name = "merge-logs"
    gSteps(0).Cmd = StepCmd("merge-logs")

    gSteps(1).Name = "parse-events"
    gSteps(1).Cmd = StepCmd("parse-events")

    gSteps(2).Name = "build-activities-state"
    gSteps(2).Cmd = StepCmd("build-activities-state")

    gSteps(3).Name = "compute-stats"
    gSteps(3).Cmd = StepCmd("compute-stats")

    gSteps(4).Name = "export-excel"
    gSteps(4).Cmd = StepCmd("export-excel")

    gSteps(5).Name = "export-individual"
    gSteps(5).Cmd = StepCmd("export-individual")
End Sub

Private Function StepCmd(ByVal stepName As String) As String
    Dim exePath As String, cfgPath As String, logPath As String
    exePath = Quote(gRoot & "\" & PIPE_EXE)
    cfgPath = Quote(gRoot & "\config.yaml")
    logPath = Quote(gRoot & "\" & RUN_LOG)

    Dim inputsDir As String
    inputsDir = UF_Text(raporty_plum, "txtInputsDir")

    Dim extraArgs As String
    extraArgs = ""

    ' parse-events: KEYS override z UI
    If LCase$(stepName) = "parse-events" Then
        Dim keysXlsx As String
        keysXlsx = UF_Text(raporty_plum, "txtKeysXlsx")
        If Len(keysXlsx) > 0 Then
            extraArgs = extraArgs & " --keys-xlsx " & Quote(keysXlsx)
        End If
    End If

    ' build-activities-state: snapshot-file z UI (KRYTYCZNE) + fallback inputs-dir
    If LCase$(stepName) = "build-activities-state" Then
        Dim snapPath As String
        snapPath = UF_Text(raporty_plum, "txtSnapshotFile")

        If Len(snapPath) > 0 Then
            extraArgs = extraArgs & " --snapshot-file " & Quote(snapPath)
        ElseIf Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        Else
            Err.Raise vbObjectError + 513, "StepCmd", _
                "Brak danych wejściowych dla build-activities-state." & vbCrLf & _
                "Uzupełnij txtSnapshotFile lub txtInputsDir."
        End If
    End If

    ' export-excel / export-individual: inputs-dir
    If LCase$(stepName) = "export-excel" Or LCase$(stepName) = "export-individual" Then
        If Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        End If
    End If
    
    ' >>> DODAJ TEN BLOK W StepCmd (obok innych per-step bloków) <<<
    If LCase$(stepName) = "merge-logs" Then
        If Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        End If
    End If
    
    ' export-individual: out-dir
    If LCase$(stepName) = "export-individual" Then
        Dim outDir As String
        outDir = gRoot & "\" & OUT_INDY
        If Right$(outDir, 1) = "\" Then outDir = Left$(outDir, Len(outDir) - 1)
        extraArgs = extraArgs & " --out-dir " & Quote(outDir)
    End If

    Dim inner As String
    inner = "chcp 65001>nul" & _
            " & cd /d " & Quote(gRoot) & _
            " & " & exePath & " " & stepName & _
            " --root " & Quote(gRoot) & _
            " --config " & cfgPath & _
            extraArgs & _
            " >> " & logPath & " 2>&1"

    ' UWAGA: dokładnie JEDNA para cudzysłowów po /c
    StepCmd = "cmd.exe /c " & Quote(inner)
End Function

Private Sub StartNextStep()
    On Error GoTo EH

    If gStepIndex > UBound(gSteps) Then
        ' Python zakończony -> integracja PDF
        AppendLog "=== PYTHON PIPELINE OK ==="
        UI_SetStatus "Python OK. Sprawdzam pliki indywidualne..."

        If Not HasAnyFiles(gRoot & "\" & OUT_INDY, "*.xlsx") Then
            PipelineFail "Brak plików w " & OUT_INDY & " — nie generuję PDF."
            Exit Sub
        End If

        UI_SetStatus "Generuję PDF (VBA)..."
        AppendLog "=== START PDF ENGINE ==="

                ' === PDF ENGINE (BATCH, bez klikania) ===
        Dim cfg As Object
        Set cfg = CreateObject("Scripting.Dictionary")

        Dim templatePath As String
        On Error Resume Next
        templatePath = Trim$(raporty_plum.txtTemplateXlsx.text)
        On Error GoTo EH

        If Len(templatePath) = 0 Then
            PipelineFail "Brak ścieżki do wzoru raportu. Uzupełnij raporty_plum.txtTemplateXlsx."
            Exit Sub
        End If
        If dir$(templatePath) = vbNullString Then
            PipelineFail "Nie znaleziono wzoru raportu: " & templatePath
            Exit Sub
        End If

        cfg("root") = gRoot
        cfg("in_indywidualne") = gRoot & "\" & OUT_INDY
        cfg("out_pdf") = gRoot & "\" & OUT_PDF
        cfg("run_dir") = gRoot & "\" & RUN_DIR
        cfg("template_path") = templatePath

        ' Nazwy arkuszy zgodne z silnikiem i Twoimi stałymi w modNA_PdfEngine:
        cfg("sheet_dane_pers") = "DANE_PERS"
        cfg("sheet_dane_kursy") = "DANE_KURSY"
        cfg("sheet_report") = "Raport_NA"

        cfg("max_blocks") = 16
        cfg("truncate_overflow") = True

        AppendLog "=== START PDF ENGINE (BATCH) ==="
        Call modPdfEngine.PdfEngine_RunBatch(cfg)
        AppendLog "=== PDF ENGINE OK ==="
        UI_SetStatus "Zakończono poprawnie."
        UI_SetRunning False
        StopMonitor
        Exit Sub
    End If

    Dim stepName As String
    stepName = gSteps(gStepIndex).Name

    UI_SetStatus "Krok " & (gStepIndex + 1) & "/" & (UBound(gSteps) + 1) & ": " & stepName
    AppendLog "--- STEP START: " & stepName & " @ " & Format(Now, "yyyy-mm-dd hh:nn:ss")
    AppendLog "CMD: " & gSteps(gStepIndex).Cmd
    gStepStart = Now

    ' Exec -> nie blokuje UI; monitorujemy Status w OnTime
    Set gExec = gWsh.Exec(gSteps(gStepIndex).Cmd)

    StartMonitor
    Exit Sub

EH:
    PipelineFail "StartNextStep error: " & Err.Number & " - " & Err.Description
End Sub

' ---------------------------
' Monitor progress.jsonl + status procesu
' ---------------------------
Private Sub StartMonitor()
    gMonitoring = True
    ScheduleMonitor Now + PROGRESS_INTERVAL_SEC
End Sub

Private Sub ScheduleMonitor(ByVal whenTime As Date)
    On Error Resume Next
    gNextOnTime = whenTime
    Application.OnTime earliesttime:=gNextOnTime, procedure:="modNA_Launcher.MonitorProgress", schedule:=True
    On Error GoTo 0
End Sub

Public Sub MonitorProgress()
    On Error GoTo EH

    If Not gMonitoring Then Exit Sub

    ' 1) update UI z ostatniej linii progress.jsonl
    UpdateUIFromProgress

    ' 2) sprawdzamy proces
    If Not gExec Is Nothing Then
        ' Status: 0=Running, 1=Finished
        If CLng(gExec.Status) = 1 Then
            Dim exitCode As Long
            exitCode = CLng(gExec.exitCode)

            Dim stepName As String
            stepName = gSteps(gStepIndex).Name

            AppendLog "--- STEP END: " & stepName & _
                      " exit=" & exitCode & _
                      " dur=" & FormatDuration(Now - gStepStart) & _
                      " @ " & Format(Now, "yyyy-mm-dd hh:nn:ss")

            If exitCode <> 0 Then
                Dim tail As String
                tail = ReadLastLines(gRoot & "\" & RUN_LOG, 10)
                PipelineFail "Krok '" & stepName & "' zakończony błędem exit=" & exitCode & vbCrLf & vbCrLf & _
                             "Ostatnie linie logu:" & vbCrLf & tail
                Exit Sub
            End If

            ' zapis <step>.ok
            WriteTextFile gRoot & "\" & RUN_DIR & stepName & ".ok", _
                "ok " & Format(Now, "yyyy-mm-dd hh:nn:ss") & " dur=" & FormatDuration(Now - gStepStart)

            ' kolejny krok
            Set gExec = Nothing
            gStepIndex = gStepIndex + 1
            StartNextStep
            Exit Sub
        End If
    End If

    ' jeśli nadal działa -> planuj kolejny tick
    ScheduleMonitor Now + PROGRESS_INTERVAL_SEC
    Exit Sub

EH:
    PipelineFail "MonitorProgress error: " & Err.Number & " - " & Err.Description
End Sub

Private Sub StopMonitor()
    On Error Resume Next
    gMonitoring = False
    If gNextOnTime <> 0 Then
        Application.OnTime earliesttime:=gNextOnTime, procedure:="modNA_Launcher.MonitorProgress", schedule:=False
    End If
    On Error GoTo 0
End Sub

' ---------------------------
' UI helpers (podłącz do UserForm)
' ---------------------------
Private Sub UI_SetRunning(ByVal running As Boolean)
    On Error Resume Next
    With raporty_plum
        .btnStart.enabled = Not running
    End With
    On Error GoTo 0
End Sub

Private Sub UI_SetStatus(ByVal msg As String)
    On Error Resume Next
    raporty_plum.LabelStatus.caption = msg
    On Error GoTo 0
End Sub

Private Sub UI_SetProgress(ByVal pct As Double, ByVal msg As String)
    On Error Resume Next
    With raporty_plum
        .LabelStatus.caption = msg
        ' ProgressBar jako Label w Frame: LabelBar.Width = Frame.Width * pct
        If pct < 0 Then pct = 0
        If pct > 1 Then pct = 1
        .LabelBar.Width = .FrameBar.Width * pct
        .LabelPct.caption = Format(pct, "0%")
    End With
    On Error GoTo 0
End Sub

' ---------------------------
' Progress.jsonl parsing
' Zakładamy, że python dopisuje linie np:
' {"step":"parse-events","pct":0.34,"msg":"Parsing..."}
' ---------------------------
Private Sub UpdateUIFromProgress()
    Dim p As String
    p = gRoot & "\" & gRootRel(PROGRESS_FILE)
    If dir(p) = vbNullString Then Exit Sub

    Dim line As String
    line = ReadLastNonEmptyLine(p)
    If Len(line) = 0 Then Exit Sub

    Dim stepName As String, msg As String
    Dim pct As Double

    stepName = JsonGetString(line, "step")

    msg = JsonGetString(line, "message")
    If Len(msg) = 0 Then msg = JsonGetString(line, "msg")

    pct = JsonGetNumber(line, "pct")

    Dim cur As Double, tot As Double
    cur = JsonGetNumber(line, "current")
    tot = JsonGetNumber(line, "total")

' pct fallback z current/total tylko jeśli pct nieobecne (u Ciebie JsonGetNumber zwykle zwraca 0)
' więc rozróżniamy: jeśli tot>0 i cur>=0 i pct=0, to i tak policz (bo to poprawne 0..1)
    If tot > 0 Then
        If pct = 0# Then
            pct = cur / tot
        End If
    End If

    If Len(msg) = 0 Then msg = stepName

' Fallback na "percent" (0..100) tylko jeśli nadal nie mamy sensownego pct i percent > 0
    If pct = 0# Then
        Dim pct100 As Double
        pct100 = JsonGetNumber(line, "percent")
        If pct100 > 1# Then
            pct = pct100 / 100#
        ElseIf pct100 > 0# Then
            pct = pct100
        End If
    End If

' clamp 0..1
    If pct < 0# Then pct = 0#
    If pct > 1# Then pct = 1#

    ' UI
    UI_SetProgress pct, msg
End Sub

Private Function JsonGetString(ByVal jsonLine As String, ByVal key As String) As String
    ' minimalistycznie: szukamy "key":"value"
    Dim pat As String, p As Long, q1 As Long, q2 As Long
    pat = """" & key & """:"
    p = InStr(1, jsonLine, pat, vbTextCompare)
    If p = 0 Then Exit Function

    q1 = InStr(p + Len(pat), jsonLine, """")
    If q1 = 0 Then Exit Function
    q2 = InStr(q1 + 1, jsonLine, """")
    If q2 = 0 Then Exit Function

    JsonGetString = Mid$(jsonLine, q1 + 1, q2 - q1 - 1)
End Function

Private Function JsonGetNumber(ByVal jsonLine As String, ByVal key As String) As Double
    Dim pat As String, p As Long, i As Long, ch As String, buf As String
    pat = """" & key & """:"
    p = InStr(1, jsonLine, pat, vbTextCompare)
    If p = 0 Then Exit Function

    i = p + Len(pat)
    ' pomiń spacje
    Do While i <= Len(jsonLine) And Mid$(jsonLine, i, 1) = " "
        i = i + 1
    Loop

    Do While i <= Len(jsonLine)
        ch = Mid$(jsonLine, i, 1)
        If (ch Like "[0-9]") Or ch = "." Or ch = "-" Then
            buf = buf & ch
            i = i + 1
        Else
            Exit Do
        End If
    Loop

    If Len(buf) = 0 Then Exit Function
    JsonGetNumber = CDbl(Replace(buf, ",", "."))
End Function

' ---------------------------
' Logging / pliki / utilsy
' ---------------------------
Private Sub PipelineFail(ByVal message As String)
    AppendLog "!!! PIPELINE FAIL: " & message
    StopMonitor
    UI_SetRunning False
    UI_SetStatus "BŁĄD: zobacz run.log"

    MsgBox message, vbCritical, "mRNA-PLUM Pipeline"
End Sub

Private Sub AppendLog(ByVal s As String)
    WriteTextFile gRoot & "\" & RUN_LOG, s & vbCrLf, True
End Sub

Private Sub WriteTextFile(ByVal fullPath As String, ByVal text As String, Optional ByVal append As Boolean = False)
    Dim fso As Object, ts As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    EnsureFolderExists fso.GetParentFolderName(fullPath)

    If append And fso.FileExists(fullPath) Then
        Set ts = fso.OpenTextFile(fullPath, 8, True, -1) ' ForAppending, Unicode
    Else
        Set ts = fso.OpenTextFile(fullPath, 2, True, -1) ' ForWriting, Unicode
    End If

    ts.Write text
    ts.Close
End Sub

Private Function ReadLastLines(ByVal fullPath As String, ByVal n As Long) As String
    ' prosto i bezpiecznie: czytamy cały plik tylko dla tail (run.log zwykle nie jest ogromny)
    On Error GoTo EH

    Dim fso As Object, ts As Object, allText As String, arr() As String
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FileExists(fullPath) Then Exit Function

    Set ts = fso.OpenTextFile(fullPath, 1, False, -1) ' ForReading, Unicode
    allText = ts.ReadAll
    ts.Close

    arr = Split(Replace(allText, vbCrLf, vbLf), vbLf)

    Dim i As Long, startI As Long, buf As String
    startI = UBound(arr) - n + 1
    If startI < 0 Then startI = 0

    For i = startI To UBound(arr)
        If Len(arr(i)) > 0 Then buf = buf & arr(i) & vbCrLf
    Next

    ReadLastLines = buf
    Exit Function

EH:
    ReadLastLines = "(nie udało się odczytać tail logu: " & Err.Description & ")"
End Function

Private Function ReadLastNonEmptyLine(ByVal fullPath As String) As String
    On Error GoTo EH

    Dim fso As Object, ts As Object, allText As String, arr() As String
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FileExists(fullPath) Then Exit Function

    Set ts = fso.OpenTextFile(fullPath, 1, False, -1)
    allText = ts.ReadAll
    ts.Close

    arr = Split(Replace(allText, vbCrLf, vbLf), vbLf)

    Dim i As Long
    For i = UBound(arr) To 0 Step -1
        If Len(Trim$(arr(i))) > 0 Then
            ReadLastNonEmptyLine = Trim$(arr(i))
            Exit Function
        End If
    Next i
    Exit Function

EH:
    ' ignoruj
End Function

Private Function HasAnyFiles(ByVal folderPath As String, ByVal pattern As String) As Boolean
    Dim p As String
    p = folderPath
    If Right$(p, 1) <> "\" Then p = p & "\"
    HasAnyFiles = (dir(p & pattern) <> vbNullString)
End Function

Private Sub EnsureFolders()
    EnsureFolderExists gRoot & "\" & RUN_DIR
    EnsureFolderExists gRoot & "\" & OUT_INDY
    EnsureFolderExists gRoot & "\" & OUT_PDF
End Sub

Private Sub EnsureFolderExists(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Len(folderPath) = 0 Then Exit Sub
    If Not fso.FolderExists(folderPath) Then fso.CreateFolder folderPath
End Sub

Private Sub SafeKillFile(ByVal fullPath As String)
    On Error Resume Next
    If Len(dir(fullPath)) > 0 Then Kill fullPath
    On Error GoTo 0
End Sub

Private Sub ClearOkFlags()
    On Error Resume Next
    Dim f As String
    f = dir(gRoot & "\" & RUN_DIR & "*.ok")
    Do While Len(f) > 0
        Kill gRoot & "\" & RUN_DIR & f
        f = dir()
    Loop
    On Error GoTo 0
End Sub

Private Function FormatDuration(ByVal dtDays As Double) As String
    Dim totalSec As Long
    totalSec = CLng(dtDays * 86400#)
    FormatDuration = (totalSec \ 60) & "m " & (totalSec Mod 60) & "s"
End Function

Private Function Quote(ByVal s As String) As String
    Quote = """" & s & """"
End Function

Private Function gRootRel(ByVal rel As String) As String
    gRootRel = rel
    If Left$(gRootRel, 1) = "\" Then gRootRel = Mid$(gRootRel, 2)
End Function
Private Function UF_Text(ByVal formObj As Object, ByVal ctrlName As String) As String
    ' Bezpiecznie pobiera .Text z kontrolki UserForm po nazwie.
    ' Zwraca "" jeśli kontrolka nie istnieje.
    On Error GoTo EH
    Dim ctl As Object
    Set ctl = CallByName(formObj, ctrlName, VbGet)
    UF_Text = Trim$(CStr(CallByName(ctl, "Text", VbGet)))
    Exit Function
EH:
    UF_Text = ""
End Function
--------------------------------------------------------------------------------

================================================================================
=== Component: modNA_UIInputs  [Standard Module]
================================================================================
Option Explicit

Private Const KEYS_REL As String = "_data\KEYS.xlsx"

Public Sub UI_LoadDefaults()
    On Error Resume Next
    With raporty_plum
        .txtLogsFolder.text = GetSetting("mRNA-PLUM", "Paths", "LogsFolder", "")
        .txtTemplateXlsx.text = ""
        .txtKeysXlsx.text = GetSetting("mRNA-PLUM", "Paths", "KeysXlsx", ThisWorkbook.path & "\_data\KEYS.xlsx")
    End With
    On Error GoTo 0
End Sub

Public Sub UI_SaveDefaults()
    On Error Resume Next
    SaveSetting "mRNA-PLUM", "Paths", "LogsFolder", raporty_plum.txtLogsFolder.text
    SaveSetting "mRNA-PLUM", "Paths", "KeysXlsx", raporty_plum.txtKeysXlsx.text
    On Error GoTo 0
End Sub

Public Function UI_ValidateInputs(ByRef errMsg As String) As Boolean

    Dim logsFolder As String, templateXlsx As String, keysXlsx As String
    logsFolder = Trim$(raporty_plum.txtLogsFolder.text)
    templateXlsx = Trim$(raporty_plum.txtTemplateXlsx.text)
    keysXlsx = Trim$(raporty_plum.txtKeysXlsx.text)

    If Len(logsFolder) = 0 Then errMsg = "Nie wskazano folderu z logami.": Exit Function
    If Not FolderExists(logsFolder) Then errMsg = "Folder logów nie istnieje: " & logsFolder: Exit Function

    If Len(keysXlsx) = 0 Then errMsg = "Nie wskazano pliku KEYS.xlsx.": Exit Function
    If Not FileExists(keysXlsx) Then errMsg = "Plik KEYS.xlsx nie istnieje: " & keysXlsx: Exit Function

    If Len(templateXlsx) = 0 Then errMsg = "Nie wskazano wzoru raportu (template).": Exit Function
    If Not FileExists(templateXlsx) Then errMsg = "Wzór raportu nie istnieje: " & templateXlsx: Exit Function

    UI_ValidateInputs = True

End Function

Public Function BuildRuntimeConfigYaml(ByVal rootPath As String) As String
    Dim cfgPath As String
    cfgPath = rootPath & "\_run\config.runtime.yaml"

    Dim logsFolder As String, templateXlsx As String, keysXlsx As String
    logsFolder = NormalizePath(raporty_plum.txtLogsFolder.text)
    templateXlsx = NormalizePath(raporty_plum.txtTemplateXlsx.text)
    keysXlsx = rootPath & "\" & KEYS_REL

    EnsureFolder rootPath & "\_run"
    EnsureFolder rootPath & "\_out"
    EnsureFolder rootPath & "\_out\indywidualne"
    EnsureFolder rootPath & "\_out\pdf"

    Dim y As String
    y = ""
    y = y & "root: """ & YamlEscape(rootPath) & """" & vbCrLf

    y = y & "data:" & vbCrLf
    y = y & "  logs_dir: """ & YamlEscape(logsFolder) & """" & vbCrLf
    y = y & "  logs_recursive: true" & vbCrLf ' <— ważne: folder + podfoldery

    y = y & "run:" & vbCrLf
    y = y & "  dir: """ & YamlEscape(rootPath & "\_run") & """" & vbCrLf

    y = y & "out:" & vbCrLf
    y = y & "  indywidualne_dir: """ & YamlEscape(rootPath & "\_out\indywidualne") & """" & vbCrLf
    y = y & "  pdf_dir: """ & YamlEscape(rootPath & "\_out\pdf") & """" & vbCrLf

    y = y & "parse_events:" & vbCrLf
    y = y & "  keys_xlsx: """ & YamlEscape(keysXlsx) & """" & vbCrLf
    y = y & "  keys_sheet: ""KEYS""" & vbCrLf

    y = y & "pdf:" & vbCrLf
    y = y & "  template_xlsx: """ & YamlEscape(templateXlsx) & """" & vbCrLf

    WriteTextFileUtf8 cfgPath, y
    BuildRuntimeConfigYaml = cfgPath
End Function

' --- dialogi i utils (zostają z poprzedniej wersji) ---
Public Function PickFolderDialog(ByVal title As String, Optional ByVal initialPath As String = "") As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(4)
    fd.title = title
    If Len(initialPath) > 0 Then fd.InitialFileName = EnsureTrailingBackslash(initialPath)
    fd.AllowMultiSelect = False
    If fd.Show <> -1 Then Exit Function
    PickFolderDialog = CStr(fd.SelectedItems(1))
    Exit Function
EH:
    PickFolderDialog = ""
End Function

Public Function PickFileDialog(ByVal title As String, ByVal filterDesc As String, ByVal filterPattern As String, Optional ByVal initialPath As String = "") As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(3)
    fd.title = title
    fd.AllowMultiSelect = False
    fd.Filters.Clear
    fd.Filters.Add filterDesc, filterPattern
    If Len(initialPath) > 0 Then fd.InitialFileName = initialPath
    If fd.Show <> -1 Then Exit Function
    PickFileDialog = CStr(fd.SelectedItems(1))
    Exit Function
EH:
    PickFileDialog = ""
End Function

Private Function FileExists(ByVal p As String) As Boolean: FileExists = (Len(dir(p)) > 0): End Function
Private Function FolderExists(ByVal p As String) As Boolean
    On Error Resume Next
    FolderExists = (Len(dir(p, vbDirectory)) > 0)
    On Error GoTo 0
End Function

Private Sub EnsureFolder(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(folderPath) Then fso.CreateFolder folderPath
End Sub

Private Function EnsureTrailingBackslash(ByVal p As String) As String
    If Len(p) = 0 Then EnsureTrailingBackslash = "": Exit Function
    If Right$(p, 1) = "\" Then EnsureTrailingBackslash = p Else EnsureTrailingBackslash = p & "\"
End Function

Private Function NormalizePath(ByVal p As String) As String
    NormalizePath = Replace(Trim$(p), "/", "\")
End Function

Private Function YamlEscape(ByVal s As String) As String
    YamlEscape = Replace(s, """", "\""")
End Function

Private Sub WriteTextFileUtf8(ByVal fullPath As String, ByVal text As String)
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    stm.Type = 2
    stm.Charset = "utf-8"
    stm.Open
    stm.WriteText text
    stm.Position = 0
    stm.SaveToFile fullPath, 2
    stm.Close
End Sub

--------------------------------------------------------------------------------

================================================================================
=== Component: modNA_Convert  [Standard Module]
================================================================================
Option Explicit

Public Sub ConvertXlsxFolderToCsv(ByVal sourceFolder As String, ByVal rootPath As String)

    On Error GoTo EH

    sourceFolder = Trim$(Replace(sourceFolder, "/", "\"))
    If Right$(sourceFolder, 1) = "\" Then sourceFolder = Left$(sourceFolder, Len(sourceFolder) - 1)

    If Len(sourceFolder) = 0 Then
        MsgBox "Nie wskazano folderu.", vbExclamation
        Exit Sub
    End If

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    If Not fso.FolderExists(sourceFolder) Then
        MsgBox "Folder nie istnieje: " & sourceFolder, vbExclamation
        Exit Sub
    End If

    Dim targetFolder As String
    targetFolder = rootPath & "\_data\converted_csv"
    EnsureFolder targetFolder

    Application.ScreenUpdating = False
    Application.DisplayAlerts = False

    ProcessFolderRecursive sourceFolder, targetFolder

    Application.DisplayAlerts = True
    Application.ScreenUpdating = True

    MsgBox "Konwersja zakończona.", vbInformation
    Exit Sub

EH:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
    MsgBox "Błąd konwersji: " & Err.Description, vbCritical
End Sub


Private Sub ProcessFolderRecursive(ByVal folderPath As String, ByVal targetFolder As String)

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    Dim f As Object
    Dim subF As Object

    For Each f In fso.GetFolder(folderPath).files
        If LCase(fso.GetExtensionName(f.Name)) = "xlsx" Then
            ConvertOneFile f.path, targetFolder
        End If
    Next f

    For Each subF In fso.GetFolder(folderPath).SubFolders
        ProcessFolderRecursive subF.path, targetFolder
    Next subF

End Sub


Private Sub ConvertOneFile(ByVal fullPath As String, ByVal targetFolder As String)

    Dim wb As Workbook
    Dim csvPath As String

    Set wb = Workbooks.Open(fullPath, ReadOnly:=True)

    csvPath = targetFolder & "\" & _
              Replace(wb.Name, ".xlsx", ".csv")

    wb.SaveAs fileName:=csvPath, _
              FileFormat:=xlCSVUTF8

    wb.Close False

End Sub


Private Sub EnsureFolder(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(folderPath) Then
        fso.CreateFolder folderPath
    End If
End Sub

--------------------------------------------------------------------------------

================================================================================
=== Component: modMergeCsvEmail  [Standard Module]
================================================================================
Option Explicit

' ============================
' CSV merge: id + dane osobowe
' email = klucz łączenia
' wynik: dane_do_raportu.csv w folderze pierwszego pliku
' ============================

Public Sub MergeCsv_ByEmail()
    On Error GoTo EH

    Dim csv1Path As String, csv2Path As String
    csv1Path = PickCsvFile("Wybierz PIERWSZY plik CSV (Pełna nazwa, E-mail, ...)")
    If Len(csv1Path) = 0 Then Exit Sub

    csv2Path = PickCsvFile("Wybierz DRUGI plik CSV (id,email)")
    If Len(csv2Path) = 0 Then Exit Sub

    Dim outPath As String
    outPath = ParentFolder(csv1Path) & "dane_do_raportu.csv"

    ' 1) wczytaj mapę email -> id z csv2
    Dim mapEmailToId As Object
    Set mapEmailToId = CreateObject("Scripting.Dictionary")
    mapEmailToId.CompareMode = 1 ' TextCompare

    Dim csv2Text As String
    csv2Text = ReadTextUtf8(csv2Path)

    Dim lines2 As Variant
    lines2 = SplitLines(csv2Text)
    If UBound(lines2) < 0 Then Err.Raise vbObjectError + 1, , "Drugi plik CSV jest pusty."

    Dim hdr2 As Variant
    Dim delim2 As String
    delim2 = DetectDelimiter(CStr(lines2(0)))
    hdr2 = ParseCsvLineEx(CStr(lines2(0)), delim2)

    Dim idx2_id As Long, idx2_email As Long
    idx2_id = FindHeaderIndex(hdr2, "id")
    idx2_email = FindHeaderIndex(hdr2, "email")

    If idx2_id < 0 Or idx2_email < 0 Then
        Err.Raise vbObjectError + 2, , "Drugi CSV musi mieć nagłówki: id,email"
    End If

    Dim i As Long
    For i = 1 To UBound(lines2)
        If Len(Trim$(CStr(lines2(i)))) = 0 Then GoTo Next2

        Dim row2 As Variant
        row2 = ParseCsvLineEx(CStr(lines2(i)), delim2)

        Dim em2 As String, id2 As String
        em2 = NormalizeEmail(GetFieldSafe(row2, idx2_email))
        id2 = Trim$(GetFieldSafe(row2, idx2_id))

        If Len(em2) > 0 Then
            ' jeśli duplikaty emaili -> ostatni wygrywa (możesz zmienić na pierwszy)
            mapEmailToId(em2) = id2
        End If
Next2:
    Next i

    ' 2) czytaj csv1 i zapisuj wynik z dodanym "id" na początku
    Dim csv1Text As String
    csv1Text = ReadTextUtf8(csv1Path)

    Dim lines1 As Variant
    lines1 = SplitLines(csv1Text)
    If UBound(lines1) < 0 Then Err.Raise vbObjectError + 3, , "Pierwszy plik CSV jest pusty."

    Dim hdr1 As Variant
    Dim delim1 As String
    delim1 = DetectDelimiter(CStr(lines1(0)))
    hdr1 = ParseCsvLineEx(CStr(lines1(0)), delim1)

    Dim idx1_email As Long
    ' w Twoim nagłówku jest "E-mail" (z myślnikiem)
    idx1_email = FindHeaderIndex(hdr1, "E-mail")
    If idx1_email < 0 Then idx1_email = FindHeaderIndex(hdr1, "Email")
    If idx1_email < 0 Then idx1_email = FindHeaderIndex(hdr1, "E-mail ") ' awaryjnie

    If idx1_email < 0 Then
        Err.Raise vbObjectError + 4, , "Pierwszy CSV musi mieć kolumnę nagłówka: E-mail"
    End If

    Dim sb As String
    sb = ""

    ' nagłówek wyjściowy: id + oryginalne nagłówki
    sb = sb & CsvJoinWithLeadingId("id", hdr1) & vbCrLf

    Dim notFound As Long, total As Long
    For i = 1 To UBound(lines1)
        Dim ln As String
        ln = CStr(lines1(i))
        If Len(Trim$(ln)) = 0 Then GoTo Next1

        total = total + 1

        Dim row1 As Variant
        row1 = ParseCsvLineEx(ln, delim1)

        Dim em1 As String
        em1 = NormalizeEmail(GetFieldSafe(row1, idx1_email))

        Dim idOut As String
        If Len(em1) > 0 And mapEmailToId.Exists(em1) Then
            idOut = CStr(mapEmailToId(em1))
        Else
            idOut = "" ' brak dopasowania -> puste id
            notFound = notFound + 1
        End If

        sb = sb & CsvJoinWithLeadingId(idOut, row1) & vbCrLf
Next1:
    Next i

    WriteTextUtf8 outPath, sb

    MsgBox "Zapisano: " & outPath & vbCrLf & _
           "Wiersze: " & total & vbCrLf & _
           "Brak dopasowania id: " & notFound, vbInformation
    Exit Sub

EH:
    MsgBox "Błąd: " & Err.Number & vbCrLf & Err.Description, vbCritical
End Sub

' ----------------------------
' UI: wybór pliku
' ----------------------------
Private Function PickCsvFile(ByVal title As String) As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(3) ' msoFileDialogFilePicker

    With fd
        .title = title
        .AllowMultiSelect = False
        .Filters.Clear
        .Filters.Add "CSV", "*.csv"
        .Filters.Add "Wszystkie pliki", "*.*"
        If .Show <> -1 Then Exit Function
        PickCsvFile = .SelectedItems(1)
    End With
    Exit Function
EH:
    PickCsvFile = ""
End Function

' ----------------------------
' UTF-8 read/write (ADODB.Stream)
' ----------------------------
Private Function ReadTextUtf8(ByVal path As String) As String
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2 ' adTypeText
        .Charset = "utf-8"
        .Open
        .LoadFromFile path
        ReadTextUtf8 = .ReadText(-1)
        .Close
    End With
End Function

Private Sub WriteTextUtf8(ByVal path As String, ByVal textData As String)
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2 ' adTypeText
        .Charset = "utf-8"
        .Open
        .WriteText textData
        .SaveToFile path, 2 ' adSaveCreateOverWrite
        .Close
    End With
End Sub

' ----------------------------
' CSV parsing (quotes-aware)
' ----------------------------
Private Function ParseCsvLineEx(ByVal line As String, ByVal delim As String) As Variant
    Dim res() As String
    Dim i As Long, ch As String
    Dim cur As String
    Dim inQ As Boolean

    ReDim res(0 To 0)
    cur = ""
    inQ = False

    i = 1
    Do While i <= Len(line)
        ch = Mid$(line, i, 1)

        If inQ Then
            If ch = """" Then
                If i < Len(line) And Mid$(line, i + 1, 1) = """" Then
                    cur = cur & """"
                    i = i + 1
                Else
                    inQ = False
                End If
            Else
                cur = cur & ch
            End If
        Else
            If ch = delim Then
                AppendField res, cur
                cur = ""
            ElseIf ch = """" Then
                inQ = True
            Else
                cur = cur & ch
            End If
        End If

        i = i + 1
    Loop

    AppendField res, cur
    ParseCsvLineEx = res
End Function

Private Sub AppendField(ByRef arr() As String, ByVal v As String)
    Dim n As Long
    n = UBound(arr)
    If n = 0 And Len(arr(0)) = 0 Then
        arr(0) = v
    Else
        ReDim Preserve arr(0 To n + 1)
        arr(n + 1) = v
    End If
End Sub

Private Function CsvJoinWithLeadingId(ByVal idVal As String, ByVal row As Variant) As String
    Dim i As Long
    Dim s As String
    s = CsvEscape(idVal)

    For i = LBound(row) To UBound(row)
        s = s & "," & CsvEscape(CStr(row(i)))
    Next i
    CsvJoinWithLeadingId = s
End Function

Private Function CsvEscape(ByVal v As String) As String
    Dim mustQ As Boolean
    mustQ = (InStr(1, v, ",", vbBinaryCompare) > 0) Or _
            (InStr(1, v, """", vbBinaryCompare) > 0) Or _
            (InStr(1, v, vbCr, vbBinaryCompare) > 0) Or _
            (InStr(1, v, vbLf, vbBinaryCompare) > 0)

    If InStr(1, v, """", vbBinaryCompare) > 0 Then
        v = Replace$(v, """", """""")
    End If

    If mustQ Then
        CsvEscape = """" & v & """"
    Else
        CsvEscape = v
    End If
End Function

' ----------------------------
' Helpers
' ----------------------------
Private Function FindHeaderIndex(ByVal headers As Variant, ByVal headerName As String) As Long
    Dim i As Long
    FindHeaderIndex = -1
    For i = LBound(headers) To UBound(headers)
        If NormalizeHeader(CStr(headers(i))) = NormalizeHeader(headerName) Then
            FindHeaderIndex = i
            Exit Function
        End If
    Next i
End Function

Private Function NormalizeHeader(ByVal s As String) As String
    s = Trim$(s)
    s = Replace$(s, Chr$(160), " ")
    s = LCase$(s)
    NormalizeHeader = s
End Function

Private Function NormalizeEmail(ByVal s As String) As String
    s = Trim$(s)
    s = Replace$(s, Chr$(160), " ")
    s = LCase$(s)
    NormalizeEmail = s
End Function

Private Function GetFieldSafe(ByVal row As Variant, ByVal idx As Long) As String
    On Error GoTo EH
    If idx < LBound(row) Or idx > UBound(row) Then Exit Function
    GetFieldSafe = CStr(row(idx))
    Exit Function
EH:
    GetFieldSafe = ""
End Function

Private Function ParentFolder(ByVal fullPath As String) As String
    Dim p As Long
    p = InStrRev(fullPath, "\")
    If p > 0 Then
        ParentFolder = Left$(fullPath, p)
    Else
        ParentFolder = ""
    End If
End Function

Private Function SplitLines(ByVal s As String) As Variant
    ' normalizacja zakończeń linii
    s = Replace$(s, vbCrLf, vbLf)
    s = Replace$(s, vbCr, vbLf)
    If Len(s) = 0 Then
        SplitLines = Array()
    Else
        SplitLines = Split(s, vbLf)
    End If
End Function
Private Function DetectDelimiter(ByVal line As String) As String
    ' prosto: który znak częściej występuje w nagłówku
    Dim cComma As Long, cSemi As Long
    cComma = Len(line) - Len(Replace$(line, ",", ""))
    cSemi = Len(line) - Len(Replace$(line, ";", ""))
    If cSemi > cComma Then DetectDelimiter = ";" Else DetectDelimiter = ","
End Function
--------------------------------------------------------------------------------



================================================================================
vba\forms\raporty_plum.vb
================================================================================

﻿' === Component: raporty_plum [UserForm]
' === Exported: 2026-02-26 14:22:22

Option Explicit

Private Sub Label3_Click()

End Sub

Private Sub UserForm_Initialize()

    Me.caption = "mRNA-PLUM — Raporty Nauczycieli Akademickich"

    ' wczytaj ostatnie ścieżki
    Me.txtLogsFolder.text = GetSetting("mRNA-PLUM", "Paths", "LogsFolder", "")
    Me.txtTemplateXlsx.text = ""

    ' KEYS: pamiętaj wybór, a jak brak to domyślnie root\_data\KEYS.xlsx
    Dim defKeys As String
    defKeys = ThisWorkbook.path & "\_data\KEYS.xlsx"

    Me.txtKeysXlsx.text = GetSetting("mRNA-PLUM", "Paths", "KeysXlsx", defKeys)
    Me.txtInputsDir.text = GetSetting("mRNA-PLUM", "Paths", "InputsDir", ThisWorkbook.path & "\_data\inputs")

    ResetProgress
    Me.LabelStatus.caption = "Gotowy."

End Sub


' =========================================================
' WYBÓR FOLDERU LOGÓW
' =========================================================
Private Sub btnPickLogsFolder_Click()

    Dim p As String
    p = modNA_UIInputs.PickFolderDialog( _
            "Wskaż folder nadrzędny z logami (z podfolderami)", _
            Me.txtLogsFolder.text)

    If Len(p) > 0 Then
        Me.txtLogsFolder.text = p
    End If

End Sub


' =========================================================
' WYBÓR TEMPLATE
' =========================================================
Private Sub btnPickTemplate_Click()

    Dim p As String
    p = modNA_UIInputs.PickFileDialog( _
            "Wskaż wzór raportu (Excel)", _
            "Excel", "*.xlsx", "")

    If Len(p) > 0 Then
        Me.txtTemplateXlsx.text = p
    End If

End Sub


' =========================================================
' START PIPELINE
' =========================================================
Private Sub btnStart_Click()

    Dim errMsg As String

    If Not modNA_UIInputs.UI_ValidateInputs(errMsg) Then
        MsgBox errMsg, vbExclamation
        Exit Sub
    End If

    ' Zapamiętaj folder logów
    SaveSetting "mRNA-PLUM", "Paths", "LogsFolder", Me.txtLogsFolder.text
    SaveSetting "mRNA-PLUM", "Paths", "KeysXlsx", Me.txtKeysXlsx.text
    SaveSetting "mRNA-PLUM", "Paths", "InputsDir", Me.txtInputsDir.text

    Me.btnStart.enabled = False
    Me.LabelStatus.caption = "Inicjalizacja..."

    modNA_Launcher.StartPipeline

End Sub


' =========================================================
' ZAMKNIJ
' =========================================================
Private Sub btnClose_Click()
    Unload Me
End Sub


' =========================================================
' PUBLIC — wywoływane z Launchera
' =========================================================

Public Sub SetStatus(ByVal txt As String)
    Me.LabelStatus.caption = txt
End Sub

Public Sub SetProgress(ByVal pct As Double, ByVal txt As String)

    If pct < 0 Then pct = 0
    If pct > 1 Then pct = 1

    Me.LabelBar.Width = Me.FrameBar.Width * pct
    Me.LabelPct.caption = Format(pct, "0%")
    Me.LabelStatus.caption = txt

End Sub

Public Sub ResetProgress()
    Me.LabelBar.Width = 0
    Me.LabelPct.caption = "0%"
End Sub

Public Sub SetRunning(ByVal running As Boolean)
    Me.btnStart.enabled = Not running
End Sub

Private Sub btnPickKeys_Click()

    Dim p As String
    p = modNA_UIInputs.PickFileDialog( _
            "Wskaż plik KEYS.xlsx (reguły parsowania)", _
            "Excel", "*.xlsx", _
            Me.txtKeysXlsx.text)

    If Len(p) > 0 Then
        Me.txtKeysXlsx.text = p
    End If

End Sub
Private Sub btnConvertXlsx_Click()
    On Error GoTo EH

    Dim src As String
    src = Trim$(Me.txtInputsDir.text) ' albo osobny textbox np. txtXlsxSourceFolder

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    ' normalizacja (często ratuje przy kopiuj/wklej)
    src = Replace$(src, """", "")
    src = Trim$(src)
    If Right$(src, 1) = "\" Then src = Left$(src, Len(src) - 1)

    If Len(src) = 0 Or Not fso.FolderExists(src) Then
        src = modNA_UIInputs.PickFolderDialog( _
                "Wskaż folder z XLSX do konwersji (z podfolderami)", _
                ThisWorkbook.path)
        If Len(src) = 0 Then Exit Sub
        Me.txtInputsDir.text = src
    End If

    Me.LabelStatus.caption = "Konwersja XLSX › CSV..."
    DoEvents

    modNA_Convert.ConvertXlsxFolderToCsv src, ThisWorkbook.path

    Me.LabelStatus.caption = "Konwersja zakończona."
    Exit Sub

EH:
    Me.LabelStatus.caption = "Błąd konwersji XLSX › CSV."
    MsgBox "Błąd: " & Err.Description, vbExclamation
End Sub
Private Sub btnMergeTeacherIdCsv_Click()
    On Error GoTo EH

    Me.LabelStatus.caption = "Scalanie CSV... wybierz 2 pliki."
    DoEvents

    Call MergeCsv_ByEmail

    Exit Sub
EH:
    Me.LabelStatus.caption = "Błąd scalania CSV."
    MsgBox "Błąd scalania CSV: " & Err.Description, vbExclamation
End Sub


Private Sub btnPickInputsDir_Click()
    Dim p As String
    p = modNA_UIInputs.PickFolderDialog( _
            "Wskaż folder z plikami źródłowymi", _
            Me.txtInputsDir.text)

    If Len(p) > 0 Then
        Me.txtInputsDir.text = p
    End If
End Sub


================================================================================
vba\modules\Autostart.vb
================================================================================

﻿' === Component: Autostart [Standard Module]
' === Exported: 2026-02-26 14:22:22

Sub StartRaportowanie()
    frmMainMenu.Show vbModeless
End Sub

================================================================================
vba\modules\Autozamykanie.vb
================================================================================

﻿' === Component: Autozamykanie [Standard Module]
' === Exported: 2026-02-26 14:22:22

Sub ZamknijSkoroszyt()
    ThisWorkbook.Close SaveChanges:=False
End Sub

================================================================================
vba\modules\Class1.vb
================================================================================

﻿' === Component: Class1 [Class Module]
' === Exported: 2026-02-26 14:22:22



================================================================================
vba\modules\modExportVBA.vb
================================================================================

﻿' === Component: modExportVBA [Standard Module]
' === Exported: 2026-02-26 14:22:22

' === modExportVBA.bas (rozszerzenie: TXT + osobne .vb do folderu) ===
Option Explicit

Private Const vbext_ct_StdModule As Long = 1
Private Const vbext_ct_ClassModule As Long = 2
Private Const vbext_ct_MSForm As Long = 3
Private Const vbext_ct_Document As Long = 100

' --- WIDOCZNE W ALT+F8 (bez parametrów) ---
Public Sub ExportAllVBAtoSingleTxt_UI()
    ExportAllVBAtoSingleTxt_Worker ""
End Sub

Public Sub ExportAllVBAtoSingleTxt_ToFolderDesktop()
    Dim desk As String
    desk = CreateObject("WScript.Shell").SpecialFolders("Desktop")

    Dim outPath As String
    outPath = desk & "\" & SafeStr(ThisWorkbookOrDoc.VBProject.Name) & "_VBA_" & Format(Now, "yyyymmdd_HHNNSS") & ".txt"
    ExportAllVBAtoSingleTxt_Worker outPath
End Sub

' NOWE: folder + osobne .vb (i dodatkowo 1 zbiorczy .txt w tym samym folderze)
Public Sub ExportAllVBA_ToFolder_WithSeparateVB_UI()
    ExportAllVBA_ToFolder_WithSeparateVB_Worker ""
End Sub
' --- /WIDOCZNE ---


' =========================
' 1) Eksport do jednego TXT
' =========================
Private Sub ExportAllVBAtoSingleTxt_Worker(Optional ByVal outPath As String = "")
    On Error GoTo blad

    Dim proj As Object, comps As Object, c As Object
    Dim hostName As String, projName As String, whenStr As String
    hostName = Application.Name
    Set proj = ThisWorkbookOrDoc.VBProject
    Set comps = proj.VBComponents
    projName = SafeStr(proj.Name)
    whenStr = Format(Now, "yyyy-mm-dd HH:nn:ss")

    If Len(outPath) = 0 Then
        outPath = PickSaveTxt(projName & "_VBA_" & Format(Now, "yyyymmdd_HHNNSS") & ".txt")
        If Len(outPath) = 0 Then Exit Sub
    End If

    Dim sb As String
    sb = "# VBA EXPORT" & vbCrLf & _
         "# Host: " & hostName & vbCrLf & _
         "# Project: " & projName & vbCrLf & _
         "# Date: " & whenStr & vbCrLf & _
         "# Components: " & comps.Count & vbCrLf & _
         String(80, "-") & vbCrLf

    For Each c In comps
        sb = sb & ComponentBlock(c) & vbCrLf
    Next c

    SaveTextUTF8 outPath, sb
    MsgBox "Zapisano eksport VBA do:" & vbCrLf & outPath, vbInformation
    Exit Sub

blad:
    HandleVBAccessError "Błąd eksportu (TXT)", Err
End Sub


' ==========================================
' 2) NOWE: Eksport do folderu + osobne .vb
' ==========================================
Private Sub ExportAllVBA_ToFolder_WithSeparateVB_Worker(Optional ByVal rootOutDir As String = "")
    On Error GoTo blad

    Dim proj As Object, comps As Object, c As Object
    Set proj = ThisWorkbookOrDoc.VBProject
    Set comps = proj.VBComponents

    Dim hostBase As String
    hostBase = GetHostFileBaseName() ' nazwa "głównego pliku" (bez rozszerzenia)
    If Len(hostBase) = 0 Then hostBase = SafeStr(proj.Name)

    If Len(rootOutDir) = 0 Then
        rootOutDir = PickFolder("Wybierz lokalizację docelową (katalog nadrzędny):")
        If Len(rootOutDir) = 0 Then Exit Sub
    End If

    Dim stamp As String: stamp = Format(Now, "yyyymmdd_HHNNSS")
    Dim outFolder As String
    outFolder = rootOutDir & "\" & CleanFileName(hostBase) & "_VBA_" & stamp

    EnsureFolderExists outFolder
    EnsureFolderExists outFolder & "\Modules"

    ' (A) Zapis zbiorczego TXT do tego samego folderu
    Dim txtPath As String
    txtPath = outFolder & "\" & CleanFileName(hostBase) & "_VBA_" & stamp & ".txt"
    ExportAllVBAtoSingleTxt_Worker txtPath

    ' (B) Zapis każdego komponentu do osobnego .vb
    Dim savedCount As Long: savedCount = 0
    For Each c In comps
        Dim codeLines As Long: codeLines = c.CodeModule.CountOfLines

        Dim code As String
        If codeLines > 0 Then
            code = c.CodeModule.lines(1, codeLines)
        Else
            code = "" ' puste moduły też zapisujemy, żeby było widać że istnieją
        End If

        Dim header As String
        header = "' === Component: " & c.Name & " [" & ComponentTypeName(c.Type) & "]" & vbCrLf & _
                 "' === Exported: " & Format(Now, "yyyy-mm-dd HH:nn:ss") & vbCrLf & vbCrLf

        Dim vbPath As String
        vbPath = outFolder & "\Modules\" & CleanFileName(c.Name) & ".vb"

        SaveTextUTF8 vbPath, header & code
        savedCount = savedCount + 1
    Next c

    MsgBox "Zapisano folder eksportu:" & vbCrLf & outFolder & vbCrLf & vbCrLf & _
           "• TXT: " & txtPath & vbCrLf & _
           "• Pliki .vb: " & savedCount & " szt. w \Modules\", vbInformation
    Exit Sub

blad:
    HandleVBAccessError "Błąd eksportu (folder + .vb)", Err
End Sub


' === Helper: zwraca obiekt-kontener projektu (Excel: ThisWorkbook, Word: ActiveDocument)
Private Function ThisWorkbookOrDoc() As Object
    Dim o As Object

    On Error Resume Next
    Set o = CallByName(Application, "ThisWorkbook", VbGet)
    On Error GoTo 0
    If Not o Is Nothing Then
        Set ThisWorkbookOrDoc = o
        Exit Function
    End If

    On Error Resume Next
    Set o = CallByName(Application, "ActiveDocument", VbGet)
    On Error GoTo 0
    If Not o Is Nothing Then
        Set ThisWorkbookOrDoc = o
        Exit Function
    End If

    Err.Raise 5, , "Nie rozpoznano hosta (Excel/Word) – nie można uzyskać kontenera VBProject."
End Function


Private Function ComponentBlock(ByVal comp As Object) As String
    Dim kind As String: kind = ComponentTypeName(comp.Type)
    Dim codeLines As Long: codeLines = comp.CodeModule.CountOfLines
    Dim code As String: If codeLines > 0 Then code = comp.CodeModule.lines(1, codeLines)

    ComponentBlock = _
        String(80, "=") & vbCrLf & _
        "=== Component: " & comp.Name & "  [" & kind & "]" & vbCrLf & _
        String(80, "=") & vbCrLf & _
        code & vbCrLf & _
        String(80, "-") & vbCrLf
End Function

Private Function ComponentTypeName(ByVal t As Long) As String
    Select Case t
        Case vbext_ct_StdModule:   ComponentTypeName = "Standard Module"
        Case vbext_ct_ClassModule: ComponentTypeName = "Class Module"
        Case vbext_ct_MSForm:      ComponentTypeName = "UserForm"
        Case vbext_ct_Document:    ComponentTypeName = "Document/Sheet Module"
        Case Else:                 ComponentTypeName = "Unknown(" & t & ")"
    End Select
End Function


' ===== UI pickery =====
Private Function PickSaveTxt(ByVal suggestName As String) As String
    On Error GoTo blad
    With Application.FileDialog(msoFileDialogSaveAs)
        .title = "Gdzie zapisać eksport VBA jako TXT?"
        .InitialFileName = suggestName
        .Filters.Clear
        .Filters.Add "Pliki tekstowe (*.txt)", "*.txt"
        If .Show Then PickSaveTxt = .SelectedItems(1)
    End With
    Exit Function
blad:
    PickSaveTxt = ""
End Function

Private Function PickFolder(ByVal title As String) As String
    On Error GoTo blad
    With Application.FileDialog(msoFileDialogFolderPicker)
        .title = title
        If .Show Then PickFolder = .SelectedItems(1)
    End With
    Exit Function
blad:
    PickFolder = ""
End Function


' ===== Zapis UTF-8 =====
Private Sub SaveTextUTF8(ByVal path As String, ByVal textData As String)
    Dim stm As Object: Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2           ' adTypeText
        .Charset = "utf-8"
        .Open
        .WriteText textData
        .SaveToFile path, 2 ' adSaveCreateOverWrite
        .Close
    End With
End Sub


' ===== Foldery/ścieżki =====
Private Sub EnsureFolderExists(ByVal folderPath As String)
    If Len(dir$(folderPath, vbDirectory)) = 0 Then
        MkDirRecursive folderPath
    End If
End Sub

Private Sub MkDirRecursive(ByVal folderPath As String)
    Dim fso As Object: Set fso = CreateObject("Scripting.FileSystemObject")
    If fso.FolderExists(folderPath) Then Exit Sub
    fso.CreateFolder folderPath
End Sub

Private Function GetHostFileBaseName() As String
    ' Excel: ThisWorkbook.Name, Word: ActiveDocument.Name
    On Error Resume Next

    Dim nm As String
    nm = ""
    nm = CallByName(ThisWorkbookOrDoc, "Name", VbGet)

    On Error GoTo 0
    If Len(nm) = 0 Then Exit Function

    Dim p As Long: p = InStrRev(nm, ".")
    If p > 1 Then
        GetHostFileBaseName = Left$(nm, p - 1)
    Else
        GetHostFileBaseName = nm
    End If
End Function

Private Function CleanFileName(ByVal s As String) As String
    ' usuwa znaki niedozwolone w nazwach plików Windows
    Dim bad As Variant, i As Long
    bad = Array("\", "/", ":", "*", "?", """", "<", ">", "|")
    CleanFileName = s
    For i = LBound(bad) To UBound(bad)
        CleanFileName = Replace(CleanFileName, bad(i), "_")
    Next i
    CleanFileName = Trim$(CleanFileName)
    If Len(CleanFileName) = 0 Then CleanFileName = "NONAME"
End Function

Private Function SafeStr(ByVal s As String) As String
    SafeStr = Replace(Replace(s, vbCr, " "), vbLf, " ")
End Function


' ===== Obsługa błędów dostępu do VBProject =====
Private Sub HandleVBAccessError(ByVal caption As String, ByVal e As ErrObject)
    If e.Number = 1004 Or e.Number = 70 Then
        MsgBox "Brak dostępu do projektu VBA." & vbCrLf & _
               "Włącz: Plik › Opcje › Centrum zaufania › Ustawienia… › Ustawienia makr ›" & vbCrLf & _
               "„Ufaj dostępowi do modelu obiektowego projektu VBA”.", vbExclamation, caption
    Else
        MsgBox caption & ":" & vbCrLf & e.Number & " - " & e.Description, vbCritical
    End If
End Sub





================================================================================
vba\modules\modMergeCsvEmail.vb
================================================================================

﻿' === Component: modMergeCsvEmail [Standard Module]
' === Exported: 2026-02-26 14:22:22

Option Explicit

' ============================
' CSV merge: id + dane osobowe
' email = klucz łączenia
' wynik: dane_do_raportu.csv w folderze pierwszego pliku
' ============================

Public Sub MergeCsv_ByEmail()
    On Error GoTo EH

    Dim csv1Path As String, csv2Path As String
    csv1Path = PickCsvFile("Wybierz PIERWSZY plik CSV (Pełna nazwa, E-mail, ...)")
    If Len(csv1Path) = 0 Then Exit Sub

    csv2Path = PickCsvFile("Wybierz DRUGI plik CSV (id,email)")
    If Len(csv2Path) = 0 Then Exit Sub

    Dim outPath As String
    outPath = ParentFolder(csv1Path) & "dane_do_raportu.csv"

    ' 1) wczytaj mapę email -> id z csv2
    Dim mapEmailToId As Object
    Set mapEmailToId = CreateObject("Scripting.Dictionary")
    mapEmailToId.CompareMode = 1 ' TextCompare

    Dim csv2Text As String
    csv2Text = ReadTextUtf8(csv2Path)

    Dim lines2 As Variant
    lines2 = SplitLines(csv2Text)
    If UBound(lines2) < 0 Then Err.Raise vbObjectError + 1, , "Drugi plik CSV jest pusty."

    Dim hdr2 As Variant
    Dim delim2 As String
    delim2 = DetectDelimiter(CStr(lines2(0)))
    hdr2 = ParseCsvLineEx(CStr(lines2(0)), delim2)

    Dim idx2_id As Long, idx2_email As Long
    idx2_id = FindHeaderIndex(hdr2, "id")
    idx2_email = FindHeaderIndex(hdr2, "email")

    If idx2_id < 0 Or idx2_email < 0 Then
        Err.Raise vbObjectError + 2, , "Drugi CSV musi mieć nagłówki: id,email"
    End If

    Dim i As Long
    For i = 1 To UBound(lines2)
        If Len(Trim$(CStr(lines2(i)))) = 0 Then GoTo Next2

        Dim row2 As Variant
        row2 = ParseCsvLineEx(CStr(lines2(i)), delim2)

        Dim em2 As String, id2 As String
        em2 = NormalizeEmail(GetFieldSafe(row2, idx2_email))
        id2 = Trim$(GetFieldSafe(row2, idx2_id))

        If Len(em2) > 0 Then
            ' jeśli duplikaty emaili -> ostatni wygrywa (możesz zmienić na pierwszy)
            mapEmailToId(em2) = id2
        End If
Next2:
    Next i

    ' 2) czytaj csv1 i zapisuj wynik z dodanym "id" na początku
    Dim csv1Text As String
    csv1Text = ReadTextUtf8(csv1Path)

    Dim lines1 As Variant
    lines1 = SplitLines(csv1Text)
    If UBound(lines1) < 0 Then Err.Raise vbObjectError + 3, , "Pierwszy plik CSV jest pusty."

    Dim hdr1 As Variant
    Dim delim1 As String
    delim1 = DetectDelimiter(CStr(lines1(0)))
    hdr1 = ParseCsvLineEx(CStr(lines1(0)), delim1)

    Dim idx1_email As Long
    ' w Twoim nagłówku jest "E-mail" (z myślnikiem)
    idx1_email = FindHeaderIndex(hdr1, "E-mail")
    If idx1_email < 0 Then idx1_email = FindHeaderIndex(hdr1, "Email")
    If idx1_email < 0 Then idx1_email = FindHeaderIndex(hdr1, "E-mail ") ' awaryjnie

    If idx1_email < 0 Then
        Err.Raise vbObjectError + 4, , "Pierwszy CSV musi mieć kolumnę nagłówka: E-mail"
    End If

    Dim sb As String
    sb = ""

    ' nagłówek wyjściowy: id + oryginalne nagłówki
    sb = sb & CsvJoinWithLeadingId("id", hdr1) & vbCrLf

    Dim notFound As Long, total As Long
    For i = 1 To UBound(lines1)
        Dim ln As String
        ln = CStr(lines1(i))
        If Len(Trim$(ln)) = 0 Then GoTo Next1

        total = total + 1

        Dim row1 As Variant
        row1 = ParseCsvLineEx(ln, delim1)

        Dim em1 As String
        em1 = NormalizeEmail(GetFieldSafe(row1, idx1_email))

        Dim idOut As String
        If Len(em1) > 0 And mapEmailToId.Exists(em1) Then
            idOut = CStr(mapEmailToId(em1))
        Else
            idOut = "" ' brak dopasowania -> puste id
            notFound = notFound + 1
        End If

        sb = sb & CsvJoinWithLeadingId(idOut, row1) & vbCrLf
Next1:
    Next i

    WriteTextUtf8 outPath, sb

    MsgBox "Zapisano: " & outPath & vbCrLf & _
           "Wiersze: " & total & vbCrLf & _
           "Brak dopasowania id: " & notFound, vbInformation
    Exit Sub

EH:
    MsgBox "Błąd: " & Err.Number & vbCrLf & Err.Description, vbCritical
End Sub

' ----------------------------
' UI: wybór pliku
' ----------------------------
Private Function PickCsvFile(ByVal title As String) As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(3) ' msoFileDialogFilePicker

    With fd
        .title = title
        .AllowMultiSelect = False
        .Filters.Clear
        .Filters.Add "CSV", "*.csv"
        .Filters.Add "Wszystkie pliki", "*.*"
        If .Show <> -1 Then Exit Function
        PickCsvFile = .SelectedItems(1)
    End With
    Exit Function
EH:
    PickCsvFile = ""
End Function

' ----------------------------
' UTF-8 read/write (ADODB.Stream)
' ----------------------------
Private Function ReadTextUtf8(ByVal path As String) As String
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2 ' adTypeText
        .Charset = "utf-8"
        .Open
        .LoadFromFile path
        ReadTextUtf8 = .ReadText(-1)
        .Close
    End With
End Function

Private Sub WriteTextUtf8(ByVal path As String, ByVal textData As String)
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    With stm
        .Type = 2 ' adTypeText
        .Charset = "utf-8"
        .Open
        .WriteText textData
        .SaveToFile path, 2 ' adSaveCreateOverWrite
        .Close
    End With
End Sub

' ----------------------------
' CSV parsing (quotes-aware)
' ----------------------------
Private Function ParseCsvLineEx(ByVal line As String, ByVal delim As String) As Variant
    Dim res() As String
    Dim i As Long, ch As String
    Dim cur As String
    Dim inQ As Boolean

    ReDim res(0 To 0)
    cur = ""
    inQ = False

    i = 1
    Do While i <= Len(line)
        ch = Mid$(line, i, 1)

        If inQ Then
            If ch = """" Then
                If i < Len(line) And Mid$(line, i + 1, 1) = """" Then
                    cur = cur & """"
                    i = i + 1
                Else
                    inQ = False
                End If
            Else
                cur = cur & ch
            End If
        Else
            If ch = delim Then
                AppendField res, cur
                cur = ""
            ElseIf ch = """" Then
                inQ = True
            Else
                cur = cur & ch
            End If
        End If

        i = i + 1
    Loop

    AppendField res, cur
    ParseCsvLineEx = res
End Function

Private Sub AppendField(ByRef arr() As String, ByVal v As String)
    Dim n As Long
    n = UBound(arr)
    If n = 0 And Len(arr(0)) = 0 Then
        arr(0) = v
    Else
        ReDim Preserve arr(0 To n + 1)
        arr(n + 1) = v
    End If
End Sub

Private Function CsvJoinWithLeadingId(ByVal idVal As String, ByVal row As Variant) As String
    Dim i As Long
    Dim s As String
    s = CsvEscape(idVal)

    For i = LBound(row) To UBound(row)
        s = s & "," & CsvEscape(CStr(row(i)))
    Next i
    CsvJoinWithLeadingId = s
End Function

Private Function CsvEscape(ByVal v As String) As String
    Dim mustQ As Boolean
    mustQ = (InStr(1, v, ",", vbBinaryCompare) > 0) Or _
            (InStr(1, v, """", vbBinaryCompare) > 0) Or _
            (InStr(1, v, vbCr, vbBinaryCompare) > 0) Or _
            (InStr(1, v, vbLf, vbBinaryCompare) > 0)

    If InStr(1, v, """", vbBinaryCompare) > 0 Then
        v = Replace$(v, """", """""")
    End If

    If mustQ Then
        CsvEscape = """" & v & """"
    Else
        CsvEscape = v
    End If
End Function

' ----------------------------
' Helpers
' ----------------------------
Private Function FindHeaderIndex(ByVal headers As Variant, ByVal headerName As String) As Long
    Dim i As Long
    FindHeaderIndex = -1
    For i = LBound(headers) To UBound(headers)
        If NormalizeHeader(CStr(headers(i))) = NormalizeHeader(headerName) Then
            FindHeaderIndex = i
            Exit Function
        End If
    Next i
End Function

Private Function NormalizeHeader(ByVal s As String) As String
    s = Trim$(s)
    s = Replace$(s, Chr$(160), " ")
    s = LCase$(s)
    NormalizeHeader = s
End Function

Private Function NormalizeEmail(ByVal s As String) As String
    s = Trim$(s)
    s = Replace$(s, Chr$(160), " ")
    s = LCase$(s)
    NormalizeEmail = s
End Function

Private Function GetFieldSafe(ByVal row As Variant, ByVal idx As Long) As String
    On Error GoTo EH
    If idx < LBound(row) Or idx > UBound(row) Then Exit Function
    GetFieldSafe = CStr(row(idx))
    Exit Function
EH:
    GetFieldSafe = ""
End Function

Private Function ParentFolder(ByVal fullPath As String) As String
    Dim p As Long
    p = InStrRev(fullPath, "\")
    If p > 0 Then
        ParentFolder = Left$(fullPath, p)
    Else
        ParentFolder = ""
    End If
End Function

Private Function SplitLines(ByVal s As String) As Variant
    ' normalizacja zakończeń linii
    s = Replace$(s, vbCrLf, vbLf)
    s = Replace$(s, vbCr, vbLf)
    If Len(s) = 0 Then
        SplitLines = Array()
    Else
        SplitLines = Split(s, vbLf)
    End If
End Function
Private Function DetectDelimiter(ByVal line As String) As String
    ' prosto: który znak częściej występuje w nagłówku
    Dim cComma As Long, cSemi As Long
    cComma = Len(line) - Len(Replace$(line, ",", ""))
    cSemi = Len(line) - Len(Replace$(line, ";", ""))
    If cSemi > cComma Then DetectDelimiter = ";" Else DetectDelimiter = ","
End Function

================================================================================
vba\modules\modNA_Convert.vb
================================================================================

﻿' === Component: modNA_Convert [Standard Module]
' === Exported: 2026-02-26 14:22:22

Option Explicit

Public Sub ConvertXlsxFolderToCsv(ByVal sourceFolder As String, ByVal rootPath As String)

    On Error GoTo EH

    sourceFolder = Trim$(Replace(sourceFolder, "/", "\"))
    If Right$(sourceFolder, 1) = "\" Then sourceFolder = Left$(sourceFolder, Len(sourceFolder) - 1)

    If Len(sourceFolder) = 0 Then
        MsgBox "Nie wskazano folderu.", vbExclamation
        Exit Sub
    End If

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    If Not fso.FolderExists(sourceFolder) Then
        MsgBox "Folder nie istnieje: " & sourceFolder, vbExclamation
        Exit Sub
    End If

    Dim targetFolder As String
    targetFolder = rootPath & "\_data\converted_csv"
    EnsureFolder targetFolder

    Application.ScreenUpdating = False
    Application.DisplayAlerts = False

    ProcessFolderRecursive sourceFolder, targetFolder

    Application.DisplayAlerts = True
    Application.ScreenUpdating = True

    MsgBox "Konwersja zakończona.", vbInformation
    Exit Sub

EH:
    Application.DisplayAlerts = True
    Application.ScreenUpdating = True
    MsgBox "Błąd konwersji: " & Err.Description, vbCritical
End Sub


Private Sub ProcessFolderRecursive(ByVal folderPath As String, ByVal targetFolder As String)

    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    Dim f As Object
    Dim subF As Object

    For Each f In fso.GetFolder(folderPath).files
        If LCase(fso.GetExtensionName(f.Name)) = "xlsx" Then
            ConvertOneFile f.path, targetFolder
        End If
    Next f

    For Each subF In fso.GetFolder(folderPath).SubFolders
        ProcessFolderRecursive subF.path, targetFolder
    Next subF

End Sub


Private Sub ConvertOneFile(ByVal fullPath As String, ByVal targetFolder As String)

    Dim wb As Workbook
    Dim csvPath As String

    Set wb = Workbooks.Open(fullPath, ReadOnly:=True)

    csvPath = targetFolder & "\" & _
              Replace(wb.Name, ".xlsx", ".csv")

    wb.SaveAs fileName:=csvPath, _
              FileFormat:=xlCSVUTF8

    wb.Close False

End Sub


Private Sub EnsureFolder(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(folderPath) Then
        fso.CreateFolder folderPath
    End If
End Sub


================================================================================
vba\modules\modNA_Launcher.vb
================================================================================

﻿' === Component: modNA_Launcher [Standard Module]
' === Exported: 2026-02-26 14:22:22

' === modNA_Launcher ===
Option Explicit

' ---------------------------
' Konfiguracja / stałe
' ---------------------------
Private Const PROGRESS_INTERVAL_SEC As Double = 1# / 86400#   ' 1 sek (Date = dni)
Private Const PROGRESS_FILE As String = "_run\progress.jsonl"
Private Const RUN_LOG As String = "_run\run.log"

Private Const OUT_INDY As String = "_out\indywidualne\"
Private Const OUT_PDF As String = "_out\pdf\"
Private Const RUN_DIR As String = "_run\"

' Uwaga: ustaw to na nazwę pliku exe jeśli dystrybuujesz PyInstaller
Private Const PIPE_EXE As String = "mrna-plum.exe"  ' albo np. "mrna_plum_cli.exe"

' ---------------------------
' Stan pipeline (globalny)
' ---------------------------
Private Type TStep
    Name As String
    Cmd As String
End Type

Private gSteps() As TStep
Private gStepIndex As Long
Private gStepStart As Date

Private gWsh As Object          ' WScript.Shell
Private gExec As Object         ' WshScriptExec
Private gNextOnTime As Date
Private gMonitoring As Boolean
Private gRoot As String

' ---------------------------
' PUBLIC: wymagane przez Ciebie
' ---------------------------
Public Function RunPython(ByVal cmdLine As String) As Long
    ' Blokujące oczekiwanie (UWAGA: zamrozi UI na czas działania procesu).
    ' Dobre do krótkich komend / testów, ale nie do długiego pipeline.
    Dim sh As Object
    Set sh = CreateObject("WScript.Shell")

    ' 0 = hidden window, True = wait
    ' cmdLine MUSI zawierać pełne cudzysłowy dla ścieżek ze spacjami.
    RunPython = sh.Run(cmdLine, 0, True)
End Function

' ---------------------------
' PUBLIC: uruchomienie całości z UserForm
' ---------------------------
Public Sub StartPipeline()
    On Error GoTo EH

    gRoot = ThisWorkbook.path
    EnsureFolders
    If dir$(gRoot & "\" & PIPE_EXE) = vbNullString Then
        Err.Raise vbObjectError + 701, "StartPipeline", "Nie znaleziono pliku EXE: " & gRoot & "\" & PIPE_EXE
    End If

    If dir$(gRoot & "\config.yaml") = vbNullString Then
        Err.Raise vbObjectError + 702, "StartPipeline", "Nie znaleziono pliku config.yaml: " & gRoot & "\config.yaml"
    End If
    InitSteps

    ' wyczyść artefakty run
    SafeKillFile gRoot & "\" & RUN_LOG
    SafeKillFile gRoot & "\" & gRootRel(PROGRESS_FILE)
    ClearOkFlags

    AppendLog "=== START PIPELINE: " & Format(Now, "yyyy-mm-dd hh:nn:ss") & " ==="

    Set gWsh = CreateObject("WScript.Shell")
    gWsh.CurrentDirectory = gRoot
    gStepIndex = 0

    ' UI: zablokuj przyciski / ustaw status startowy
    UI_SetRunning True
    UI_SetStatus "Start pipeline..."

    StartNextStep
    Exit Sub

EH:
    PipelineFail "StartPipeline error: " & Err.Number & " - " & Err.Description
End Sub

' ---------------------------
' Pipeline core (asynchroniczny, bez freeze UI)
' ---------------------------
Private Sub InitSteps()
    ReDim gSteps(0 To 5) As TStep

    gSteps(0).Name = "merge-logs"
    gSteps(0).Cmd = StepCmd("merge-logs")

    gSteps(1).Name = "parse-events"
    gSteps(1).Cmd = StepCmd("parse-events")

    gSteps(2).Name = "build-activities-state"
    gSteps(2).Cmd = StepCmd("build-activities-state")

    gSteps(3).Name = "compute-stats"
    gSteps(3).Cmd = StepCmd("compute-stats")

    gSteps(4).Name = "export-excel"
    gSteps(4).Cmd = StepCmd("export-excel")

    gSteps(5).Name = "export-individual"
    gSteps(5).Cmd = StepCmd("export-individual")
End Sub

Private Function StepCmd(ByVal stepName As String) As String
    Dim exePath As String, cfgPath As String, logPath As String
    exePath = Quote(gRoot & "\" & PIPE_EXE)
    cfgPath = Quote(gRoot & "\config.yaml")
    logPath = Quote(gRoot & "\" & RUN_LOG)

    Dim inputsDir As String
    inputsDir = UF_Text(raporty_plum, "txtInputsDir")

    Dim extraArgs As String
    extraArgs = ""

    ' parse-events: KEYS override z UI
    If LCase$(stepName) = "parse-events" Then
        Dim keysXlsx As String
        keysXlsx = UF_Text(raporty_plum, "txtKeysXlsx")
        If Len(keysXlsx) > 0 Then
            extraArgs = extraArgs & " --keys-xlsx " & Quote(keysXlsx)
        End If
    End If

    ' build-activities-state: snapshot-file z UI (KRYTYCZNE) + fallback inputs-dir
    If LCase$(stepName) = "build-activities-state" Then
        Dim snapPath As String
        snapPath = UF_Text(raporty_plum, "txtSnapshotFile")

        If Len(snapPath) > 0 Then
            extraArgs = extraArgs & " --snapshot-file " & Quote(snapPath)
        ElseIf Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        Else
            Err.Raise vbObjectError + 513, "StepCmd", _
                "Brak danych wejściowych dla build-activities-state." & vbCrLf & _
                "Uzupełnij txtSnapshotFile lub txtInputsDir."
        End If
    End If

    ' export-excel / export-individual: inputs-dir
    If LCase$(stepName) = "export-excel" Or LCase$(stepName) = "export-individual" Then
        If Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        End If
    End If
    
    ' >>> DODAJ TEN BLOK W StepCmd (obok innych per-step bloków) <<<
    If LCase$(stepName) = "merge-logs" Then
        If Len(inputsDir) > 0 Then
            extraArgs = extraArgs & " --inputs-dir " & Quote(inputsDir)
        End If
    End If
    
    ' export-individual: out-dir
    If LCase$(stepName) = "export-individual" Then
        Dim outDir As String
        outDir = gRoot & "\" & OUT_INDY
        If Right$(outDir, 1) = "\" Then outDir = Left$(outDir, Len(outDir) - 1)
        extraArgs = extraArgs & " --out-dir " & Quote(outDir)
    End If

    Dim inner As String
    inner = "chcp 65001>nul" & _
            " & cd /d " & Quote(gRoot) & _
            " & " & exePath & " " & stepName & _
            " --root " & Quote(gRoot) & _
            " --config " & cfgPath & _
            extraArgs & _
            " >> " & logPath & " 2>&1"

    ' UWAGA: dokładnie JEDNA para cudzysłowów po /c
    StepCmd = "cmd.exe /c " & Quote(inner)
End Function

Private Sub StartNextStep()
    On Error GoTo EH

    If gStepIndex > UBound(gSteps) Then
        ' Python zakończony -> integracja PDF
        AppendLog "=== PYTHON PIPELINE OK ==="
        UI_SetStatus "Python OK. Sprawdzam pliki indywidualne..."

        If Not HasAnyFiles(gRoot & "\" & OUT_INDY, "*.xlsx") Then
            PipelineFail "Brak plików w " & OUT_INDY & " — nie generuję PDF."
            Exit Sub
        End If

        UI_SetStatus "Generuję PDF (VBA)..."
        AppendLog "=== START PDF ENGINE ==="

                ' === PDF ENGINE (BATCH, bez klikania) ===
        Dim cfg As Object
        Set cfg = CreateObject("Scripting.Dictionary")

        Dim templatePath As String
        On Error Resume Next
        templatePath = Trim$(raporty_plum.txtTemplateXlsx.text)
        On Error GoTo EH

        If Len(templatePath) = 0 Then
            PipelineFail "Brak ścieżki do wzoru raportu. Uzupełnij raporty_plum.txtTemplateXlsx."
            Exit Sub
        End If
        If dir$(templatePath) = vbNullString Then
            PipelineFail "Nie znaleziono wzoru raportu: " & templatePath
            Exit Sub
        End If

        cfg("root") = gRoot
        cfg("in_indywidualne") = gRoot & "\" & OUT_INDY
        cfg("out_pdf") = gRoot & "\" & OUT_PDF
        cfg("run_dir") = gRoot & "\" & RUN_DIR
        cfg("template_path") = templatePath

        ' Nazwy arkuszy zgodne z silnikiem i Twoimi stałymi w modNA_PdfEngine:
        cfg("sheet_dane_pers") = "DANE_PERS"
        cfg("sheet_dane_kursy") = "DANE_KURSY"
        cfg("sheet_report") = "Raport_NA"

        cfg("max_blocks") = 16
        cfg("truncate_overflow") = True

        AppendLog "=== START PDF ENGINE (BATCH) ==="
        Call modPdfEngine.PdfEngine_RunBatch(cfg)
        AppendLog "=== PDF ENGINE OK ==="
        UI_SetStatus "Zakończono poprawnie."
        UI_SetRunning False
        StopMonitor
        Exit Sub
    End If

    Dim stepName As String
    stepName = gSteps(gStepIndex).Name

    UI_SetStatus "Krok " & (gStepIndex + 1) & "/" & (UBound(gSteps) + 1) & ": " & stepName
    AppendLog "--- STEP START: " & stepName & " @ " & Format(Now, "yyyy-mm-dd hh:nn:ss")
    AppendLog "CMD: " & gSteps(gStepIndex).Cmd
    gStepStart = Now

    ' Exec -> nie blokuje UI; monitorujemy Status w OnTime
    Set gExec = gWsh.Exec(gSteps(gStepIndex).Cmd)

    StartMonitor
    Exit Sub

EH:
    PipelineFail "StartNextStep error: " & Err.Number & " - " & Err.Description
End Sub

' ---------------------------
' Monitor progress.jsonl + status procesu
' ---------------------------
Private Sub StartMonitor()
    gMonitoring = True
    ScheduleMonitor Now + PROGRESS_INTERVAL_SEC
End Sub

Private Sub ScheduleMonitor(ByVal whenTime As Date)
    On Error Resume Next
    gNextOnTime = whenTime
    Application.OnTime earliesttime:=gNextOnTime, procedure:="modNA_Launcher.MonitorProgress", schedule:=True
    On Error GoTo 0
End Sub

Public Sub MonitorProgress()
    On Error GoTo EH

    If Not gMonitoring Then Exit Sub

    ' 1) update UI z ostatniej linii progress.jsonl
    UpdateUIFromProgress

    ' 2) sprawdzamy proces
    If Not gExec Is Nothing Then
        ' Status: 0=Running, 1=Finished
        If CLng(gExec.Status) = 1 Then
            Dim exitCode As Long
            exitCode = CLng(gExec.exitCode)

            Dim stepName As String
            stepName = gSteps(gStepIndex).Name

            AppendLog "--- STEP END: " & stepName & _
                      " exit=" & exitCode & _
                      " dur=" & FormatDuration(Now - gStepStart) & _
                      " @ " & Format(Now, "yyyy-mm-dd hh:nn:ss")

            If exitCode <> 0 Then
                Dim tail As String
                tail = ReadLastLines(gRoot & "\" & RUN_LOG, 10)
                PipelineFail "Krok '" & stepName & "' zakończony błędem exit=" & exitCode & vbCrLf & vbCrLf & _
                             "Ostatnie linie logu:" & vbCrLf & tail
                Exit Sub
            End If

            ' zapis <step>.ok
            WriteTextFile gRoot & "\" & RUN_DIR & stepName & ".ok", _
                "ok " & Format(Now, "yyyy-mm-dd hh:nn:ss") & " dur=" & FormatDuration(Now - gStepStart)

            ' kolejny krok
            Set gExec = Nothing
            gStepIndex = gStepIndex + 1
            StartNextStep
            Exit Sub
        End If
    End If

    ' jeśli nadal działa -> planuj kolejny tick
    ScheduleMonitor Now + PROGRESS_INTERVAL_SEC
    Exit Sub

EH:
    PipelineFail "MonitorProgress error: " & Err.Number & " - " & Err.Description
End Sub

Private Sub StopMonitor()
    On Error Resume Next
    gMonitoring = False
    If gNextOnTime <> 0 Then
        Application.OnTime earliesttime:=gNextOnTime, procedure:="modNA_Launcher.MonitorProgress", schedule:=False
    End If
    On Error GoTo 0
End Sub

' ---------------------------
' UI helpers (podłącz do UserForm)
' ---------------------------
Private Sub UI_SetRunning(ByVal running As Boolean)
    On Error Resume Next
    With raporty_plum
        .btnStart.enabled = Not running
    End With
    On Error GoTo 0
End Sub

Private Sub UI_SetStatus(ByVal msg As String)
    On Error Resume Next
    raporty_plum.LabelStatus.caption = msg
    On Error GoTo 0
End Sub

Private Sub UI_SetProgress(ByVal pct As Double, ByVal msg As String)
    On Error Resume Next
    With raporty_plum
        .LabelStatus.caption = msg
        ' ProgressBar jako Label w Frame: LabelBar.Width = Frame.Width * pct
        If pct < 0 Then pct = 0
        If pct > 1 Then pct = 1
        .LabelBar.Width = .FrameBar.Width * pct
        .LabelPct.caption = Format(pct, "0%")
    End With
    On Error GoTo 0
End Sub

' ---------------------------
' Progress.jsonl parsing
' Zakładamy, że python dopisuje linie np:
' {"step":"parse-events","pct":0.34,"msg":"Parsing..."}
' ---------------------------
Private Sub UpdateUIFromProgress()
    Dim p As String
    p = gRoot & "\" & gRootRel(PROGRESS_FILE)
    If dir(p) = vbNullString Then Exit Sub

    Dim line As String
    line = ReadLastNonEmptyLine(p)
    If Len(line) = 0 Then Exit Sub

    Dim stepName As String, msg As String
    Dim pct As Double

    stepName = JsonGetString(line, "step")

    msg = JsonGetString(line, "message")
    If Len(msg) = 0 Then msg = JsonGetString(line, "msg")

    pct = JsonGetNumber(line, "pct")

    Dim cur As Double, tot As Double
    cur = JsonGetNumber(line, "current")
    tot = JsonGetNumber(line, "total")

' pct fallback z current/total tylko jeśli pct nieobecne (u Ciebie JsonGetNumber zwykle zwraca 0)
' więc rozróżniamy: jeśli tot>0 i cur>=0 i pct=0, to i tak policz (bo to poprawne 0..1)
    If tot > 0 Then
        If pct = 0# Then
            pct = cur / tot
        End If
    End If

    If Len(msg) = 0 Then msg = stepName

' Fallback na "percent" (0..100) tylko jeśli nadal nie mamy sensownego pct i percent > 0
    If pct = 0# Then
        Dim pct100 As Double
        pct100 = JsonGetNumber(line, "percent")
        If pct100 > 1# Then
            pct = pct100 / 100#
        ElseIf pct100 > 0# Then
            pct = pct100
        End If
    End If

' clamp 0..1
    If pct < 0# Then pct = 0#
    If pct > 1# Then pct = 1#

    ' UI
    UI_SetProgress pct, msg
End Sub

Private Function JsonGetString(ByVal jsonLine As String, ByVal key As String) As String
    ' minimalistycznie: szukamy "key":"value"
    Dim pat As String, p As Long, q1 As Long, q2 As Long
    pat = """" & key & """:"
    p = InStr(1, jsonLine, pat, vbTextCompare)
    If p = 0 Then Exit Function

    q1 = InStr(p + Len(pat), jsonLine, """")
    If q1 = 0 Then Exit Function
    q2 = InStr(q1 + 1, jsonLine, """")
    If q2 = 0 Then Exit Function

    JsonGetString = Mid$(jsonLine, q1 + 1, q2 - q1 - 1)
End Function

Private Function JsonGetNumber(ByVal jsonLine As String, ByVal key As String) As Double
    Dim pat As String, p As Long, i As Long, ch As String, buf As String
    pat = """" & key & """:"
    p = InStr(1, jsonLine, pat, vbTextCompare)
    If p = 0 Then Exit Function

    i = p + Len(pat)
    ' pomiń spacje
    Do While i <= Len(jsonLine) And Mid$(jsonLine, i, 1) = " "
        i = i + 1
    Loop

    Do While i <= Len(jsonLine)
        ch = Mid$(jsonLine, i, 1)
        If (ch Like "[0-9]") Or ch = "." Or ch = "-" Then
            buf = buf & ch
            i = i + 1
        Else
            Exit Do
        End If
    Loop

    If Len(buf) = 0 Then Exit Function
    JsonGetNumber = CDbl(Replace(buf, ",", "."))
End Function

' ---------------------------
' Logging / pliki / utilsy
' ---------------------------
Private Sub PipelineFail(ByVal message As String)
    AppendLog "!!! PIPELINE FAIL: " & message
    StopMonitor
    UI_SetRunning False
    UI_SetStatus "BŁĄD: zobacz run.log"

    MsgBox message, vbCritical, "mRNA-PLUM Pipeline"
End Sub

Private Sub AppendLog(ByVal s As String)
    WriteTextFile gRoot & "\" & RUN_LOG, s & vbCrLf, True
End Sub

Private Sub WriteTextFile(ByVal fullPath As String, ByVal text As String, Optional ByVal append As Boolean = False)
    Dim fso As Object, ts As Object
    Set fso = CreateObject("Scripting.FileSystemObject")

    EnsureFolderExists fso.GetParentFolderName(fullPath)

    If append And fso.FileExists(fullPath) Then
        Set ts = fso.OpenTextFile(fullPath, 8, True, -1) ' ForAppending, Unicode
    Else
        Set ts = fso.OpenTextFile(fullPath, 2, True, -1) ' ForWriting, Unicode
    End If

    ts.Write text
    ts.Close
End Sub

Private Function ReadLastLines(ByVal fullPath As String, ByVal n As Long) As String
    ' prosto i bezpiecznie: czytamy cały plik tylko dla tail (run.log zwykle nie jest ogromny)
    On Error GoTo EH

    Dim fso As Object, ts As Object, allText As String, arr() As String
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FileExists(fullPath) Then Exit Function

    Set ts = fso.OpenTextFile(fullPath, 1, False, -1) ' ForReading, Unicode
    allText = ts.ReadAll
    ts.Close

    arr = Split(Replace(allText, vbCrLf, vbLf), vbLf)

    Dim i As Long, startI As Long, buf As String
    startI = UBound(arr) - n + 1
    If startI < 0 Then startI = 0

    For i = startI To UBound(arr)
        If Len(arr(i)) > 0 Then buf = buf & arr(i) & vbCrLf
    Next

    ReadLastLines = buf
    Exit Function

EH:
    ReadLastLines = "(nie udało się odczytać tail logu: " & Err.Description & ")"
End Function

Private Function ReadLastNonEmptyLine(ByVal fullPath As String) As String
    On Error GoTo EH

    Dim fso As Object, ts As Object, allText As String, arr() As String
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FileExists(fullPath) Then Exit Function

    Set ts = fso.OpenTextFile(fullPath, 1, False, -1)
    allText = ts.ReadAll
    ts.Close

    arr = Split(Replace(allText, vbCrLf, vbLf), vbLf)

    Dim i As Long
    For i = UBound(arr) To 0 Step -1
        If Len(Trim$(arr(i))) > 0 Then
            ReadLastNonEmptyLine = Trim$(arr(i))
            Exit Function
        End If
    Next i
    Exit Function

EH:
    ' ignoruj
End Function

Private Function HasAnyFiles(ByVal folderPath As String, ByVal pattern As String) As Boolean
    Dim p As String
    p = folderPath
    If Right$(p, 1) <> "\" Then p = p & "\"
    HasAnyFiles = (dir(p & pattern) <> vbNullString)
End Function

Private Sub EnsureFolders()
    EnsureFolderExists gRoot & "\" & RUN_DIR
    EnsureFolderExists gRoot & "\" & OUT_INDY
    EnsureFolderExists gRoot & "\" & OUT_PDF
End Sub

Private Sub EnsureFolderExists(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Len(folderPath) = 0 Then Exit Sub
    If Not fso.FolderExists(folderPath) Then fso.CreateFolder folderPath
End Sub

Private Sub SafeKillFile(ByVal fullPath As String)
    On Error Resume Next
    If Len(dir(fullPath)) > 0 Then Kill fullPath
    On Error GoTo 0
End Sub

Private Sub ClearOkFlags()
    On Error Resume Next
    Dim f As String
    f = dir(gRoot & "\" & RUN_DIR & "*.ok")
    Do While Len(f) > 0
        Kill gRoot & "\" & RUN_DIR & f
        f = dir()
    Loop
    On Error GoTo 0
End Sub

Private Function FormatDuration(ByVal dtDays As Double) As String
    Dim totalSec As Long
    totalSec = CLng(dtDays * 86400#)
    FormatDuration = (totalSec \ 60) & "m " & (totalSec Mod 60) & "s"
End Function

Private Function Quote(ByVal s As String) As String
    Quote = """" & s & """"
End Function

Private Function gRootRel(ByVal rel As String) As String
    gRootRel = rel
    If Left$(gRootRel, 1) = "\" Then gRootRel = Mid$(gRootRel, 2)
End Function
Private Function UF_Text(ByVal formObj As Object, ByVal ctrlName As String) As String
    ' Bezpiecznie pobiera .Text z kontrolki UserForm po nazwie.
    ' Zwraca "" jeśli kontrolka nie istnieje.
    On Error GoTo EH
    Dim ctl As Object
    Set ctl = CallByName(formObj, ctrlName, VbGet)
    UF_Text = Trim$(CStr(CallByName(ctl, "Text", VbGet)))
    Exit Function
EH:
    UF_Text = ""
End Function

================================================================================
vba\modules\modNA_PdfEngine.vb
================================================================================

﻿' === Component: modNA_PdfEngine [Standard Module]
' === Exported: 2026-02-26 14:22:22

Option Explicit

' =========================
' KONFIG
' =========================
Private Const SHEET_KURSY As String = "DANE_KURSY"
Private Const SHEET_PERS  As String = "DANE_PERS"

Private Const REPORT_SHEET As String = "Raport_NA" ' <-- potwierdziłeś

Private Const MAX_BLOCKS As Long = 16

' PDF / wydruk
Private Const MARGIN_CM As Double = 1.5
Private Const PERCENT_FORMAT As String = "0,0%"

Private mLogFile As Integer
Private mLogPath As String

' =========================
' START
' =========================
Public Sub RaportyNAPDF()
    On Error GoTo EH
    Application.ScreenUpdating = False
    Application.EnableEvents = False
    Application.Calculation = xlCalculationManual

    Dim wzorPath As String, srcFolder As String, outFolder As String

    wzorPath = PickReportTemplate()
    If Len(wzorPath) = 0 Then GoTo CleanUp

    srcFolder = PickSourceFolder()
    If Len(srcFolder) = 0 Then GoTo CleanUp
    If Right$(srcFolder, 1) <> "\" Then srcFolder = srcFolder & "\"

    outFolder = srcFolder & "raporty_NA_pdf\"
    EnsureFolder outFolder

    Dim f As String
    f = dir$(srcFolder & "*.xlsx")

    If Len(f) = 0 Then
        MsgBox "Brak plików .xlsx w folderze.", vbExclamation
        GoTo CleanUp
    End If

    Do While Len(f) > 0
        ProcessOneSourceFile srcFolder & f, wzorPath, outFolder
        f = dir$
    Loop

    MsgBox "Zakończone. PDF-y zapisane w: " & outFolder, vbInformation

CleanUp:
    Application.ScreenUpdating = True
    Application.EnableEvents = True
    Application.Calculation = xlCalculationAutomatic
    Exit Sub

EH:
    MsgBox "Błąd: " & Err.Number & " - " & Err.Description, vbCritical
    Resume CleanUp
End Sub

' =========================
' 1 PLIK -> 1 PDF
' =========================
Private Sub ProcessOneSourceFile(ByVal srcPath As String, ByVal wzorPath As String, ByVal outFolder As String)
    On Error GoTo EH

    Dim wbSrc As Workbook, wbTpl As Workbook, wbOut As Workbook
    Dim wsK As Worksheet, wsP As Worksheet, wsOut As Worksheet

    Dim runFolder As String, logPath As String
    runFolder = ParentFolderWithBackslash(outFolder) & "_run\"
    EnsureFolder runFolder

    logPath = runFolder & "pdf_" & Format$(Now, "yyyymmdd_hhnnss") & "_" & SanitizeFileName(Replace$(dir$(srcPath), ".xlsx", "")) & ".log"
    LogOpen logPath
    LogLine "START src=" & srcPath

    ' --- open source (read-only) ---
    Set wbSrc = Workbooks.Open(srcPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)
    Set wsK = GetWsOrNothing(wbSrc, SHEET_KURSY)
    Set wsP = GetWsOrNothing(wbSrc, SHEET_PERS)

    If wsK Is Nothing Then
        LogLine "ERROR: missing sheet: " & SHEET_KURSY
        GoTo CloseAndExit
    End If

    ' --- open template (read-only) and SaveCopyAs ---
    Set wbTpl = Workbooks.Open(wzorPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Dim tmpPath As String
    tmpPath = outFolder & "~tmp_" & Format$(Now, "yyyymmdd_hhnnss") & "_" & SanitizeFileName(Replace$(wbSrc.Name, ".xlsx", "")) & ".xlsx"

    Application.DisplayAlerts = False
    wbTpl.SaveCopyAs tmpPath
    Application.DisplayAlerts = True

    wbTpl.Close SaveChanges:=False
    Set wbTpl = Nothing

    ' --- open working copy (writable) ---
    Set wbOut = Workbooks.Open(tmpPath, ReadOnly:=False, UpdateLinks:=0, AddToMru:=False)
    Set wsOut = GetWsOrNothing(wbOut, REPORT_SHEET)
    If wsOut Is Nothing Then
        LogLine "ERROR: missing report sheet: " & REPORT_SHEET
        GoTo CloseAndExit
    End If

    ' 1) DANE_PERS -> NamedRanges
    If Not wsP Is Nothing Then
        FillNamedRangesFromDanePers wbOut, wsP
    Else
        LogLine "WARN: missing sheet: " & SHEET_PERS
    End If

    ' 2) Kursy -> 16 bloków
    FillAllCourseBlocks wbOut, wsOut, wsK, MAX_BLOCKS

    ' 3) Layout + Print settings
    ApplyLayout wsOut

    ' 4) PDF name (prefer NamedRanges, fallback to source filename)
    Dim nauczyciel As String, bazusID As String, base As String
    nauczyciel = CStr(GetNameValueOrEmpty(wbOut, "nr_meta_Nauczyciel"))
    bazusID = CStr(GetNameValueOrEmpty(wbOut, "nr_meta_BazusID"))

    base = Replace$(wbSrc.Name, ".xlsx", "")
    If Len(Trim$(nauczyciel)) > 0 Then base = Trim$(nauczyciel)
    If Len(Trim$(bazusID)) > 0 Then base = base & "_" & Trim$(bazusID)

    base = SanitizeFileName(base)
    If Len(base) > 180 Then base = Left$(base, 180)

    Dim outPdfPath As String
    outPdfPath = outFolder & base & ".pdf"
    LogLine "Export PDF -> " & outPdfPath

    wsOut.ExportAsFixedFormat Type:=xlTypePDF, _
                              fileName:=outPdfPath, _
                              Quality:=xlQualityStandard, _
                              IncludeDocProperties:=True, _
                              IgnorePrintAreas:=False, _
                              OpenAfterPublish:=False

    LogLine "OK"

CloseAndExit:
    On Error Resume Next
    If Not wbOut Is Nothing Then wbOut.Close SaveChanges:=False
    If Len(tmpPath) > 0 Then Kill tmpPath
    If Not wbTpl Is Nothing Then wbTpl.Close SaveChanges:=False
    If Not wbSrc Is Nothing Then wbSrc.Close SaveChanges:=False
    LogClose
    On Error GoTo 0
    Exit Sub

EH:
    LogLine "FAIL Err=" & Err.Number & " | " & Err.Description
    Resume CloseAndExit
End Sub

' =========================
' BLOKI KURSÓW
' =========================
Private Sub FillAllCourseBlocks(ByVal wbOut As Workbook, ByVal wsOut As Worksheet, ByVal wsK As Worksheet, ByVal maxBlocks As Long)
    On Error GoTo EH

    Dim courses As Collection
    Set courses = LoadDistinctCourses(wsK) ' kolekcja stringów (display name)

    Dim nAll As Long: nAll = courses.Count
    Dim nUse As Long: nUse = nAll
    If nUse > maxBlocks Then
        LogLine "WARN: overflow courses " & nUse & " -> truncate to " & maxBlocks
        nUse = maxBlocks
    End If

    ' słownik metryk: key = courseKey|activityKey -> Array(count, pct)
    Dim metrics As Object
    Set metrics = LoadCourseMetrics(wsK)

    Dim b As Long
    For b = 1 To maxBlocks
        If b <= nUse Then
            Dim courseName As String
            courseName = CStr(courses(b))

            FillOneCourseBlock wbOut, wsOut, b, courseName, metrics
        Else
            ClearOneCourseBlock wbOut, wsOut, b
        End If
    Next b

    ' pagebreaks: #2,#5,#8,#11,#14 (wg PROMPT 9)
    SetupPageBreaks_ByTopAnchors wbOut, wsOut, maxBlocks

    ' print area: do końca bloku nUse
    SetPrintAreaToLastUsedBlock_ByTopAnchors wbOut, wsOut, nUse, maxBlocks

    Exit Sub

EH:
    Err.Raise Err.Number, "FillAllCourseBlocks", Err.Description
End Sub

Private Sub FillOneCourseBlock(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long, ByVal courseName As String, ByVal metrics As Object)
    On Error GoTo EH

    Dim sNo As String: sNo = Format$(blockNo, "00")

    ' --- nagłówek bloku przez NamedRanges ---
    SafeSetNameValue wb, "nr_blk_" & sNo & "_top", blockNo
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseName", courseName

    ' ID / liczby: jeśli masz je w DANE_KURSY (np. specjalne wiersze),
    ' to najprościej dostarczyć je jako NamedRanges w DANE_PERS.
    ' Ale jeżeli masz w DANE_KURSY kolumny dla ID/studentów/nauczycieli,
    ' dopisz tu mapowanie. Na razie zostawiamy puste (albo "-").
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseID", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Studenci", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Nauczyciele", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Aktywni", ""

    ' --- zakres bloku: bierzemy od nr_blk_XX_top do tuż przed kolejnym top (albo wysokość jak blok 1) ---
    Dim rngBlock As Range
    Set rngBlock = GetBlockRangeByTopAnchors(wb, ws, blockNo, MAX_BLOCKS)

    ' --- aktywności: wypełnij po etykietach w obrębie bloku (działa dla układu lewa/prawa tabela) ---
    FillActivitiesInsideBlock rngBlock, courseName, metrics

    Exit Sub

EH:
    Err.Raise Err.Number, "FillOneCourseBlock", Err.Description
End Sub

Private Sub ClearOneCourseBlock(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long)
    Dim sNo As String: sNo = Format$(blockNo, "00")

    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseName", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_CourseID", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Studenci", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Nauczyciele", ""
    SafeSetNameValue wb, "nr_blk_" & sNo & "_Aktywni", ""

    ' wyczyść wartości liczbowe/procenty w tabelach aktywności w obrębie bloku
    On Error Resume Next
    Dim rngBlock As Range
    Set rngBlock = GetBlockRangeByTopAnchors(wb, ws, blockNo, MAX_BLOCKS)
    On Error GoTo 0
    If rngBlock Is Nothing Then Exit Sub

    ClearActivityValuesInsideBlock rngBlock
End Sub

' -------------------------
' Aktywności w bloku: znajdź etykiety i wpisz wartości do komórek obok
' -------------------------
Private Sub FillActivitiesInsideBlock(ByVal rngBlock As Range, ByVal courseName As String, ByVal metrics As Object)
    ' Założenie: w wierszu aktywności jest komórka z etykietą (np. "Rozdziały w książce"),
    ' a po prawej w tym samym wierszu są kolumny: Ilość, % w skali kursu.
    ' Działa także gdy blok ma DWIE tabele (lewa i prawa), bo etykiety są w obu miejscach.

    Dim activities As Variant
    activities = Array( _
        "Rozdziały w książce", "Strony lekcji", "Strona", "Tekst i media", _
        "Wpisy do bazy danych", "Pojęcia w słowniku", "Adres URL", _
        "Pliki i foldery", "H5P", "Wpisy w Wiki", _
        "Utworzone pytania", "Ocenione zadań", "Ocenione zadan", "Ocenione zadania", _
        "Spotkania MS Teams", "Opinia zwrotna", "Głosowanie", _
        "Wiadomości na czacie", "Wpisy na forum" _
    )

    Dim i As Long
    For i = LBound(activities) To UBound(activities)
        Dim actLabel As String: actLabel = CStr(activities(i))

        Dim c As Range
        For Each c In rngBlock.Cells
            If NormalizeFuzzy(CStr(c.value)) = NormalizeFuzzy(actLabel) Then
                ' komórka etykiety może być scalona
                Dim labArea As Range: Set labArea = MergeAreaOrSelf(c)
                Dim rowNum As Long: rowNum = labArea.row

                ' znajdź w tym wierszu “Ilość” i “% w skali kursu” w ramach tej tabeli
                ' heurystyka: bierzemy pierwsze dwie NIEPuste komórki na prawo od etykiety,
                ' które nie są tekstem-nagłówkiem.
                Dim tgtCount As Range, tgtPct As Range
                Set tgtCount = FindNextValueCellRight(labArea)
                If Not tgtCount Is Nothing Then Set tgtPct = FindNextValueCellRight(tgtCount.MergeArea)

                Dim key As String
                key = NormalizeFuzzy(courseName) & "|" & NormalizeFuzzy(actLabel)

                If metrics.Exists(key) Then
                    Dim arr As Variant: arr = metrics(key)
                    PutValueOrDash tgtCount, arr(0), False
                    PutValueOrDash tgtPct, arr(1), True
                Else
                    PutValueOrDash tgtCount, Empty, False
                    PutValueOrDash tgtPct, Empty, True
                End If
            End If
        Next c
    Next i
End Sub

Private Sub ClearActivityValuesInsideBlock(ByVal rngBlock As Range)
    ' Czyścimy tylko komórki, które wyglądają jak pola Ilość/% (czyli nie teksty).
    Dim c As Range
    For Each c In rngBlock.Cells
        If c.MergeCells Then
            If c.Address <> c.MergeArea.Cells(1, 1).Address Then GoTo NextC
        End If

        Dim t As String: t = Trim$(CStr(c.value))
        If Len(t) = 0 Then GoTo NextC

        ' jeśli to tekst etykiety lub nagłówek - pomijamy
        If Not IsNumericLike(t) And InStr(1, t, "%", vbTextCompare) = 0 Then GoTo NextC

        c.MergeArea.ClearContents
NextC:
    Next c
End Sub

' =========================
' DANE: kursy i metryki
' =========================
Private Function LoadDistinctCourses(ByVal wsK As Worksheet) As Collection
    Dim col As New Collection
    Dim dict As Object: Set dict = CreateObject("Scripting.Dictionary")
    dict.CompareMode = vbTextCompare

    Dim lastR As Long: lastR = LastRow(wsK)
    Dim r As Long
    For r = 2 To lastR
        Dim courseName As String
        courseName = Trim$(CStr(wsK.Cells(r, 1).value))
        If Len(courseName) > 0 Then
            Dim key As String: key = NormalizeFuzzy(courseName)
            If Not dict.Exists(key) Then
                dict.Add key, True
                col.Add courseName
            End If
        End If
    Next r

    Set LoadDistinctCourses = col
End Function

Private Function LoadCourseMetrics(ByVal wsK As Worksheet) As Object
    Dim dict As Object: Set dict = CreateObject("Scripting.Dictionary")
    dict.CompareMode = vbTextCompare

    Dim lastR As Long: lastR = LastRow(wsK)
    Dim r As Long
    For r = 2 To lastR
        Dim courseName As String, actLabel As String
        courseName = Trim$(CStr(wsK.Cells(r, 1).value))
        actLabel = Trim$(CStr(wsK.Cells(r, 2).value))
        If Len(courseName) = 0 Or Len(actLabel) = 0 Then GoTo NextR

        Dim cnt As Variant, pct As Variant
        cnt = wsK.Cells(r, 3).value
        pct = wsK.Cells(r, 4).value

        Dim key As String
        key = NormalizeFuzzy(courseName) & "|" & NormalizeFuzzy(actLabel)

        dict(key) = Array(cnt, pct)
NextR:
    Next r

    Set LoadCourseMetrics = dict
End Function

' =========================
' PageBreaks + PrintArea oparte o nr_blk_XX_top
' =========================
Private Sub SetupPageBreaks_ByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal maxBlocks As Long)
    On Error Resume Next
    ws.ResetAllPageBreaks
    On Error GoTo 0

    Dim breaks As Variant
    breaks = Array(2, 5, 8, 11, 14)

    Dim i As Long, b As Long
    For i = LBound(breaks) To UBound(breaks)
        b = CLng(breaks(i))
        If b >= 1 And b <= maxBlocks Then
            Dim topCell As Range
            Set topCell = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(b, "00") & "_top")
            If Not topCell Is Nothing Then
                ws.HPageBreaks.Add Before:=ws.Rows(topCell.row)
            End If
        End If
    Next i
End Sub

Private Sub SetPrintAreaToLastUsedBlock_ByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    If nCourses < 1 Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If
    If nCourses > maxBlocks Then nCourses = maxBlocks

    Dim topLast As Range
    Set topLast = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(nCourses, "00") & "_top")
    If topLast Is Nothing Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If

    ' wysokość bloku: różnica top(2) - top(1) (stały układ)
    Dim h As Long: h = GetBlockHeightFromAnchors(wb)
    If h <= 0 Then
        ws.PageSetup.PrintArea = ws.UsedRange.Address
        Exit Sub
    End If

    Dim LastRow As Long
    LastRow = topLast.row + h - 1

    Dim lastCol As Long
    lastCol = ws.UsedRange.Column + ws.UsedRange.Columns.Count - 1

    ws.PageSetup.PrintArea = ws.Range(ws.Cells(1, 1), ws.Cells(LastRow, lastCol)).Address
End Sub

Private Function GetBlockRangeByTopAnchors(ByVal wb As Workbook, ByVal ws As Worksheet, ByVal blockNo As Long, ByVal maxBlocks As Long) As Range
    Dim topCell As Range
    Set topCell = GetNameRangeOrNothing(wb, "nr_blk_" & Format$(blockNo, "00") & "_top")
    If topCell Is Nothing Then Exit Function

    Dim h As Long: h = GetBlockHeightFromAnchors(wb)
    If h <= 0 Then Exit Function

    ' szerokość bierzemy z UsedRange kolumn (praktycznie cały blok jest w tym zakresie)
    Dim w As Long
    w = ws.UsedRange.Columns.Count
    If w < 1 Then w = 30

    Set GetBlockRangeByTopAnchors = ws.Range(topCell, topCell.Offset(h - 1, w - 1))
End Function

Private Function GetBlockHeightFromAnchors(ByVal wb As Workbook) As Long
    Dim t1 As Range, t2 As Range
    Set t1 = GetNameRangeOrNothing(wb, "nr_blk_01_top")
    Set t2 = GetNameRangeOrNothing(wb, "nr_blk_02_top")
    If t1 Is Nothing Or t2 Is Nothing Then Exit Function
    GetBlockHeightFromAnchors = t2.row - t1.row
End Function

' =========================
' NamedRanges: DANE_PERS -> workbook.Names
' =========================
Private Sub FillNamedRangesFromDanePers(ByVal templateWb As Workbook, ByVal danePersWs As Worksheet)
    On Error GoTo EH

    Dim lastR As Long: lastR = LastRow(danePersWs)
    If lastR < 1 Then Exit Sub

    Dim startRow As Long: startRow = 1
    If LCase$(Trim$(CStr(danePersWs.Cells(1, 1).value))) = "name" Then startRow = 2

    Dim r As Long
    For r = startRow To lastR
        Dim nm As String: nm = Trim$(CStr(danePersWs.Cells(r, 1).value))
        If Len(nm) = 0 Then GoTo NextR

        Dim v As Variant: v = danePersWs.Cells(r, 2).value
        If NameExists(templateWb, nm) Then
            On Error Resume Next
            templateWb.names(nm).RefersToRange.value = v
            If Err.Number <> 0 Then
                LogLine "WARN: NamedRange set failed '" & nm & "' Err=" & Err.Number
                Err.Clear
            End If
            On Error GoTo EH
        End If
NextR:
    Next r
    Exit Sub

EH:
    Err.Raise Err.Number, "FillNamedRangesFromDanePers", Err.Description
End Sub

Private Sub SafeSetNameValue(ByVal wb As Workbook, ByVal nm As String, ByVal v As Variant)
    If Not NameExists(wb, nm) Then Exit Sub
    On Error Resume Next
    wb.names(nm).RefersToRange.value = v
    On Error GoTo 0
End Sub

Private Function GetNameValueOrEmpty(ByVal wb As Workbook, ByVal nm As String) As Variant
    On Error GoTo EH
    If Not NameExists(wb, nm) Then Exit Function
    GetNameValueOrEmpty = wb.names(nm).RefersToRange.value
    Exit Function
EH:
    GetNameValueOrEmpty = Empty
End Function

Private Function NameExists(ByVal wb As Workbook, ByVal nameText As String) As Boolean
    On Error GoTo EH
    Dim n As Name
    Set n = wb.names(nameText)
    NameExists = True
    Exit Function
EH:
    NameExists = False
End Function

Private Function GetNameRangeOrNothing(ByVal wb As Workbook, ByVal nm As String) As Range
    On Error GoTo EH
    If Not NameExists(wb, nm) Then Exit Function
    Set GetNameRangeOrNothing = wb.names(nm).RefersToRange
    Exit Function
EH:
End Function

' =========================
' Layout
' =========================
Private Sub ApplyLayout(ByVal ws As Worksheet)
    With ws.PageSetup
        .PaperSize = xlPaperA4
        .Orientation = xlPortrait
        .LeftMargin = Application.CentimetersToPoints(MARGIN_CM)
        .RightMargin = Application.CentimetersToPoints(MARGIN_CM)
        .TopMargin = Application.CentimetersToPoints(MARGIN_CM)
        .BottomMargin = Application.CentimetersToPoints(MARGIN_CM)
        .Zoom = False
        .FitToPagesWide = 1
        .FitToPagesTall = False
    End With
    ws.UsedRange.WrapText = True
End Sub

' =========================
' PutValue / helpers
' =========================
Private Sub PutValueOrDash(ByVal tgt As Range, ByVal v As Variant, ByVal isPercent As Boolean)
    If tgt Is Nothing Then Exit Sub

    Dim area As Range
    Set area = tgt.MergeArea

    If IsEmpty(v) Or v = "" Then
        area.NumberFormat = "General"
        area.Cells(1, 1).value = "-"
        Exit Sub
    End If

    If isPercent Then
        Dim x As Double, s As String

        If IsNumeric(v) Then
            x = CDbl(v)
        Else
            s = Trim$(CStr(v))
            s = Replace$(s, "%", "")
            s = Replace$(s, Chr$(160), " ")
            s = Replace$(s, " ", "")

            If Application.DecimalSeparator = "," Then
                s = Replace$(s, ".", ",")
            Else
                s = Replace$(s, ",", ".")
            End If

            If Not IsNumeric(s) Then
                area.NumberFormat = "General"
                area.Cells(1, 1).value = "-"
                Exit Sub
            End If
            x = CDbl(s)
        End If

        If x > 1# Then x = x / 100#
        area.Cells(1, 1).value = x
        area.NumberFormat = PERCENT_FORMAT
    Else
        If IsNumeric(v) Then
            area.Cells(1, 1).value = CDbl(v)
            area.NumberFormat = "General"
        Else
            area.NumberFormat = "General"
            area.Cells(1, 1).value = "-"
        End If
    End If
End Sub

Private Function FindNextValueCellRight(ByVal fromArea As Range) As Range
    ' Szuka pierwszej "sensownej" komórki na prawo od etykiety, w tym samym wierszu.
    ' Obsługa scaleń: przechodzimy po kolumnach od końca mergeArea.
    Dim ws As Worksheet: Set ws = fromArea.Worksheet
    Dim r As Long: r = fromArea.row
    Dim startCol As Long: startCol = fromArea.Column + fromArea.Columns.Count

    Dim c As Long
    For c = startCol To ws.Columns.Count
        Dim cc As Range: Set cc = ws.Cells(r, c)
        Dim ma As Range: Set ma = MergeAreaOrSelf(cc)

        ' pomijamy jeśli to ewidentny tekst-nagłówek
        Dim t As String: t = Trim$(CStr(ma.Cells(1, 1).value))
        If NormalizeFuzzy(t) Like "*rodzaj udostepnionej*" Then GoTo NextC
        If NormalizeFuzzy(t) Like "*ilosc*" Then GoTo NextC
        If InStr(1, t, "%", vbTextCompare) > 0 And InStr(1, NormalizeFuzzy(t), "skali", vbTextCompare) > 0 Then GoTo NextC

        Set FindNextValueCellRight = ma
        Exit Function
NextC:
    Next c
End Function

Private Function MergeAreaOrSelf(ByVal c As Range) As Range
    If c.MergeCells Then
        Set MergeAreaOrSelf = c.MergeArea
    Else
        Set MergeAreaOrSelf = c
    End If
End Function

Private Function IsNumericLike(ByVal s As String) As Boolean
    Dim t As String
    t = Replace$(s, "%", "")
    t = Replace$(t, " ", "")
    t = Replace$(t, Chr$(160), "")
    If Len(t) = 0 Then Exit Function
    If Application.DecimalSeparator = "," Then
        t = Replace$(t, ".", ",")
    Else
        t = Replace$(t, ",", ".")
    End If
    IsNumericLike = IsNumeric(t)
End Function

Private Function NormalizeFuzzy(ByVal s As String) As String
    s = Replace$(s, vbCr, " ")
    s = Replace$(s, vbLf, " ")
    s = Replace$(s, Chr$(160), " ")
    s = Trim$(Application.WorksheetFunction.Trim(s))
    s = LCase$(s)
    s = ReplacePolish(s)
    NormalizeFuzzy = s
End Function

Private Function ReplacePolish(ByVal s As String) As String
    s = Replace$(s, "ą", "a")
    s = Replace$(s, "ć", "c")
    s = Replace$(s, "ę", "e")
    s = Replace$(s, "ł", "l")
    s = Replace$(s, "ń", "n")
    s = Replace$(s, "ó", "o")
    s = Replace$(s, "ś", "s")
    s = Replace$(s, "ż", "z")
    s = Replace$(s, "ź", "z")
    ReplacePolish = s
End Function

' =========================
' Tools: sheets, picker, folder, lastrow, sanitize
' =========================
Private Function GetWsOrNothing(ByVal wb As Workbook, ByVal wsName As String) As Worksheet
    On Error Resume Next
    Set GetWsOrNothing = wb.Worksheets(wsName)
    On Error GoTo 0
End Function

Private Function PickReportTemplate() As String
    Dim fd As FileDialog
    Set fd = Application.FileDialog(msoFileDialogFilePicker)
    With fd
        .title = "Wskaż plik wzoru raportu (.xlsx)"
        .Filters.Clear
        .Filters.Add "Excel", "*.xlsx"
        .AllowMultiSelect = False
        If .Show = -1 Then PickReportTemplate = .SelectedItems(1)
    End With
End Function

Private Function PickSourceFolder() As String
    Dim fd As FileDialog
    Set fd = Application.FileDialog(msoFileDialogFolderPicker)
    With fd
        .title = "Wybierz folder z plikami źródłowymi (.xlsx)"
        If .Show = -1 Then PickSourceFolder = .SelectedItems(1)
    End With
End Function

Private Sub EnsureFolder(ByVal path As String)
    Dim fso As Object
    If Len(path) = 0 Then Exit Sub
    If Right$(path, 1) = "\" Then path = Left$(path, Len(path) - 1)
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(path) Then fso.CreateFolder path
End Sub

Private Function SanitizeFileName(ByVal s As String) As String
    Dim bad: bad = Array("/", "\", ":", "*", "?", """", "<", ">", "|")
    Dim i As Long
    For i = LBound(bad) To UBound(bad)
        s = Replace$(s, bad(i), "-")
    Next i
    SanitizeFileName = s
End Function

Private Function LastRow(ByVal ws As Worksheet) As Long
    LastRow = ws.Cells(ws.Rows.Count, 1).End(xlUp).row
End Function

Private Function ParentFolderWithBackslash(ByVal folderPath As String) As String
    Dim p As String: p = folderPath
    If Right$(p, 1) = "\" Then p = Left$(p, Len(p) - 1)
    Dim i As Long: i = InStrRev(p, "\")
    If i > 0 Then ParentFolderWithBackslash = Left$(p, i)
End Function

' =========================
' Logging
' =========================


Private Sub LogOpen(ByVal path As String)
    mLogPath = path
    mLogFile = FreeFile
    Open mLogPath For Output As #mLogFile
    Print #mLogFile, "LOG " & Now
End Sub

Private Sub LogLine(ByVal s As String)
    On Error Resume Next
    If mLogFile <> 0 Then Print #mLogFile, Format$(Now, "hh:nn:ss") & " | " & s
    On Error GoTo 0
End Sub

Private Sub LogClose()
    On Error Resume Next
    If mLogFile <> 0 Then Close #mLogFile
    mLogFile = 0
    On Error GoTo 0
End Sub


================================================================================
vba\modules\modNA_UIInputs.vb
================================================================================

﻿' === Component: modNA_UIInputs [Standard Module]
' === Exported: 2026-02-26 14:22:22

Option Explicit

Private Const KEYS_REL As String = "_data\KEYS.xlsx"

Public Sub UI_LoadDefaults()
    On Error Resume Next
    With raporty_plum
        .txtLogsFolder.text = GetSetting("mRNA-PLUM", "Paths", "LogsFolder", "")
        .txtTemplateXlsx.text = ""
        .txtKeysXlsx.text = GetSetting("mRNA-PLUM", "Paths", "KeysXlsx", ThisWorkbook.path & "\_data\KEYS.xlsx")
    End With
    On Error GoTo 0
End Sub

Public Sub UI_SaveDefaults()
    On Error Resume Next
    SaveSetting "mRNA-PLUM", "Paths", "LogsFolder", raporty_plum.txtLogsFolder.text
    SaveSetting "mRNA-PLUM", "Paths", "KeysXlsx", raporty_plum.txtKeysXlsx.text
    On Error GoTo 0
End Sub

Public Function UI_ValidateInputs(ByRef errMsg As String) As Boolean

    Dim logsFolder As String, templateXlsx As String, keysXlsx As String
    logsFolder = Trim$(raporty_plum.txtLogsFolder.text)
    templateXlsx = Trim$(raporty_plum.txtTemplateXlsx.text)
    keysXlsx = Trim$(raporty_plum.txtKeysXlsx.text)

    If Len(logsFolder) = 0 Then errMsg = "Nie wskazano folderu z logami.": Exit Function
    If Not FolderExists(logsFolder) Then errMsg = "Folder logów nie istnieje: " & logsFolder: Exit Function

    If Len(keysXlsx) = 0 Then errMsg = "Nie wskazano pliku KEYS.xlsx.": Exit Function
    If Not FileExists(keysXlsx) Then errMsg = "Plik KEYS.xlsx nie istnieje: " & keysXlsx: Exit Function

    If Len(templateXlsx) = 0 Then errMsg = "Nie wskazano wzoru raportu (template).": Exit Function
    If Not FileExists(templateXlsx) Then errMsg = "Wzór raportu nie istnieje: " & templateXlsx: Exit Function

    UI_ValidateInputs = True

End Function

Public Function BuildRuntimeConfigYaml(ByVal rootPath As String) As String
    Dim cfgPath As String
    cfgPath = rootPath & "\_run\config.runtime.yaml"

    Dim logsFolder As String, templateXlsx As String, keysXlsx As String
    logsFolder = NormalizePath(raporty_plum.txtLogsFolder.text)
    templateXlsx = NormalizePath(raporty_plum.txtTemplateXlsx.text)
    keysXlsx = rootPath & "\" & KEYS_REL

    EnsureFolder rootPath & "\_run"
    EnsureFolder rootPath & "\_out"
    EnsureFolder rootPath & "\_out\indywidualne"
    EnsureFolder rootPath & "\_out\pdf"

    Dim y As String
    y = ""
    y = y & "root: """ & YamlEscape(rootPath) & """" & vbCrLf

    y = y & "data:" & vbCrLf
    y = y & "  logs_dir: """ & YamlEscape(logsFolder) & """" & vbCrLf
    y = y & "  logs_recursive: true" & vbCrLf ' <— ważne: folder + podfoldery

    y = y & "run:" & vbCrLf
    y = y & "  dir: """ & YamlEscape(rootPath & "\_run") & """" & vbCrLf

    y = y & "out:" & vbCrLf
    y = y & "  indywidualne_dir: """ & YamlEscape(rootPath & "\_out\indywidualne") & """" & vbCrLf
    y = y & "  pdf_dir: """ & YamlEscape(rootPath & "\_out\pdf") & """" & vbCrLf

    y = y & "parse_events:" & vbCrLf
    y = y & "  keys_xlsx: """ & YamlEscape(keysXlsx) & """" & vbCrLf
    y = y & "  keys_sheet: ""KEYS""" & vbCrLf

    y = y & "pdf:" & vbCrLf
    y = y & "  template_xlsx: """ & YamlEscape(templateXlsx) & """" & vbCrLf

    WriteTextFileUtf8 cfgPath, y
    BuildRuntimeConfigYaml = cfgPath
End Function

' --- dialogi i utils (zostają z poprzedniej wersji) ---
Public Function PickFolderDialog(ByVal title As String, Optional ByVal initialPath As String = "") As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(4)
    fd.title = title
    If Len(initialPath) > 0 Then fd.InitialFileName = EnsureTrailingBackslash(initialPath)
    fd.AllowMultiSelect = False
    If fd.Show <> -1 Then Exit Function
    PickFolderDialog = CStr(fd.SelectedItems(1))
    Exit Function
EH:
    PickFolderDialog = ""
End Function

Public Function PickFileDialog(ByVal title As String, ByVal filterDesc As String, ByVal filterPattern As String, Optional ByVal initialPath As String = "") As String
    On Error GoTo EH
    Dim fd As Object
    Set fd = Application.FileDialog(3)
    fd.title = title
    fd.AllowMultiSelect = False
    fd.Filters.Clear
    fd.Filters.Add filterDesc, filterPattern
    If Len(initialPath) > 0 Then fd.InitialFileName = initialPath
    If fd.Show <> -1 Then Exit Function
    PickFileDialog = CStr(fd.SelectedItems(1))
    Exit Function
EH:
    PickFileDialog = ""
End Function

Private Function FileExists(ByVal p As String) As Boolean: FileExists = (Len(dir(p)) > 0): End Function
Private Function FolderExists(ByVal p As String) As Boolean
    On Error Resume Next
    FolderExists = (Len(dir(p, vbDirectory)) > 0)
    On Error GoTo 0
End Function

Private Sub EnsureFolder(ByVal folderPath As String)
    Dim fso As Object
    Set fso = CreateObject("Scripting.FileSystemObject")
    If Not fso.FolderExists(folderPath) Then fso.CreateFolder folderPath
End Sub

Private Function EnsureTrailingBackslash(ByVal p As String) As String
    If Len(p) = 0 Then EnsureTrailingBackslash = "": Exit Function
    If Right$(p, 1) = "\" Then EnsureTrailingBackslash = p Else EnsureTrailingBackslash = p & "\"
End Function

Private Function NormalizePath(ByVal p As String) As String
    NormalizePath = Replace(Trim$(p), "/", "\")
End Function

Private Function YamlEscape(ByVal s As String) As String
    YamlEscape = Replace(s, """", "\""")
End Function

Private Sub WriteTextFileUtf8(ByVal fullPath As String, ByVal text As String)
    Dim stm As Object
    Set stm = CreateObject("ADODB.Stream")
    stm.Type = 2
    stm.Charset = "utf-8"
    stm.Open
    stm.WriteText text
    stm.Position = 0
    stm.SaveToFile fullPath, 2
    stm.Close
End Sub


================================================================================
vba\modules\modPdfEngine.vb
================================================================================

﻿' === Component: modPdfEngine [Standard Module]
' === Exported: 2026-02-26 14:22:22

Option Explicit

' ============================================================
' modPdfEngine — stable PDF engine for mRNA-PLUM (late binding)
' ============================================================

' ---------- Logging ----------
Private mLogFile As Integer
Private mLogPath As String

' ============================================================
' PUBLIC API
' ============================================================
Public Sub PdfEngine_RunBatch(ByVal cfg As Object)
    On Error GoTo EH

    Dim t0 As Double: t0 = Timer

    ' Validate cfg
    Dim root As String: root = NzStr(cfg("root"))
    Dim inFolder As String: inFolder = NzStr(cfg("in_indywidualne"))
    Dim outPdf As String: outPdf = NzStr(cfg("out_pdf"))
    Dim runDir As String: runDir = NzStr(cfg("run_dir"))
    Dim templatePath As String: templatePath = NzStr(cfg("template_path"))

    Dim sheetPers As String: sheetPers = NzStr(cfg("sheet_dane_pers"))
    Dim sheetKursy As String: sheetKursy = NzStr(cfg("sheet_dane_kursy"))
    Dim sheetReport As String: sheetReport = NzStr(cfg("sheet_report"))

    Dim maxBlocks As Long: maxBlocks = CLng(cfg("max_blocks"))
    Dim truncateOverflow As Boolean: truncateOverflow = CBool(cfg("truncate_overflow"))

    If Right$(inFolder, 1) <> "\" Then inFolder = inFolder & "\"
    If Right$(outPdf, 1) <> "\" Then outPdf = outPdf & "\"
    If Right$(runDir, 1) <> "\" Then runDir = runDir & "\"

    EnsureFolder runDir
    EnsureFolder outPdf

    OpenLog runDir, "pdf_batch"

    LogLine "START PdfEngine_RunBatch"
    LogLine "root=" & root
    LogLine "in_indywidualne=" & inFolder
    LogLine "out_pdf=" & outPdf
    LogLine "template_path=" & templatePath

    If dir(templatePath) = vbNullString Then
        Err.Raise vbObjectError + 100, "PdfEngine_RunBatch", "Nie znaleziono template: " & templatePath
    End If

    ' Stability settings
    Dim prevCalc As XlCalculation
    Dim prevSU As Boolean, prevEE As Boolean, prevDA As Boolean
    prevCalc = Application.Calculation
    prevSU = Application.ScreenUpdating
    prevEE = Application.EnableEvents
    prevDA = Application.DisplayAlerts

    Application.ScreenUpdating = False
    Application.EnableEvents = False
    Application.DisplayAlerts = False
    Application.Calculation = xlCalculationManual

    Dim f As String
    f = dir(inFolder & "*.xlsx")
    If Len(f) = 0 Then
        LogLine "Brak plików XLSX w: " & inFolder
        GoTo CleanUp
    End If

    Dim countOk As Long, countFail As Long, countAll As Long

    Do While Len(f) > 0
        countAll = countAll + 1
        Dim srcPath As String: srcPath = inFolder & f

        On Error GoTo OneFail
        ProcessOneTeacherFile srcPath, templatePath, outPdf, sheetPers, sheetKursy, sheetReport, maxBlocks, truncateOverflow
        countOk = countOk + 1
        LogLine "OK: " & srcPath
        On Error GoTo EH

NextFile:
    f = dir()
    DoEvents
    GoTo ContinueLoop

OneFail:
    countFail = countFail + 1
    LogLine "FAIL: " & srcPath & " | Err=" & Err.Number & " | " & Err.Description
    Err.Clear
    On Error GoTo EH
    Resume NextFile

ContinueLoop:
Loop

CleanUp:
    Application.Calculation = prevCalc
    Application.DisplayAlerts = prevDA
    Application.EnableEvents = prevEE
    Application.ScreenUpdating = prevSU

    LogLine "DONE: all=" & countAll & ", ok=" & countOk & ", fail=" & countFail & ", sec=" & Format$(Timer - t0, "0.0")
    CloseLog
    Exit Sub

EH:
    LogLine "FATAL: Err=" & Err.Number & " | " & Err.Description
    CloseLog
    Err.Raise Err.Number, "PdfEngine_RunBatch", Err.Description
End Sub

' ============================================================
' CORE — one teacher file
' ============================================================
Private Sub ProcessOneTeacherFile( _
    ByVal srcPath As String, _
    ByVal templatePath As String, _
    ByVal outPdfFolder As String, _
    ByVal sheetPers As String, _
    ByVal sheetKursy As String, _
    ByVal sheetReport As String, _
    ByVal maxBlocks As Long, _
    ByVal truncateOverflow As Boolean _
)
    On Error GoTo EH

    Dim wbData As Workbook, wbTpl As Workbook
    Dim wsPers As Worksheet, wsKursy As Worksheet, wsReport As Worksheet

    LogLine "----"
    LogLine "Process: " & srcPath

    Set wbData = Workbooks.Open(fileName:=srcPath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Set wsPers = GetSheetSafe(wbData, sheetPers)
    Set wsKursy = GetSheetSafe(wbData, sheetKursy)
    If wsKursy Is Nothing Then Err.Raise vbObjectError + 200, "ProcessOneTeacherFile", "Brak arkusza DANE_KURSY w: " & srcPath

    Set wbTpl = Workbooks.Open(fileName:=templatePath, ReadOnly:=True, UpdateLinks:=0, AddToMru:=False)

    Set wsReport = ResolveReportSheet(wbTpl, sheetReport)
    If wsReport Is Nothing Then Err.Raise vbObjectError + 201, "ProcessOneTeacherFile", "Nie znaleziono arkusza raportu w template."

    ' 1) Fill named ranges (metryczka + KPI)
    If Not wsPers Is Nothing Then
        FillNamedRangesFromDanePers wbTpl, wsPers
    Else
        LogLine "WARN: Brak DANE_PERS w źródle: " & srcPath
    End If

    ' 2) Load courses
    Dim courses As Collection
    Set courses = LoadCourses(wsKursy)

    Dim nCourses As Long
    nCourses = courses.Count

    If nCourses > maxBlocks Then
        Dim msg As String
        msg = "Nadmiar kursów: " & nCourses & " > " & maxBlocks & " w " & srcPath
        If truncateOverflow Then
            LogLine "WARN: " & msg & " | TRUNCATE -> " & maxBlocks
            nCourses = maxBlocks
        Else
            Err.Raise vbObjectError + 202, "ProcessOneTeacherFile", msg
        End If
    End If

    ' 3) Fill course blocks 1..N
    Dim i As Long
    For i = 1 To nCourses
        FillCourseBlock wsReport, i, courses(i)
    Next i

    ' 4) Clear unused blocks
    TrimUnusedBlocks wsReport, nCourses, maxBlocks

    ' 5) Setup page breaks (manual)
    SetupPageBreaks wsReport, nCourses, maxBlocks

    ' 6) Print area to last block
    SetPrintAreaToLastBlock wsReport, nCourses, maxBlocks

    ' 7) Export PDF
    Dim outPdfPath As String
    outPdfPath = outPdfFolder & BuildPdfFileName(wbTpl, wbData, wsPers, srcPath) & ".pdf"

    ExportReportToPdf wbTpl, wsReport, outPdfPath

    ' Close without saving (template always)
    SafeClose wbTpl
    SafeClose wbData
    Exit Sub

EH:
    LogLine "ERROR ProcessOneTeacherFile: Err=" & Err.Number & " | " & Err.Description
    SafeClose wbTpl
    SafeClose wbData
    Err.Raise Err.Number, "ProcessOneTeacherFile", Err.Description
End Sub

' ============================================================
' REQUIRED FUNCTIONS (per spec)
' ============================================================

Public Sub FillNamedRangesFromDanePers(ByVal templateWb As Workbook, ByVal danePersWs As Worksheet)
    On Error GoTo EH

    Dim LastRow As Long
    LastRow = LastUsedRow(danePersWs, 1)
    If LastRow < 1 Then Exit Sub

    Dim r As Long
    Dim startRow As Long: startRow = 1

    ' jeśli A1 wygląda jak nagłówek "Name" -> start od 2
    If LCase$(Trim$(CStr(danePersWs.Cells(1, 1).value))) = "name" Then startRow = 2

    For r = startRow To LastRow
        Dim nm As String, v As Variant
        nm = Trim$(CStr(danePersWs.Cells(r, 1).value))
        v = danePersWs.Cells(r, 2).value

        If Len(nm) > 0 Then
            If NameExistsInWorkbook(templateWb, nm) Then
                On Error Resume Next
                templateWb.names(nm).RefersToRange.value = v
                If Err.Number <> 0 Then
                    LogLine "WARN: nie dało się ustawić NamedRange '" & nm & "' (" & Err.Number & "): " & Err.Description
                    Err.Clear
                End If
                On Error GoTo EH
            Else
                LogLine "WARN: brak NamedRange w template: " & nm
            End If
        End If
    Next r

    Exit Sub
EH:
    Err.Raise Err.Number, "FillNamedRangesFromDanePers", Err.Description
End Sub

Public Function LoadCourses(ByVal daneKursyWs As Worksheet) As Collection
    On Error GoTo EH

    Dim col As New Collection

    Dim LastRow As Long, lastCol As Long
    LastRow = LastUsedRow(daneKursyWs, 1)
    lastCol = LastUsedCol(daneKursyWs, 1)
    If LastRow < 2 Or lastCol < 1 Then
        Set LoadCourses = col
        Exit Function
    End If

    Dim headers() As Variant
    headers = daneKursyWs.Range(daneKursyWs.Cells(1, 1), daneKursyWs.Cells(1, lastCol)).Value2

    Dim data() As Variant
    data = daneKursyWs.Range(daneKursyWs.Cells(2, 1), daneKursyWs.Cells(LastRow, lastCol)).Value2

    Dim r As Long, c As Long
    For r = 1 To UBound(data, 1)
        Dim d As Object ' Scripting.Dictionary
        Set d = CreateObject("Scripting.Dictionary")
        d.CompareMode = 1 ' TextCompare

        For c = 1 To lastCol
            Dim h As String
            h = Trim$(CStr(headers(1, c)))
            If Len(h) = 0 Then h = "col_" & c
            d(h) = data(r, c)
        Next c

        col.Add d
    Next r

    Set LoadCourses = col
    Exit Function

EH:
    Err.Raise Err.Number, "LoadCourses", Err.Description
End Function

Public Sub FillCourseBlock(ByVal wsReport As Worksheet, ByVal blockNo As Long, ByVal courseRow As Object)
    ' courseRow: Scripting.Dictionary header->value
    On Error GoTo EH

    Dim topNm As String
    topNm = "nr_blk_" & Format$(blockNo, "00") & "_top"

    Dim topCell As Range
    Set topCell = GetNamedRangeCell(wsReport.Parent, topNm)
    If topCell Is Nothing Then
        LogLine "WARN: brak NamedRange top dla bloku: " & topNm
        Exit Sub
    End If

    ' --- MAPOWANIE BLOKU ---
    ' Najstabilniejsze podejście: tabela map w template (opcjonalna):
    ' Sheet: "MAPA_BLOKU"
    ' kol A: FieldName (nagłówek z DANE_KURSY)
    ' kol B: RowOffset (0=ten sam wiersz co top)
    ' kol C: ColOffset (0=ta sama kolumna co top)
    ' Jeśli nie ma MAPA_BLOKU -> stosujemy "default minimal" (tytuł kursu itp.) + log ostrzegawczy.

    Dim map As Object
    Set map = TryLoadBlockMap(wsReport.Parent)

    If map Is Nothing Then
        ' Default minimal: wpisz tytuł kursu w 2 wierszach od top,
        ' a ID kursu obok (bardzo bezpieczne, bo nie rozwala layoutu).
        ' Dostosujesz po potwierdzeniu offsetów albo dodaniu MAPA_BLOKU.
        LogLine "WARN: brak MAPA_BLOKU w template — używam default minimal dla bloku " & blockNo

        Dim vTitle As Variant, vId As Variant
        vTitle = PickCourseValue(courseRow, Array("pełna nazwa e-kursu", "pelna nazwa e-kursu", "full_name", "fullname", "nazwa", "course_name", "nazwa kursu"))
        vId = PickCourseValue(courseRow, Array("id kursu", "course_id", "id", "courseid"))

        ' Wstaw: topCell.Offset(0,0) -> tytuł
        topCell.Offset(0, 0).value = vTitle
        ' ID np. w komórce obok (kolumna +10) — bezpieczne, ale może wymagać korekty
        topCell.Offset(0, 10).value = vId

        Exit Sub
    End If

    ' Map exists: iterate entries field->(rOff,cOff)
    Dim k As Variant
    For Each k In map.keys
        Dim rc As Variant
        rc = map(k) ' array(0)=rOff, array(1)=cOff

        Dim val As Variant
        val = GetCourseValueByHeader(courseRow, CStr(k))

        With topCell.Offset(CLng(rc(0)), CLng(rc(1)))
            .value = val
        End With
    Next k

    Exit Sub

EH:
    Err.Raise Err.Number, "FillCourseBlock", Err.Description
End Sub

Public Sub SetupPageBreaks(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    ' Reset existing manual breaks
    On Error Resume Next
    wsReport.ResetAllPageBreaks
    On Error GoTo EH

    ' Wg ustaleń: HPageBreak przed blokami #2,#5,#8,#11,#14 (ale tylko jeśli istnieją w zakresie 1..maxBlocks)
    Dim breaks As Variant
    breaks = Array(2, 5, 8, 11, 14)

    Dim i As Long
    For i = LBound(breaks) To UBound(breaks)
        Dim b As Long: b = CLng(breaks(i))
        If b >= 1 And b <= maxBlocks Then
            ' Jeśli realnie mamy mniej kursów niż b, to i tak break jest OK (template ma stałe strony),
            ' ale możesz też warunkować: If nCourses >= b Then ...
            Dim nm As String
            nm = "nr_blk_" & Format$(b, "00") & "_top"
            Dim topCell As Range
            Set topCell = GetNamedRangeCell(wsReport.Parent, nm)
            If Not topCell Is Nothing Then
                wsReport.HPageBreaks.Add Before:=topCell
            Else
                LogLine "WARN: SetupPageBreaks brak named range: " & nm
            End If
        End If
    Next i

    Exit Sub
EH:
    Err.Raise Err.Number, "SetupPageBreaks", Err.Description
End Sub

Public Sub TrimUnusedBlocks(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    If nCourses < 0 Then nCourses = 0
    If nCourses >= maxBlocks Then Exit Sub

    Dim blockHeight As Long
    blockHeight = DetectBlockHeight(wsReport, maxBlocks)
    If blockHeight <= 0 Then
        LogLine "WARN: Nie wykryto wysokości bloku — TrimUnusedBlocks pominięte"
        Exit Sub
    End If

    Dim b As Long
    For b = nCourses + 1 To maxBlocks
        Dim topNm As String: topNm = "nr_blk_" & Format$(b, "00") & "_top"
        Dim topCell As Range: Set topCell = GetNamedRangeCell(wsReport.Parent, topNm)
        If Not topCell Is Nothing Then
            Dim rng As Range
            ' Czyścimy "obszar bloku": od top w dół blockHeight-1 wierszy.
            ' Szerokość: używamy UsedRange.Columns, ale ograniczamy do sensownego obszaru strony.
            Set rng = BlockRangeByHeuristics(wsReport, topCell, blockHeight)
            rng.ClearContents
        End If
    Next b

    Exit Sub
EH:
    Err.Raise Err.Number, "TrimUnusedBlocks", Err.Description
End Sub

Public Sub SetPrintAreaToLastBlock(ByVal wsReport As Worksheet, ByVal nCourses As Long, ByVal maxBlocks As Long)
    On Error GoTo EH

    If nCourses <= 0 Then
        ' jeżeli brak kursów — drukuj stronę 1 (metryczka + KPI) -> ustawimy UsedRange
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    If nCourses > maxBlocks Then nCourses = maxBlocks

    Dim blockHeight As Long
    blockHeight = DetectBlockHeight(wsReport, maxBlocks)
    If blockHeight <= 0 Then
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    Dim lastTopNm As String: lastTopNm = "nr_blk_" & Format$(nCourses, "00") & "_top"
    Dim lastTop As Range: Set lastTop = GetNamedRangeCell(wsReport.Parent, lastTopNm)

    If lastTop Is Nothing Then
        wsReport.PageSetup.PrintArea = wsReport.UsedRange.Address
        Exit Sub
    End If

    Dim LastRow As Long
    LastRow = lastTop.row + blockHeight - 1

    ' Kolumny do wydruku: od 1 do ostatniej użytej w nagłówku / usedrange
    Dim lastCol As Long
    lastCol = wsReport.UsedRange.Column + wsReport.UsedRange.Columns.Count - 1
    If lastCol < 1 Then lastCol = 1

    Dim rng As Range
    Set rng = wsReport.Range(wsReport.Cells(1, 1), wsReport.Cells(LastRow, lastCol))
    wsReport.PageSetup.PrintArea = rng.Address

    Exit Sub
EH:
    Err.Raise Err.Number, "SetPrintAreaToLastBlock", Err.Description
End Sub

Public Sub ExportReportToPdf(ByVal templateWb As Workbook, ByVal wsReport As Worksheet, ByVal outPdfPath As String)
    On Error GoTo EH

    EnsureFolder ParentFolder(outPdfPath)

    ' Stabilne ustawienia PageSetup wg ustaleń
    With wsReport.PageSetup
        .Zoom = False
        .FitToPagesWide = 1
        .FitToPagesTall = False
    End With

    ' Export
    wsReport.ExportAsFixedFormat _
        Type:=xlTypePDF, _
        fileName:=outPdfPath, _
        Quality:=xlQualityStandard, _
        IncludeDocProperties:=True, _
        IgnorePrintAreas:=False, _
        OpenAfterPublish:=False

    LogLine "PDF: " & outPdfPath
    Exit Sub

EH:
    Err.Raise Err.Number, "ExportReportToPdf", Err.Description
End Sub

' ============================================================
' Helpers — report/template/data
' ============================================================

Private Function ResolveReportSheet(ByVal wb As Workbook, ByVal sheetName As String) As Worksheet
    On Error Resume Next
    If Len(sheetName) > 0 Then
        Set ResolveReportSheet = wb.Worksheets(sheetName)
    Else
        Set ResolveReportSheet = wb.Worksheets(1)
    End If
    On Error GoTo 0
End Function

Private Function GetSheetSafe(ByVal wb As Workbook, ByVal sheetName As String) As Worksheet
    On Error Resume Next
    Set GetSheetSafe = wb.Worksheets(sheetName)
    On Error GoTo 0
End Function

Private Sub SafeClose(ByVal wb As Workbook)
    On Error Resume Next
    If Not wb Is Nothing Then wb.Close SaveChanges:=False
    On Error GoTo 0
End Sub

Private Function BuildPdfFileName(ByVal wbTpl As Workbook, ByVal wbData As Workbook, ByVal wsPers As Worksheet, ByVal srcPath As String) As String
    ' Prefer: NazwiskoImie + BAZUS ID (z DANE_PERS jeśli są NamedRanges na te dane)
    On Error GoTo EH

    Dim base As String
    base = FileBaseName(srcPath)

    Dim nazw As String, bazus As String
    nazw = ""
    bazus = ""

    ' Jeżeli w DANE_PERS są klucze, np. nr_meta_NazwiskoImie / nr_meta_BazusID
    ' to to już trafia do NamedRanges w template. Ale do nazwy PDF możemy też czytać prosto z DANE_PERS:
    If Not wsPers Is Nothing Then
        nazw = FindPersValue(wsPers, Array("NazwiskoImie", "Nazwisko Imię", "NAZWISKOIMIE", "nr_meta_NazwiskoImie"))
        bazus = FindPersValue(wsPers, Array("BAZUS ID", "Bazus ID", "BAZUSID", "nr_meta_BazusID"))
    End If

    If Len(Trim$(nazw)) > 0 Then base = Trim$(nazw)
    If Len(Trim$(bazus)) > 0 Then base = base & "_" & Trim$(bazus)

    base = SanitizeFileName(base)
    If Len(base) > 180 Then base = Left$(base, 180)

    BuildPdfFileName = base
    Exit Function

EH:
    BuildPdfFileName = SanitizeFileName(FileBaseName(srcPath))
End Function

Private Function FindPersValue(ByVal ws As Worksheet, ByVal keys As Variant) As String
    On Error GoTo EH
    Dim LastRow As Long: LastRow = LastUsedRow(ws, 1)
    If LastRow < 1 Then Exit Function

    Dim startRow As Long: startRow = 1
    If LCase$(Trim$(CStr(ws.Cells(1, 1).value))) = "name" Then startRow = 2

    Dim r As Long, i As Long
    For r = startRow To LastRow
        Dim nm As String: nm = Trim$(CStr(ws.Cells(r, 1).value))
        If Len(nm) > 0 Then
            For i = LBound(keys) To UBound(keys)
                If LCase$(nm) = LCase$(CStr(keys(i))) Then
                    FindPersValue = Trim$(CStr(ws.Cells(r, 2).value))
                    Exit Function
                End If
            Next i
        End If
    Next r
    Exit Function
EH:
    FindPersValue = ""
End Function

' ============================================================
' Block mapping via MAPA_BLOKU (recommended)
' ============================================================

Private Function TryLoadBlockMap(ByVal wb As Workbook) As Object
    ' Returns Scripting.Dictionary: key=FieldName (DANE_KURSY header), value=array(rOff,cOff)
    ' Expected sheet: MAPA_BLOKU
    ' A: FieldName, B: RowOffset, C: ColOffset
    On Error GoTo EH

    Dim ws As Worksheet
    On Error Resume Next
    Set ws = wb.Worksheets("MAPA_BLOKU")
    On Error GoTo 0
    If ws Is Nothing Then Exit Function

    Dim LastRow As Long: LastRow = LastUsedRow(ws, 1)
    If LastRow < 2 Then Exit Function

    Dim d As Object: Set d = CreateObject("Scripting.Dictionary")
    d.CompareMode = 1 ' TextCompare

    Dim r As Long
    For r = 2 To LastRow
        Dim fieldName As String
        fieldName = Trim$(CStr(ws.Cells(r, 1).value))
        If Len(fieldName) > 0 Then
            Dim ro As Long, co As Long
            ro = CLng(val(ws.Cells(r, 2).value))
            co = CLng(val(ws.Cells(r, 3).value))
            d(fieldName) = Array(ro, co)
        End If
    Next r

    If d.Count = 0 Then Exit Function
    Set TryLoadBlockMap = d
    Exit Function

EH:
    LogLine "WARN: MAPA_BLOKU read error: " & Err.Number & " | " & Err.Description
End Function

Private Function GetCourseValueByHeader(ByVal courseRow As Object, ByVal headerName As String) As Variant
    ' direct header match
    If courseRow.Exists(headerName) Then
        GetCourseValueByHeader = courseRow(headerName)
    Else
        ' fuzzy (normalized)
        GetCourseValueByHeader = GetCourseValueFuzzy(courseRow, headerName)
    End If
End Function

Private Function GetCourseValueFuzzy(ByVal courseRow As Object, ByVal headerName As String) As Variant
    On Error GoTo EH

    Dim target As String
    target = NormalizeKey(headerName)

    Dim k As Variant
    For Each k In courseRow.keys
        If NormalizeKey(CStr(k)) = target Then
            GetCourseValueFuzzy = courseRow(k)
            Exit Function
        End If
    Next k

    GetCourseValueFuzzy = vbNullString
    Exit Function

EH:
    GetCourseValueFuzzy = vbNullString
End Function

Private Function PickCourseValue(ByVal courseRow As Object, ByVal candidates As Variant) As Variant
    Dim i As Long
    For i = LBound(candidates) To UBound(candidates)
        Dim v As Variant
        v = GetCourseValueByHeader(courseRow, CStr(candidates(i)))
        If Len(Trim$(CStr(v))) > 0 Then
            PickCourseValue = v
            Exit Function
        End If
    Next i
    PickCourseValue = vbNullString
End Function

' ============================================================
' Block geometry heuristics
' ============================================================

Private Function DetectBlockHeight(ByVal wsReport As Worksheet, ByVal maxBlocks As Long) As Long
    ' detect from successive tops: min positive delta between blk_i and blk_{i+1}
    On Error GoTo EH

    Dim minDelta As Long: minDelta = 0
    Dim i As Long
    For i = 1 To maxBlocks - 1
        Dim a As Range, b As Range
        Set a = GetNamedRangeCell(wsReport.Parent, "nr_blk_" & Format$(i, "00") & "_top")
        Set b = GetNamedRangeCell(wsReport.Parent, "nr_blk_" & Format$(i + 1, "00") & "_top")
        If Not a Is Nothing And Not b Is Nothing Then
            Dim d As Long: d = b.row - a.row
            If d > 0 Then
                If minDelta = 0 Or d < minDelta Then minDelta = d
            End If
        End If
    Next i

    DetectBlockHeight = minDelta
    Exit Function

EH:
    DetectBlockHeight = 0
End Function

Private Function BlockRangeByHeuristics(ByVal ws As Worksheet, ByVal topCell As Range, ByVal blockHeight As Long) As Range
    ' width: we take usedrange last col, but at least up to topCell.Column
    Dim lastCol As Long
    lastCol = ws.UsedRange.Column + ws.UsedRange.Columns.Count - 1
    If lastCol < topCell.Column Then lastCol = topCell.Column

    Set BlockRangeByHeuristics = ws.Range(ws.Cells(topCell.row, 1), ws.Cells(topCell.row + blockHeight - 1, lastCol))
End Function

' ============================================================
' Named range utilities
' ============================================================

Private Function NameExistsInWorkbook(ByVal wb As Workbook, ByVal nameText As String) As Boolean
    On Error GoTo EH
    Dim nm As Name
    Set nm = wb.names(nameText)
    NameExistsInWorkbook = True
    Exit Function
EH:
    NameExistsInWorkbook = False
End Function

Private Function GetNamedRangeCell(ByVal wb As Workbook, ByVal nameText As String) As Range
    On Error GoTo EH
    Dim nm As Name
    Set nm = wb.names(nameText)
    Set GetNamedRangeCell = nm.RefersToRange.Cells(1, 1)
    Exit Function
EH:
    Set GetNamedRangeCell = Nothing
End Function

' ============================================================
' File / folder / log
' ============================================================

Private Sub EnsureFolder(ByVal path As String)
    On Error Resume Next
    If Len(path) = 0 Then Exit Sub
    If Right$(path, 1) = "\" Then path = Left$(path, Len(path) - 1)
    If Len(dir(path, vbDirectory)) = 0 Then MkDir path
    On Error GoTo 0
End Sub

Private Function ParentFolder(ByVal fullPath As String) As String
    Dim p As Long: p = InStrRev(fullPath, "\")
    If p > 0 Then ParentFolder = Left$(fullPath, p) Else ParentFolder = ""
End Function

Private Function FileBaseName(ByVal fullPath As String) As String
    Dim s As String: s = fullPath
    Dim p As Long: p = InStrRev(s, "\")
    If p > 0 Then s = Mid$(s, p + 1)
    Dim d As Long: d = InStrRev(s, ".")
    If d > 0 Then s = Left$(s, d - 1)
    FileBaseName = s
End Function

Private Function SanitizeFileName(ByVal s As String) As String
    Dim bad As Variant, i As Long
    bad = Array("\", "/", ":", "*", "?", """", "<", ">", "|")
    For i = LBound(bad) To UBound(bad)
        s = Replace$(s, CStr(bad(i)), "_")
    Next i
    s = Replace$(s, vbCr, " ")
    s = Replace$(s, vbLf, " ")
    s = Trim$(s)
    SanitizeFileName = s
End Function

Private Sub OpenLog(ByVal runDir As String, ByVal prefix As String)
    Dim ts As String
    ts = Format$(Now, "yyyy-mm-dd_hh-nn-ss")
    mLogPath = runDir & prefix & "_" & ts & ".log"

    mLogFile = FreeFile
    Open mLogPath For Output As #mLogFile
    Print #mLogFile, "LOG " & Now
End Sub

Private Sub CloseLog()
    On Error Resume Next
    If mLogFile <> 0 Then Close #mLogFile
    mLogFile = 0
    On Error GoTo 0
End Sub

Private Sub LogLine(ByVal s As String)
    On Error Resume Next
    If mLogFile <> 0 Then Print #mLogFile, Format$(Now, "hh:nn:ss") & " | " & s
    On Error GoTo 0
End Sub

' ============================================================
' Worksheet scanning
' ============================================================

Private Function LastUsedRow(ByVal ws As Worksheet, ByVal col As Long) As Long
    On Error GoTo EH
    LastUsedRow = ws.Cells(ws.Rows.Count, col).End(xlUp).row
    Exit Function
EH:
    LastUsedRow = 0
End Function

Private Function LastUsedCol(ByVal ws As Worksheet, ByVal row As Long) As Long
    On Error GoTo EH
    LastUsedCol = ws.Cells(row, ws.Columns.Count).End(xlToLeft).Column
    Exit Function
EH:
    LastUsedCol = 0
End Function

' ============================================================
' Text normalization (simple, stable)
' ============================================================

Private Function NormalizeKey(ByVal s As String) As String
    s = LCase$(Trim$(s))
    s = ReplacePolish(s)
    s = Replace$(s, " ", "")
    s = Replace$(s, "_", "")
    s = Replace$(s, "-", "")
    s = Replace$(s, "/", "")
    s = Replace$(s, ":", "")
    s = Replace$(s, ".", "")
    s = Replace$(s, ",", "")
    NormalizeKey = s
End Function

Private Function ReplacePolish(ByVal s As String) As String
    s = Replace$(s, "ą", "a")
    s = Replace$(s, "ć", "c")
    s = Replace$(s, "ę", "e")
    s = Replace$(s, "ł", "l")
    s = Replace$(s, "ń", "n")
    s = Replace$(s, "ó", "o")
    s = Replace$(s, "ś", "s")
    s = Replace$(s, "ż", "z")
    s = Replace$(s, "ź", "z")
    ReplacePolish = s
End Function

Private Function NzStr(ByVal v As Variant) As String
    If IsError(v) Then NzStr = "" Else NzStr = CStr(v)
End Function
